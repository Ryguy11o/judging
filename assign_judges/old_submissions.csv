Opt-in prize,Submission Title,Table Number,Submission Url,Plain Description,Video,Website,File Url,Built With,Mlh Points,Mlh Software Lab,Mlh Hardware Lab,Submitter Screen Name,Submitter First Name,Submitter Last Name,Submitter Email,College/Universities Of Team Members,Additional Team Member Count,Team Member 1 Screen Name,Team Member 1 First Name,Team Member 1 Last Name,Team Member 1 Email,...
"",TCP Tac Toe,62,https://hackpsu-fall-2018.devpost.com/submissions/102004-tcp-tac-toe,"Inspiration

I wanted to apply my knowledge of the internet's protocol stack, specifically TCP to something fun 

What it does

How I built it

Challenges I ran into

Accomplishments that I'm proud of

What I learned

What's next for TCP Tac Toe
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36157/zip_files/hackpsu.zip,"python, python-socket-module",Penn State,"","",sap5699,Steven,Petrone,sap5699@psu.edu,Pennsylvania State University,0
"",NFL Team Selection,33,https://hackpsu-fall-2018.devpost.com/submissions/102009-nfl-team-selection,"Inspiration

I love sports, especially football and wrestling.

What it does

Tells you the basics of all 32 NFL teams.

How I built it

Visual Basic

Challenges I ran into

Learning people who know Visual Basic

Accomplishments that I'm proud of

Spending hours on this!

What I learned

How to code efficiently
",,https://drive.google.com/file/d/1PG4IcFperjkZNvIgpy0-oryiXdHfOOIq/view?ts=5bba0f1d,,visual-basic,1,Google Cloud Platform,Google Home,AlexBaca,Alex,Baca,afb360@gmail.com,Bloomsburg University of Pennsylvania,0
"",Tuition Fees Converter,26,https://hackpsu-fall-2018.devpost.com/submissions/102010-tuition-fees-converter,"Inspiration

Being an international student, I realized that it's important to know Penn State tuition fees in my own currency before enrolling. By doing this, all international students will not be in debt as they will be able to make sure that they afford.

What it does

Convert tuition fees to selected currency

How I built it

Using Net beans and Java language. I built using the GUI option provided in Net beans.

Challenges I ran into

Updating currency rates daily

Accomplishments that I'm proud of

Being able to code it in a limited time

What I learned

Design a GUI

What's next for Tuition Fees Converter

Being able to get current currency rates updates automatically without having to update manually. By having this, currency rates will be daily up-to-date. Also, provide more currency rates options from other country.
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36158/zip_files/Currency_Converter.zip,java,Pennsylvania State University,"","",andin,,,nqn5171@psu.edu,Pennsylvania State University,0
HackPSU Overall - Tech,Customizable Memory Game,32,https://hackpsu-fall-2018.devpost.com/submissions/102018-customizable-memory-game,"Inspiration

We were very interested in coming up with a way to combine a fun game with learning. A memory game is a very simple game that any person with any kind of background can easily pick up and start playing.

What it does

This game gives 3 types of memory games. One of the styles is a simple number to number memory game where you choose the number card and you are shown the number that it hides, match the pair to gain points and win. The second style is a customizable question and answer format where you can substitute the hidden numbers from the style before with your own questions, whether they are about computer science or psychology. The last style is a permanent format. This can be changed to be whatever the user wants, but can only be adjusted through changing the code.

How we built it

We started building the first type of the game by structuring it very simple to get the format and card checking correct. Then we moved on to adjusting the program to randomly move the hidden values around. This took time as we also had to adjust the card checking algorithm, but overall it did not take too long. After this, we decided to add the customizable functionality, our main part of the project. This was one of the easier parts as all we had to add was a loop taking inputs and adding it to an empty list. Once we finished that we thought we should add a sample/permanent format to make it easier for users to see what they can actually build. We knew just telling people to make something may confuse them so adding this section gives users an idea of the potential of the program. Lastly, we added a scoring system to keep people playing for longer. Studies show that making things more ""game-like"" can keep players attention longer.

Challenges we ran into

When first creating the program we believed that this was going to be very easy, as the game itself is rather simple. We soon realized that keeping data in-line and consistent was a problem. At first, we decided to make the grid a 2D array. After working more on the program we realized that we were running into more problems when we were displaying the grid and traversing it as a whole. Because of this, we changed the layout to be a 1D array simply using a carriage return to display the grid.

Accomplishments that we're proud of

We are very proud of working together and the process of how we broke down problems. In a team, it is much harder to find a common direction where you would want the project to go. After a while of drawing up what we thought the project was going to be we had a very similar viewpoint as a group. 

One of our groupmates, Joe, did not know any Python by the beginning of the project. As we worked on it we had to teach him as we went. It was a good lesson on how to teach and learn something very new while at the same time working on a time-sensitive project. 

What we learned

We learned that having a detailed plan of the interface, coding structure, and small updates can help in the long run of creating and developing a program. For most of us, we knew how important it is but seeing it in complete action truly shows how being a little bit more detailed can take something good and make it even better. Groups may be tough to work with in some instances, but in others, they are crucial with members helping one another when they stuck on a certain line of code or persistent error.

What's next for Creatable Memory Game

When we got closer to the end we realized how much we could have added to the project as a whole. We thought about how we could create a database where we could maintain and hold old sets of questions and answers. This would make the game better as when you are studying you will most likely be studying over multiple sessions and having to go back and re-add the last session takes a long time. This is a great format that can be used in tons of different circumstances and ways that allows a greater number of people to be able to use the program. All of us feel as though this is a game that could be used in K-10 situations where students have ample access to computers. Being able to port this onto a mobile platform could also be useful in being easily used while on the go as well. With a lot of potential, we are interested in seeing where and how this program could develop to its fullest.
",,https://drive.google.com/file/d/1Olg49HxysJCVcgLxDsqksEqFUBIBUCS7/view?usp=sharing,https://s3.amazonaws.com/challengepost/zip_files/production/36160/zip_files/HACKPSU.py.zip,python,Penn State University,"","",edg5151,Ethan,Griswold,edg5151@psu.edu,Pennsylvania State University,2,alpbabalik97,Alp,Babalik,alpbabalik97@gmail.com,jpm6172,Joseph,Merlino,jpm6172@psu.edu
JPMC - Best Social Good Hack,Customizable Memory Game,32,https://hackpsu-fall-2018.devpost.com/submissions/102018-customizable-memory-game,"Inspiration

We were very interested in coming up with a way to combine a fun game with learning. A memory game is a very simple game that any person with any kind of background can easily pick up and start playing.

What it does

This game gives 3 types of memory games. One of the styles is a simple number to number memory game where you choose the number card and you are shown the number that it hides, match the pair to gain points and win. The second style is a customizable question and answer format where you can substitute the hidden numbers from the style before with your own questions, whether they are about computer science or psychology. The last style is a permanent format. This can be changed to be whatever the user wants, but can only be adjusted through changing the code.

How we built it

We started building the first type of the game by structuring it very simple to get the format and card checking correct. Then we moved on to adjusting the program to randomly move the hidden values around. This took time as we also had to adjust the card checking algorithm, but overall it did not take too long. After this, we decided to add the customizable functionality, our main part of the project. This was one of the easier parts as all we had to add was a loop taking inputs and adding it to an empty list. Once we finished that we thought we should add a sample/permanent format to make it easier for users to see what they can actually build. We knew just telling people to make something may confuse them so adding this section gives users an idea of the potential of the program. Lastly, we added a scoring system to keep people playing for longer. Studies show that making things more ""game-like"" can keep players attention longer.

Challenges we ran into

When first creating the program we believed that this was going to be very easy, as the game itself is rather simple. We soon realized that keeping data in-line and consistent was a problem. At first, we decided to make the grid a 2D array. After working more on the program we realized that we were running into more problems when we were displaying the grid and traversing it as a whole. Because of this, we changed the layout to be a 1D array simply using a carriage return to display the grid.

Accomplishments that we're proud of

We are very proud of working together and the process of how we broke down problems. In a team, it is much harder to find a common direction where you would want the project to go. After a while of drawing up what we thought the project was going to be we had a very similar viewpoint as a group. 

One of our groupmates, Joe, did not know any Python by the beginning of the project. As we worked on it we had to teach him as we went. It was a good lesson on how to teach and learn something very new while at the same time working on a time-sensitive project. 

What we learned

We learned that having a detailed plan of the interface, coding structure, and small updates can help in the long run of creating and developing a program. For most of us, we knew how important it is but seeing it in complete action truly shows how being a little bit more detailed can take something good and make it even better. Groups may be tough to work with in some instances, but in others, they are crucial with members helping one another when they stuck on a certain line of code or persistent error.

What's next for Creatable Memory Game

When we got closer to the end we realized how much we could have added to the project as a whole. We thought about how we could create a database where we could maintain and hold old sets of questions and answers. This would make the game better as when you are studying you will most likely be studying over multiple sessions and having to go back and re-add the last session takes a long time. This is a great format that can be used in tons of different circumstances and ways that allows a greater number of people to be able to use the program. All of us feel as though this is a game that could be used in K-10 situations where students have ample access to computers. Being able to port this onto a mobile platform could also be useful in being easily used while on the go as well. With a lot of potential, we are interested in seeing where and how this program could develop to its fullest.
",,https://drive.google.com/file/d/1Olg49HxysJCVcgLxDsqksEqFUBIBUCS7/view?usp=sharing,https://s3.amazonaws.com/challengepost/zip_files/production/36160/zip_files/HACKPSU.py.zip,python,Penn State University,"","",edg5151,Ethan,Griswold,edg5151@psu.edu,Pennsylvania State University,2,alpbabalik97,Alp,Babalik,alpbabalik97@gmail.com,jpm6172,Joseph,Merlino,jpm6172@psu.edu
"",Run Router,59,https://hackpsu-fall-2018.devpost.com/submissions/102044-run-router,"Inspiration

I really like to have running workouts on my free time, however I don't know if the weather outside is going to be the good. That is why I decided to create a simple app to get this information.

What it does

It uses the Accuweather and Google Maps APIs to give information about running spots and weather data to know when is the best time for run in a city.

How I built it

I used python with Flask for the backend and HTML and CSS for the front-end

Challenges I ran into

I didn't have too much experience with Flask and deploying applications on Heroku. Also, I ran into multiple bugs during the development.

Accomplishments that I'm proud of

After hours of work, I'm proud to see the basic structure of the project finished.

What I learned

I learned how to build a server with python that uses multiple APIs and how to deploy it.

What's next for Run Router

Continue adding functionality and new information from external sources.
",,https://run-router.herokuapp.com/,,"python, flask, accuweather, google-maps, html5, css3",Penn State University,"","",fxl33,Fernando,Leira Cortel,fxl33@psu.edu,Pennsylvania State University,0
Best use of Google Cloud Platform,Funding Secured: Algorithmic Trading Bot,29,https://hackpsu-fall-2018.devpost.com/submissions/102083-funding-secured-algorithmic-trading-bot,"Algorithmic Trading project with Robinhood

We built 2 different models with historical stock data in order to automatically make trades.

Data is updated on the open of each trading day and trades are made based on daily closing prices.
",,https://github.com/jed326/AutoTrader,,"python, html",Pennsylvania State University,"","",jefferycao1,Jeffery,Cao,jefferycao2016@gmail.com,Pennsylvania State University,3,jed326,Jay,Deng,jayd0104@gmail.com,ckm5373,,,ckm5373@psu.edu,aclheexn,Alex,Chen,auc39@psu.edu
Booz Allen Hamilton - Best Machine Learning Hack,Funding Secured: Algorithmic Trading Bot,29,https://hackpsu-fall-2018.devpost.com/submissions/102083-funding-secured-algorithmic-trading-bot,"Algorithmic Trading project with Robinhood

We built 2 different models with historical stock data in order to automatically make trades.

Data is updated on the open of each trading day and trades are made based on daily closing prices.
",,https://github.com/jed326/AutoTrader,,"python, html",Pennsylvania State University,"","",jefferycao1,Jeffery,Cao,jefferycao2016@gmail.com,Pennsylvania State University,3,jed326,Jay,Deng,jayd0104@gmail.com,ckm5373,,,ckm5373@psu.edu,aclheexn,Alex,Chen,auc39@psu.edu
Nittany AI Alliance - AI Challenge,Funding Secured: Algorithmic Trading Bot,29,https://hackpsu-fall-2018.devpost.com/submissions/102083-funding-secured-algorithmic-trading-bot,"Algorithmic Trading project with Robinhood

We built 2 different models with historical stock data in order to automatically make trades.

Data is updated on the open of each trading day and trades are made based on daily closing prices.
",,https://github.com/jed326/AutoTrader,,"python, html",Pennsylvania State University,"","",jefferycao1,Jeffery,Cao,jefferycao2016@gmail.com,Pennsylvania State University,3,jed326,Jay,Deng,jayd0104@gmail.com,ckm5373,,,ckm5373@psu.edu,aclheexn,Alex,Chen,auc39@psu.edu
HackPSU Overall - Tech,Funding Secured: Algorithmic Trading Bot,29,https://hackpsu-fall-2018.devpost.com/submissions/102083-funding-secured-algorithmic-trading-bot,"Algorithmic Trading project with Robinhood

We built 2 different models with historical stock data in order to automatically make trades.

Data is updated on the open of each trading day and trades are made based on daily closing prices.
",,https://github.com/jed326/AutoTrader,,"python, html",Pennsylvania State University,"","",jefferycao1,Jeffery,Cao,jefferycao2016@gmail.com,Pennsylvania State University,3,jed326,Jay,Deng,jayd0104@gmail.com,ckm5373,,,ckm5373@psu.edu,aclheexn,Alex,Chen,auc39@psu.edu
Capital One - Best Financial Hack,Funding Secured: Algorithmic Trading Bot,29,https://hackpsu-fall-2018.devpost.com/submissions/102083-funding-secured-algorithmic-trading-bot,"Algorithmic Trading project with Robinhood

We built 2 different models with historical stock data in order to automatically make trades.

Data is updated on the open of each trading day and trades are made based on daily closing prices.
",,https://github.com/jed326/AutoTrader,,"python, html",Pennsylvania State University,"","",jefferycao1,Jeffery,Cao,jefferycao2016@gmail.com,Pennsylvania State University,3,jed326,Jay,Deng,jayd0104@gmail.com,ckm5373,,,ckm5373@psu.edu,aclheexn,Alex,Chen,auc39@psu.edu
HackPSU Overall - Tech,Procedurally Generated Artwork,7,https://hackpsu-fall-2018.devpost.com/submissions/102087-procedurally-generated-artwork,"Inspiration

Video games such as No Man's Sky

What it does

Gives a unique procedurally generated piece of art everytime it is run

How I built it

Using python

Challenges I ran into

none

Accomplishments that I'm proud of

Generating procedural artwork

What I learned

I learned about random numbers in python

What's next for Procedurally Generated Artwork

Adding more 'procedural' elements.
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36186/zip_files/hackpsu.zip,python,Penn State University,"","",kwh5484,kwh5484,,kwh5484@psu.edu,Pennsylvania State University,0
"",Today in History Alexa Skill,56,https://hackpsu-fall-2018.devpost.com/submissions/102090-today-in-history-alexa-skill,"Inspiration

I wanted to learn how to make amazon alexa skills. This skill required me to be able to use the skills builder tool and aws lambda. 

What it does

It gives you a fact pulled from http://history.muffinlabs.com/ of the current date from some time in History.

How I built it

Amazon Alexa Skill Builder, AWS Lambda

Challenges I ran into

Learning how to use Alexa skill builder. Learning how to use intents and AWS Lambda. Ran into not picking the correct locations for aws setup correctly. 

Accomplishments that I'm proud of

Learning how to use a tool that I'm unfamiliar with. Being able to complete a project from start to finish. 

What I learned

AWS Lambda. 

What's next for Today in History Alexa Skill

Give a specific date through voice and getting a fact back in return. Multiple facts
",https://vimeo.com/293816373,,https://s3.amazonaws.com/challengepost/zip_files/production/36300/zip_files/Archive.zip,"amazon-alexa, amazon-web-services",Penn State,"","",michaelpostava213,Michael,Postava,michaelpostava213@gmail.com,Pennsylvania State University,0
KCF - Hack the Waiting Room Challenge,Room Occupancy Tracker,10,https://hackpsu-fall-2018.devpost.com/submissions/102094-room-occupancy-tracker,"Inspiration

We wanted to create a hardware and software setup that collects data on the occupancy of a room and makes it view-able to a client and editable to an admin. We also wanted to explore the capabilities of the Arduino's data collection abilities

What it does

Our build will record people entering and exiting the space by using a set of pressure sensors and an ultrasonic sensor to count the actions a person makes on their way through an entrance. It also accounts for people following close behind one another by using the ultrasonic sensor to double-check the people crossing the threshold. Then the program takes the data and sends it to an admin and client for viewing and editing.

Data Collection:
For higher accuracy, we assumed that the door only allows one person to go through at a time. The data collection begins with the Arduino waiting for a response from one of the buttons, which act as our pressure sensors. Depending on which side of the door is pressed first defines which path the program takes. It then waits for the person to either back away from the door, leaving nothing to happen to the count, or step across the opening onto the next plate, leaving both pressed. Now two more things can happen; the person can step back into the room and we go back to the previous step, or the person continues and steps off the plate their back foot is on. When this happens, the count of people in the room changes based on the starting plate, which denotes the direction they went through the opening. The code also supports multiple people moving through the opening one after the other with the help of an ultrasonic sensor.

Visual Interface:
Our visual interface is split into two main parts; the Admin Page, and the Client Page. The Client Page displays information that would be relevant to customers or visitors at the venue of deployment. It displays the total number of people currently in the room, the maximum occupancy, and an announcement that notifies the customers about the status of the room. Also, visible beneath the attendance and announcement, there is the memo which is a message from the administrator of the building that says whatever he/she desires. This message is controlled by the Admin Page. The Admin Page contains specific data that the admin would find useful. The administrator can change, as of now, two settings; the previously mentioned memo on the client page, and the rooms maximum capacity.

How we built it

We utilized Arduinos to collect data through sensors and the Johnny-Five API to compile the data into a format that could be utilized for data manipulation. Through HTML formatting, we were able to make this data user friendly and informative to clients.

Challenges we ran into

The first roadblock we ran into was figuring out which sensors we could use. Many of them weren't usable for our task and the ones that we could use had severe limitations. For instance, the Infrared sensor was only able to test for motion once every three seconds which made them unusable in an environment where people walk past the sensor constantly. Another problem we faced was that our initial plan involved using pressure sensors, which would have been an accurate indicator of people entering and exiting a room. However,  since none of us had any pressure sensors, we were unable to follow out initial plan. Instead we used something that could simulate it, buttons, which were readily available to us. We got the chance to use JavaScript , which was something new to us, and this made this a difficult and interesting learn experience. It works very differently to the other languages we already knew and made every step something we had to learn before using. 

Accomplishments that We're proud of

We are proud that we were able to get the Arduino to collect usable data. We were also proud that we were able to use JavaScript to complete the challenge

What we learned

We learned to utilize the Arduino and it's sensors to collect usable data. We also learned how to use JavaScript to collect, compile, and format data.

What's next for Room Occupancy Tracker


Add a interactive graphs on the website
Add more admin functionality
Add more ways to identify the status of the room
Add an interactive graph to the admin page
Replace buttons with pressure sensors

",,https://github.com/tint3dgreen/Room-Sensors,https://s3.amazonaws.com/challengepost/zip_files/production/36273/zip_files/Room-Sensors-master.zip,"johnny-five-api, arduino, javascript, html5, css, sensors, express.js",Pennsylvania State University,"","",anb5731,Anthony,Brigidi,anb5731@psu.edu,Pennsylvania State University,2,YangShizzle,Yang,,yanglin501st@yahoo.com,tint3dgreen,tint3dgreen,,carscott@optonline.net
HackPSU Overall - Design,Room Occupancy Tracker,10,https://hackpsu-fall-2018.devpost.com/submissions/102094-room-occupancy-tracker,"Inspiration

We wanted to create a hardware and software setup that collects data on the occupancy of a room and makes it view-able to a client and editable to an admin. We also wanted to explore the capabilities of the Arduino's data collection abilities

What it does

Our build will record people entering and exiting the space by using a set of pressure sensors and an ultrasonic sensor to count the actions a person makes on their way through an entrance. It also accounts for people following close behind one another by using the ultrasonic sensor to double-check the people crossing the threshold. Then the program takes the data and sends it to an admin and client for viewing and editing.

Data Collection:
For higher accuracy, we assumed that the door only allows one person to go through at a time. The data collection begins with the Arduino waiting for a response from one of the buttons, which act as our pressure sensors. Depending on which side of the door is pressed first defines which path the program takes. It then waits for the person to either back away from the door, leaving nothing to happen to the count, or step across the opening onto the next plate, leaving both pressed. Now two more things can happen; the person can step back into the room and we go back to the previous step, or the person continues and steps off the plate their back foot is on. When this happens, the count of people in the room changes based on the starting plate, which denotes the direction they went through the opening. The code also supports multiple people moving through the opening one after the other with the help of an ultrasonic sensor.

Visual Interface:
Our visual interface is split into two main parts; the Admin Page, and the Client Page. The Client Page displays information that would be relevant to customers or visitors at the venue of deployment. It displays the total number of people currently in the room, the maximum occupancy, and an announcement that notifies the customers about the status of the room. Also, visible beneath the attendance and announcement, there is the memo which is a message from the administrator of the building that says whatever he/she desires. This message is controlled by the Admin Page. The Admin Page contains specific data that the admin would find useful. The administrator can change, as of now, two settings; the previously mentioned memo on the client page, and the rooms maximum capacity.

How we built it

We utilized Arduinos to collect data through sensors and the Johnny-Five API to compile the data into a format that could be utilized for data manipulation. Through HTML formatting, we were able to make this data user friendly and informative to clients.

Challenges we ran into

The first roadblock we ran into was figuring out which sensors we could use. Many of them weren't usable for our task and the ones that we could use had severe limitations. For instance, the Infrared sensor was only able to test for motion once every three seconds which made them unusable in an environment where people walk past the sensor constantly. Another problem we faced was that our initial plan involved using pressure sensors, which would have been an accurate indicator of people entering and exiting a room. However,  since none of us had any pressure sensors, we were unable to follow out initial plan. Instead we used something that could simulate it, buttons, which were readily available to us. We got the chance to use JavaScript , which was something new to us, and this made this a difficult and interesting learn experience. It works very differently to the other languages we already knew and made every step something we had to learn before using. 

Accomplishments that We're proud of

We are proud that we were able to get the Arduino to collect usable data. We were also proud that we were able to use JavaScript to complete the challenge

What we learned

We learned to utilize the Arduino and it's sensors to collect usable data. We also learned how to use JavaScript to collect, compile, and format data.

What's next for Room Occupancy Tracker


Add a interactive graphs on the website
Add more admin functionality
Add more ways to identify the status of the room
Add an interactive graph to the admin page
Replace buttons with pressure sensors

",,https://github.com/tint3dgreen/Room-Sensors,https://s3.amazonaws.com/challengepost/zip_files/production/36273/zip_files/Room-Sensors-master.zip,"johnny-five-api, arduino, javascript, html5, css, sensors, express.js",Pennsylvania State University,"","",anb5731,Anthony,Brigidi,anb5731@psu.edu,Pennsylvania State University,2,YangShizzle,Yang,,yanglin501st@yahoo.com,tint3dgreen,tint3dgreen,,carscott@optonline.net
HackPSU Overall - Tech,Room Occupancy Tracker,10,https://hackpsu-fall-2018.devpost.com/submissions/102094-room-occupancy-tracker,"Inspiration

We wanted to create a hardware and software setup that collects data on the occupancy of a room and makes it view-able to a client and editable to an admin. We also wanted to explore the capabilities of the Arduino's data collection abilities

What it does

Our build will record people entering and exiting the space by using a set of pressure sensors and an ultrasonic sensor to count the actions a person makes on their way through an entrance. It also accounts for people following close behind one another by using the ultrasonic sensor to double-check the people crossing the threshold. Then the program takes the data and sends it to an admin and client for viewing and editing.

Data Collection:
For higher accuracy, we assumed that the door only allows one person to go through at a time. The data collection begins with the Arduino waiting for a response from one of the buttons, which act as our pressure sensors. Depending on which side of the door is pressed first defines which path the program takes. It then waits for the person to either back away from the door, leaving nothing to happen to the count, or step across the opening onto the next plate, leaving both pressed. Now two more things can happen; the person can step back into the room and we go back to the previous step, or the person continues and steps off the plate their back foot is on. When this happens, the count of people in the room changes based on the starting plate, which denotes the direction they went through the opening. The code also supports multiple people moving through the opening one after the other with the help of an ultrasonic sensor.

Visual Interface:
Our visual interface is split into two main parts; the Admin Page, and the Client Page. The Client Page displays information that would be relevant to customers or visitors at the venue of deployment. It displays the total number of people currently in the room, the maximum occupancy, and an announcement that notifies the customers about the status of the room. Also, visible beneath the attendance and announcement, there is the memo which is a message from the administrator of the building that says whatever he/she desires. This message is controlled by the Admin Page. The Admin Page contains specific data that the admin would find useful. The administrator can change, as of now, two settings; the previously mentioned memo on the client page, and the rooms maximum capacity.

How we built it

We utilized Arduinos to collect data through sensors and the Johnny-Five API to compile the data into a format that could be utilized for data manipulation. Through HTML formatting, we were able to make this data user friendly and informative to clients.

Challenges we ran into

The first roadblock we ran into was figuring out which sensors we could use. Many of them weren't usable for our task and the ones that we could use had severe limitations. For instance, the Infrared sensor was only able to test for motion once every three seconds which made them unusable in an environment where people walk past the sensor constantly. Another problem we faced was that our initial plan involved using pressure sensors, which would have been an accurate indicator of people entering and exiting a room. However,  since none of us had any pressure sensors, we were unable to follow out initial plan. Instead we used something that could simulate it, buttons, which were readily available to us. We got the chance to use JavaScript , which was something new to us, and this made this a difficult and interesting learn experience. It works very differently to the other languages we already knew and made every step something we had to learn before using. 

Accomplishments that We're proud of

We are proud that we were able to get the Arduino to collect usable data. We were also proud that we were able to use JavaScript to complete the challenge

What we learned

We learned to utilize the Arduino and it's sensors to collect usable data. We also learned how to use JavaScript to collect, compile, and format data.

What's next for Room Occupancy Tracker


Add a interactive graphs on the website
Add more admin functionality
Add more ways to identify the status of the room
Add an interactive graph to the admin page
Replace buttons with pressure sensors

",,https://github.com/tint3dgreen/Room-Sensors,https://s3.amazonaws.com/challengepost/zip_files/production/36273/zip_files/Room-Sensors-master.zip,"johnny-five-api, arduino, javascript, html5, css, sensors, express.js",Pennsylvania State University,"","",anb5731,Anthony,Brigidi,anb5731@psu.edu,Pennsylvania State University,2,YangShizzle,Yang,,yanglin501st@yahoo.com,tint3dgreen,tint3dgreen,,carscott@optonline.net
HackPSU Overall - Tech,SQUARE RACE,42,https://hackpsu-fall-2018.devpost.com/submissions/102173-square-race,"Inspiration

I came to hackpsu for extra credit, but I thought while I was here to take advantage of the event and try to learn something new. So after sitting through a short workshop in unity I thought it is something that seems kind of fun and I know nothing about.  So I teach myself through unity online informative material, then built a neat local multiplayer game that reminded me of old flash games.

What it does

races squares

How I built it

unity and some simple c# code

Accomplishments that I'm proud of

staying overnight at hackpsu and learning a new skill I knew nothing about before the weekend

What I learned

how to build something in Unity

What's next for SQUARE RACE

the sky is the limit truly
",,,,"unity, c#",Penn State,"","",jkm26,Jacob,Minnich,jkm26@psu.edu,Pennsylvania State University,0
HackPSU Overall - Design,SAVIOUR - A Disaster Management App,23,https://hackpsu-fall-2018.devpost.com/submissions/102182-saviour-a-disaster-management-app,"DISASTER RELIEF & RECOVERY CHALLENGE
JPMorgan Chase - Best Hack for Social Good

Designing a wireframe for a mobile application called SAVIOUR to improve the efficiency and effectiveness of Disaster Management system post-disaster.

Sagar Prakash. Rasam
Engineering Design Graduate Student
The Pennsylvania State University

INTRODUCTION
This mobile application idea is my attempt to address the relief and recovery issue faced by cities impacted by a natural disaster. This app addresses the gaps and limitations of an existing disaster relief app. The Amrita Kripa App was recently developed by the Department of Wireless Network and Applications, Amrita University, India to assist the relief work during the Kerala Floods in India. 

IMPACT
The solution to this challenge was to centralise the relief and recovery efforts after a natural disaster so as to make the disaster management process effective and efficient. Amrita university said their app even in its development stage  helped “locate, rescue and provide relief” to more than 12,000 people in Kerala. The app, which is available as of now in Malayalam and English, is called AmritaKripa and uses real-time GPS data to locate users. The beneficiary  numbers in this stage reflect that there is definitely a market for similar apps if those apps are able to scale up taking into consideration all the stakeholders that are involved in the relief  and recovery effort during disaster management.

INNOVATION & CREATIVITY
Moving a step ahead, my first step was to identify all relevant stakeholders that participate in the relief and recovery process following a natural disaster. The original app was designed taking into considerations just the victims of the disasters. My app ‘SAVIOUR - By the People, For the People’ not only takes into consideration the needs of victims but also the relief workers. This relief workers may be people who volunteer or make direct monetary donations.

SAVIOUR is a fresh attempt to not only help the victims but also to provide a centralised portals where people can systematically volunteer and donate food, medical as well other resources to the needy. 

In pic: Screenshots from the SAVIOUR mobile application showcasing the addressal of different needs of different stakeholder

COMPLETENESS OF SOLUTION
This may not be complete, but this application is definitely scalable and can be scaled to other disasters. The next process will be to study the rehabilitation timeline of the affected areas so as to integrate additional services that will assist the victims to rebuild their life at the earliest.

SUSTAINABILITY
SAVIOUR’s tagline says it all - ‘By the people, For the people’. Yes this is definitely a sustainable solution, as the affected community does not have to wait for relief and recovery work till the government declares relief aid for the victims. We often donate money on portals and we don’t know what it is used for, some portals are not even officially authorised. This portals gives the donor ability to select and donate the relief material desired by the victims. This eliminates the probability of fraudulent transactions. Thus the app tries to bring order in those moments of confusion and panic faced by the victims after a disaster.

In pic: Screenshots from SAVIOUR mobile application showcasing the ability of the stakeholders to be self sustainable during disaster management process post-disaster.

DESIGN
I work as a volunteer for Penn State’s chapter of Association of India’s Development, a student body that collects fund through various social activities at Penn State and then make donations to volunteer organizations in India that address various social causes. Durin the Kerela flood, we were as confused as people in India as we did not had a relevant channel to assist the flood victims during the initial stages(for upto 2 weeks) of the flooding situation. Plus on the ground zero scenes there were problems in tracking down the trapped victims. This application addresses both this scenarios. Not only this but it also helps the potential donors empathize with the situation on ground zero due to its real time information display(not described here due to short project timeline). Plus donors gets a sense of pride and fulfilment seeing their donations directly impacting people on ground zero rather than sending funds through multiple middle channels.

PROTOTYPE LINK:
https://xd.adobe.com/view/1c7770d3-6c0b-4f54-5864-1238b5b23d29-6a46/?fullscreen 
",,https://xd.adobe.com/view/1c7770d3-6c0b-4f54-5864-1238b5b23d29-6a46/?fullscreen ,https://s3.amazonaws.com/challengepost/zip_files/production/36254/zip_files/JPMC_Challenge.pdf,adobe-xd,Pennsylvania State University,"","",spr20,Sagar,Rasam,spr20@psu.edu,Pennsylvania State University,0
JPMC - Best Social Good Hack,SAVIOUR - A Disaster Management App,23,https://hackpsu-fall-2018.devpost.com/submissions/102182-saviour-a-disaster-management-app,"DISASTER RELIEF & RECOVERY CHALLENGE
JPMorgan Chase - Best Hack for Social Good

Designing a wireframe for a mobile application called SAVIOUR to improve the efficiency and effectiveness of Disaster Management system post-disaster.

Sagar Prakash. Rasam
Engineering Design Graduate Student
The Pennsylvania State University

INTRODUCTION
This mobile application idea is my attempt to address the relief and recovery issue faced by cities impacted by a natural disaster. This app addresses the gaps and limitations of an existing disaster relief app. The Amrita Kripa App was recently developed by the Department of Wireless Network and Applications, Amrita University, India to assist the relief work during the Kerala Floods in India. 

IMPACT
The solution to this challenge was to centralise the relief and recovery efforts after a natural disaster so as to make the disaster management process effective and efficient. Amrita university said their app even in its development stage  helped “locate, rescue and provide relief” to more than 12,000 people in Kerala. The app, which is available as of now in Malayalam and English, is called AmritaKripa and uses real-time GPS data to locate users. The beneficiary  numbers in this stage reflect that there is definitely a market for similar apps if those apps are able to scale up taking into consideration all the stakeholders that are involved in the relief  and recovery effort during disaster management.

INNOVATION & CREATIVITY
Moving a step ahead, my first step was to identify all relevant stakeholders that participate in the relief and recovery process following a natural disaster. The original app was designed taking into considerations just the victims of the disasters. My app ‘SAVIOUR - By the People, For the People’ not only takes into consideration the needs of victims but also the relief workers. This relief workers may be people who volunteer or make direct monetary donations.

SAVIOUR is a fresh attempt to not only help the victims but also to provide a centralised portals where people can systematically volunteer and donate food, medical as well other resources to the needy. 

In pic: Screenshots from the SAVIOUR mobile application showcasing the addressal of different needs of different stakeholder

COMPLETENESS OF SOLUTION
This may not be complete, but this application is definitely scalable and can be scaled to other disasters. The next process will be to study the rehabilitation timeline of the affected areas so as to integrate additional services that will assist the victims to rebuild their life at the earliest.

SUSTAINABILITY
SAVIOUR’s tagline says it all - ‘By the people, For the people’. Yes this is definitely a sustainable solution, as the affected community does not have to wait for relief and recovery work till the government declares relief aid for the victims. We often donate money on portals and we don’t know what it is used for, some portals are not even officially authorised. This portals gives the donor ability to select and donate the relief material desired by the victims. This eliminates the probability of fraudulent transactions. Thus the app tries to bring order in those moments of confusion and panic faced by the victims after a disaster.

In pic: Screenshots from SAVIOUR mobile application showcasing the ability of the stakeholders to be self sustainable during disaster management process post-disaster.

DESIGN
I work as a volunteer for Penn State’s chapter of Association of India’s Development, a student body that collects fund through various social activities at Penn State and then make donations to volunteer organizations in India that address various social causes. Durin the Kerela flood, we were as confused as people in India as we did not had a relevant channel to assist the flood victims during the initial stages(for upto 2 weeks) of the flooding situation. Plus on the ground zero scenes there were problems in tracking down the trapped victims. This application addresses both this scenarios. Not only this but it also helps the potential donors empathize with the situation on ground zero due to its real time information display(not described here due to short project timeline). Plus donors gets a sense of pride and fulfilment seeing their donations directly impacting people on ground zero rather than sending funds through multiple middle channels.

PROTOTYPE LINK:
https://xd.adobe.com/view/1c7770d3-6c0b-4f54-5864-1238b5b23d29-6a46/?fullscreen 
",,https://xd.adobe.com/view/1c7770d3-6c0b-4f54-5864-1238b5b23d29-6a46/?fullscreen ,https://s3.amazonaws.com/challengepost/zip_files/production/36254/zip_files/JPMC_Challenge.pdf,adobe-xd,Pennsylvania State University,"","",spr20,Sagar,Rasam,spr20@psu.edu,Pennsylvania State University,0
HackPSU Overall - Design,Ranger Danger,45,https://hackpsu-fall-2018.devpost.com/submissions/102201-ranger-danger,"The design idea for the National Park Rangers was to provide a task list, a map, and a current statuses of a Park Ranger. We reviewed the current National Park Ranger’s website for inspiration along with a Washington Post to explain a typical day as a Park Ranger. This project was a three step process starting with our ideas, our low-fidelity, and our high-fidelity. The goal of the design was to have a desktop version and a mobile version for a Park Ranger to use either at their office or in the National Park. Please refer to the Google Docs link for access to the Desktop prototype and the Mobile prototype. Thank you!
",,https://docs.google.com/document/d/1TCDN23xel8sNOEBW9IlSF04pkIJzt69ftpBpjMWdvCE/edit?usp=sharing,,"invision, photoshop",Penn State York,"","",leeper,Patrick,Leeper,leeper@psu.edu,"Pennsylvania State University - York, Pennsylvania State University",1,dik5305,Donghun,Kim,dik5305@psu.edu
HackPSU Overall - Tech,Spotify Playlist Visualization Tool,15,https://hackpsu-fall-2018.devpost.com/submissions/102235-spotify-playlist-visualization-tool,"Inspiration

What it does

Given a Spotify username, this tool will graph various attributes of all of the accounts' playlists.

How we built it

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for Spotify Playlist Visualization Tool
",,https://github.com/bns5273/hackPSU-PlaylistVisualizationTool,https://s3.amazonaws.com/challengepost/zip_files/production/36250/zip_files/hackPSU.zip,"",Penn State University,"","",BrettSpangler,Brett,Spangler,brettspan@gmail.com,Pennsylvania State University,0
HackPSU Overall - Tech,MessageCapitalization,39,https://hackpsu-fall-2018.devpost.com/submissions/102236-messagecapitalization,"Inspiration

I wanted to make life easier for capitalization 

What it does

capitalizes a message you wrote 

How I built it

learnt the telegram api and implements calls 

Challenges I ran into

Save the input 

Accomplishments that I'm proud of

Getting a response

What I learned

api calls

What's next for MessageCapitalization

Find another purpose
",,https://github.com/aarushg/MessageCapitalization,,python,penn state,Domain.com,"",aarushg,Aarush,Gupta,aarush.gupta@gmail.com,Pennsylvania State University,0
JPMC - Best Social Good Hack,MessageCapitalization,39,https://hackpsu-fall-2018.devpost.com/submissions/102236-messagecapitalization,"Inspiration

I wanted to make life easier for capitalization 

What it does

capitalizes a message you wrote 

How I built it

learnt the telegram api and implements calls 

Challenges I ran into

Save the input 

Accomplishments that I'm proud of

Getting a response

What I learned

api calls

What's next for MessageCapitalization

Find another purpose
",,https://github.com/aarushg/MessageCapitalization,,python,penn state,Domain.com,"",aarushg,Aarush,Gupta,aarush.gupta@gmail.com,Pennsylvania State University,0
Best Domain Name from Domain.com,rushguy.com,70,https://hackpsu-fall-2018.devpost.com/submissions/102237-rushguy-com,"Inspiration

name

What it does

domain

How I built it

Challenges I ran into

Accomplishments that I'm proud of

What I learned

What's next for rushguy.com
",,,,"",penn state,"","",aarushg,Aarush,Gupta,aarush.gupta@gmail.com,Pennsylvania State University,0
"",Unity_pong_game,17,https://hackpsu-fall-2018.devpost.com/submissions/102241-unity_pong_game,"Unity_pong_game

Pong
",,https://github.com/Bwlazelek/Unity_pong_game,,c#,Penn State,"","",Bwlazelek,Brandon,Wlazelek,bwlazie@yahoo.com,Pennsylvania State University,1,WildScavello,WildScavello,,nfs5129@psu.edu
Vanguard - Reducing Student Debt,moneySaver,40,https://hackpsu-fall-2018.devpost.com/submissions/102245-moneysaver,"Inspiration:

Many people find their money spent easily and they even haven't realized how they spent the money. This system is helping people to analyze how they spend money on different aspects. It will show a pie chart to afford visualization of the analyzation.

What it does

Visualize how user's money spent and give out a specific suggestion for saving money.

How I built it

Java, Netbeans, Coffee

Challenges I ran into

How to visualize it by a piechart with aspect name and data, not only a simple pie chart.

Accomplishments

I'm proud of writing a piechart showing aspect name and data at the same time in java. I never learned that before.

What I learned

How to let a piechart work. Not only a pie chart but showing both aspect name and data at the same time.

What's next for moneySaver----An visualized analyze system

Saving data into a Database. Give new features about comparing and analyzing the data between months.
",,https://github.com/tug23655/moneySaver,https://s3.amazonaws.com/challengepost/zip_files/production/36262/zip_files/moneySaver.zip,java,Temple University,"","",usadaiwei,,,tug23655@temple.edu,Temple University,0
HackPSU Overall - Tech,moneySaver,40,https://hackpsu-fall-2018.devpost.com/submissions/102245-moneysaver,"Inspiration:

Many people find their money spent easily and they even haven't realized how they spent the money. This system is helping people to analyze how they spend money on different aspects. It will show a pie chart to afford visualization of the analyzation.

What it does

Visualize how user's money spent and give out a specific suggestion for saving money.

How I built it

Java, Netbeans, Coffee

Challenges I ran into

How to visualize it by a piechart with aspect name and data, not only a simple pie chart.

Accomplishments

I'm proud of writing a piechart showing aspect name and data at the same time in java. I never learned that before.

What I learned

How to let a piechart work. Not only a pie chart but showing both aspect name and data at the same time.

What's next for moneySaver----An visualized analyze system

Saving data into a Database. Give new features about comparing and analyzing the data between months.
",,https://github.com/tug23655/moneySaver,https://s3.amazonaws.com/challengepost/zip_files/production/36262/zip_files/moneySaver.zip,java,Temple University,"","",usadaiwei,,,tug23655@temple.edu,Temple University,0
Capital One - Best Financial Hack,moneySaver,40,https://hackpsu-fall-2018.devpost.com/submissions/102245-moneysaver,"Inspiration:

Many people find their money spent easily and they even haven't realized how they spent the money. This system is helping people to analyze how they spend money on different aspects. It will show a pie chart to afford visualization of the analyzation.

What it does

Visualize how user's money spent and give out a specific suggestion for saving money.

How I built it

Java, Netbeans, Coffee

Challenges I ran into

How to visualize it by a piechart with aspect name and data, not only a simple pie chart.

Accomplishments

I'm proud of writing a piechart showing aspect name and data at the same time in java. I never learned that before.

What I learned

How to let a piechart work. Not only a pie chart but showing both aspect name and data at the same time.

What's next for moneySaver----An visualized analyze system

Saving data into a Database. Give new features about comparing and analyzing the data between months.
",,https://github.com/tug23655/moneySaver,https://s3.amazonaws.com/challengepost/zip_files/production/36262/zip_files/moneySaver.zip,java,Temple University,"","",usadaiwei,,,tug23655@temple.edu,Temple University,0
HackPSU Overall - Design,Design Challenge - Park Ranger App,46,https://hackpsu-fall-2018.devpost.com/submissions/102258-design-challenge-park-ranger-app,"Inspiration

The default weather app for android, google maps, and emergency preparedness.

What it does

It shows the design of an app that will be utilized by Park Rangers to manage their National Park.  The app can send out mass texts, monitor the weather, contains a map of the park, and displays emergency message about the weather, missing persons, and other emergencies.

How we built it

Built the initial Wire Map using a whiteboard and then used Proto.io to create a working prototype.

Documentation

https://docs.google.com/document/d/1YG27pLRNYCKv_j4aYLYapaHMqhfB2Yxs9vMm7NeZ9-U/edit?usp=sharing

Challenges we ran into

Finding and using a proper prototyping software.

Accomplishments that we're proud of

We made a functioning prototype.

What we learned

How to prototype using Prot.io as well as gained experience with the design of graphical interfaces.

What's next for Design Challenge - Park Ranger App

Creating the Coding and integration for the app and then contacting Park Rangers on what they want for the app and how to integrate it into their system.
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36265/zip_files/NationalParkRangerApp-html.zip,proto.io,Penn State Erie: The Behrend College,"","",rkh22,Richard,Henry,rkh22@psu.edu,Pennsylvania State University,2,mod5430,Marshall,Dimperio,mod5430@psu.edu,jbc5740psu,Joseph,Chang,jbc5740psu@gmail.com
HackPSU Overall - Design,Pit Boss: The Raspberry-Pi Blackjack Helper,36,https://hackpsu-fall-2018.devpost.com/submissions/102266-pit-boss-the-raspberry-pi-blackjack-helper,"Inspiration

Pit Boss, named after the casino overseer who controls the various blackjack pits, was designed to help users make some money

What it does

Pit Boss helps you win at Blackjack by recognizing cards played, and using probability to recommend the action the player should take to maximize winnings

How I built it

I built it with a Raspberry Pi 3 Model B and a Pi camera. It utilizes OpenCV and some open source playing card recognition software (https://github.com/EdjeElectronics/OpenCV-Playing-Card-Detector)

Challenges I ran into

Challenges I ran into included how to recognize which cards belong to the player, how to handle the dealer's upside down card, and tracking reshuffles

Accomplishments that I'm proud of

Using OpenCV and refreshing my knowledge of python, while doing it all on a Raspberry Pi posed significant new hurdles that I'm proud to have attempted

What I learned

I learned more about OpenCV, and the Pi-Camera.

What's next for Pit Boss: The Raspberry-Pi Blackjack Helper

Pit Boss needs support for a few more things:

Support for the ""Split"" action

Support for multiple players

Support for multiple decks

and finally, a head mount in order to make Pit Boss portable

WARNING:

Most card counting devices are illegal to use in a casino, DO NOT use Pit Boss in a casino.

https://en.wikipedia.org/wiki/Card_counting#Devices
",,https://github.com/AdamMSteinberg/PitBoss,,"raspberry-pi, camera, python, opencv",Penn State,"","",AdamMSteinberg,AdamMSteinberg,,adamstein@comcast.net,Pennsylvania State University,0
HackPSU Overall - Tech,Pit Boss: The Raspberry-Pi Blackjack Helper,36,https://hackpsu-fall-2018.devpost.com/submissions/102266-pit-boss-the-raspberry-pi-blackjack-helper,"Inspiration

Pit Boss, named after the casino overseer who controls the various blackjack pits, was designed to help users make some money

What it does

Pit Boss helps you win at Blackjack by recognizing cards played, and using probability to recommend the action the player should take to maximize winnings

How I built it

I built it with a Raspberry Pi 3 Model B and a Pi camera. It utilizes OpenCV and some open source playing card recognition software (https://github.com/EdjeElectronics/OpenCV-Playing-Card-Detector)

Challenges I ran into

Challenges I ran into included how to recognize which cards belong to the player, how to handle the dealer's upside down card, and tracking reshuffles

Accomplishments that I'm proud of

Using OpenCV and refreshing my knowledge of python, while doing it all on a Raspberry Pi posed significant new hurdles that I'm proud to have attempted

What I learned

I learned more about OpenCV, and the Pi-Camera.

What's next for Pit Boss: The Raspberry-Pi Blackjack Helper

Pit Boss needs support for a few more things:

Support for the ""Split"" action

Support for multiple players

Support for multiple decks

and finally, a head mount in order to make Pit Boss portable

WARNING:

Most card counting devices are illegal to use in a casino, DO NOT use Pit Boss in a casino.

https://en.wikipedia.org/wiki/Card_counting#Devices
",,https://github.com/AdamMSteinberg/PitBoss,,"raspberry-pi, camera, python, opencv",Penn State,"","",AdamMSteinberg,AdamMSteinberg,,adamstein@comcast.net,Pennsylvania State University,0
HackPSU Overall - Tech,Behrend Blocks,79,https://hackpsu-fall-2018.devpost.com/submissions/102270-behrend-blocks,"Inspiration

In our brainstorming session we were trying find topics that we were all passionate about. We knew from the beginning the we were interested in doing a Social Welfare project. Knowing our skill sets and the challenges available, we wanted to create something that would educate children about physics which would increase awareness in STEM fields. We decided on creating a game which would allow players to place objects in positions that solve the task that is laid out for them. We then thought of different level ideas to make the game appeal to kids.

What it does

It is a browser game made in Unity which contains two levels: A more gravitational accurate stacking level where the limit is only your imagination and an orbital mechanics level where the player must move a falling meteor onto a platform by using blocks unaffected by gravity.

How we built it

We used Unity and C# which for the most part our programmers had never used before and our artists used Adobe Illustrator and Photoshop.

Challenges we ran into

Learning an entire game engine and a new programming language is quite the challenge! But we also ran into many design problems like implementing the main game mechanic of placing blocks into the level which was not completed until 2 A.M. today. We also ran into issues with turning gravity on and off, which allows players to build their structure with no forces acting upon them. Because of the way that we created the game, on three separate computers, we ran into some issues with scaling the levels and objects, which took some time to resolve.

Accomplishments that we're proud of...

We are very proud of what we were able to accomplish with this game, especially the main game mechanic and some of the unique ideas we thought of while designing the game. Specifically we are proud of the difference between our project one year ago, and our project today. Going into the competition, the number one thing that we wanted to do was get a finished project that accomplishes the basic parameters we set for the project. 

What we learned

We learned Unity and C# as well as skills important to programmers and software engineers like having multiple team members working a project at the same time using a repository and finding the solutions to difficult programming challenges. Our team is composed of a mixture of computer/software engineers and mechanical engineers. For the Mechanical Engineering students, the ability to get more familiar with syntax in C# and Unity was valuable. While both of the mechanical engineering students have used other programming languages in the past, they were able to observe the students more familiar with coding and help to make sure the physics were realistic.

What's next for Behrend Blocks

The team is definitely interested in continuing development on the project by adding new levels and game mechanics in the future, or perhaps developing the game in 3 dimensions.
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36355/zip_files/Build_2.0.zip,"unity, c#, adobe-illustrator, photoshop","The Pennsylvania State University Erie, The Behrend College","","",nxc5283,Nick,Corey,nxc5283@psu.edu,"Pennsylvania State University, Penn State Erie, Behrend",4,cwl11,cwl11,,cwl11@psu.edu,rwp5366,Ryan,Piccone,rwp5366@psu.edu,JacobUhrin,Jacob,Uhrin,jacob124578@yahoo.com,njm5637,Neale,Misquitta Jr.,njm5637@psu.edu
JPMC - Best Social Good Hack,Behrend Blocks,79,https://hackpsu-fall-2018.devpost.com/submissions/102270-behrend-blocks,"Inspiration

In our brainstorming session we were trying find topics that we were all passionate about. We knew from the beginning the we were interested in doing a Social Welfare project. Knowing our skill sets and the challenges available, we wanted to create something that would educate children about physics which would increase awareness in STEM fields. We decided on creating a game which would allow players to place objects in positions that solve the task that is laid out for them. We then thought of different level ideas to make the game appeal to kids.

What it does

It is a browser game made in Unity which contains two levels: A more gravitational accurate stacking level where the limit is only your imagination and an orbital mechanics level where the player must move a falling meteor onto a platform by using blocks unaffected by gravity.

How we built it

We used Unity and C# which for the most part our programmers had never used before and our artists used Adobe Illustrator and Photoshop.

Challenges we ran into

Learning an entire game engine and a new programming language is quite the challenge! But we also ran into many design problems like implementing the main game mechanic of placing blocks into the level which was not completed until 2 A.M. today. We also ran into issues with turning gravity on and off, which allows players to build their structure with no forces acting upon them. Because of the way that we created the game, on three separate computers, we ran into some issues with scaling the levels and objects, which took some time to resolve.

Accomplishments that we're proud of...

We are very proud of what we were able to accomplish with this game, especially the main game mechanic and some of the unique ideas we thought of while designing the game. Specifically we are proud of the difference between our project one year ago, and our project today. Going into the competition, the number one thing that we wanted to do was get a finished project that accomplishes the basic parameters we set for the project. 

What we learned

We learned Unity and C# as well as skills important to programmers and software engineers like having multiple team members working a project at the same time using a repository and finding the solutions to difficult programming challenges. Our team is composed of a mixture of computer/software engineers and mechanical engineers. For the Mechanical Engineering students, the ability to get more familiar with syntax in C# and Unity was valuable. While both of the mechanical engineering students have used other programming languages in the past, they were able to observe the students more familiar with coding and help to make sure the physics were realistic.

What's next for Behrend Blocks

The team is definitely interested in continuing development on the project by adding new levels and game mechanics in the future, or perhaps developing the game in 3 dimensions.
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36355/zip_files/Build_2.0.zip,"unity, c#, adobe-illustrator, photoshop","The Pennsylvania State University Erie, The Behrend College","","",nxc5283,Nick,Corey,nxc5283@psu.edu,"Pennsylvania State University, Penn State Erie, Behrend",4,cwl11,cwl11,,cwl11@psu.edu,rwp5366,Ryan,Piccone,rwp5366@psu.edu,JacobUhrin,Jacob,Uhrin,jacob124578@yahoo.com,njm5637,Neale,Misquitta Jr.,njm5637@psu.edu
Capital One - Best Financial Hack,Capital Connect,54,https://hackpsu-fall-2018.devpost.com/submissions/102283-capital-connect,"Inspiration As young entrepreneurs, we have the utmost respect for those who have an promising business idea and bring it to fruition.  That said, we have firsthand experience in the difficulty of locating funding for our own promising ideas.

What it does

Capital Connect is a unique way to allow Capital One customers to invest their accumulated rewards points in a promising startup in hopes of their success. By doing so, the investor becomes a shareholder in their startup company of choice, backed by Capital One's own business experts and analysts. The platform makes it easy to authenticate through Capital One's API, and authorize the transaction. The platform also provides a reputation meter whose value is determined by the expert analysis of Capital One's own professionals.

How we built it

We used Android Studio to create the app. We used Dreamweaver to create the website.

Challenges we ran into

On multiple occasions, we ran into technical problems that seemed to arise out of nowhere. For example, Android Studio would through errors that were exceptionally difficult to find, and the files for our website were corrupted twice. 

Accomplishments that we're proud of

What we learned

We learned to work effectively as a team to overcome our own challenges.

What's next for Capital Connect

We hope to fully integrate Capital One's payment and authentication API into the app to give the user a complete feeling of security.
",,https://github.com/sjh5888/PSU-2018-Fall-HackaThon.git,https://s3.amazonaws.com/challengepost/zip_files/production/36280/zip_files/Capital_Connect.zip,"android-studio, java, xml, dreamweaver, html5",Penn State,"","",Stevenhansen,,,stevenhansen451@gmail.com,Pennsylvania State University,1,smschuler7,Seth,Schuler,smschuler7@gmail.com
HackPSU Overall - Design,Omnidirectional Motorized Shoes,64,https://hackpsu-fall-2018.devpost.com/submissions/102286-omnidirectional-motorized-shoes,"Inspiration

Right now there isn't a viable solution for moving around in Virtual Reality, in a natural way. The Motorized Skates seek to fix that problem by allowing you to walk in a limited physical space to explore an infinite virtual space. 

What it does

The concept behind the skate is that there would be a set of sensors to track the user in the physical space. When they step forward, the skates will track where they are moving to and when the foot presses down on the ground, the motors will activate and pilot the user backwards toward their starting position.

How I built it

The current frame is built out of a vex frame and a set of 4 Omnidirectional wheels.The electrical components are on a breadboard and connect an Arduino to an IMU.

Challenges I ran into

I was planning on using a motor controller I had brought from home to safely control the motors, but I found that I didn't have the correct kind of wires to attach the motors. So I opted to just work on using the IMU in this prototype.

Accomplishments that I'm proud of

I'm proud that I was able to solder the IMU correctly and that I was able to achieve compass like functionality for the IMU based off the 3 axis Magnetometer.

What I learned

I learned that how to do some basic things inside of the Arduino editor and how to properly shift focus on a project when a piece doesn't function correctly.

What's next for Omnidirectional Motorized Shoes

I'd like to continue working on the device in my spare time. Maybe find a team of people to help me with some of the concepts I'm not familiar with. I also want to gather the necessary parts, get the motor controller attached to the device, and start writing the movement algorithm.
",,https://github.com/mrhatkat/LocomotionIMUCode,https://s3.amazonaws.com/challengepost/zip_files/production/36282/zip_files/lsm9ds1Modified.txt,"arduino, vex",The Pennsylvania State University,"","",mrhatkat,mrhatkat,,ajh5849@psu.edu,Pennsylvania State University,0
Best use of Google Cloud Platform,maintainFlow,75,https://hackpsu-fall-2018.devpost.com/submissions/102290-maintainflow,"Inspiration

From our personal experience as both renters & owners of property we know how cumbersome 

What it does

Simplifies maintenance issue reporting with an intelligent chatbot assistant (Argo) to facilitate transparent & easy sms/chat based exchanges. Next time you have a broken pipe, the heater is on the Fritz, or any other issue just text Argo. 

How we built it

The chatbot was built with DialogFlow, which is accessed through the Twilio SMS service which is written in python. The data from this is stored on an SQL database which is hosted on a google cloud instance along with the google vision API

Challenges we ran into

Twilio is built mainly for javascript & when we tried to build using their node.js starter we ran into a major roadblock & had to switch to python. Otherwise the major hurdles were just connecting all the pieces together.

Accomplishments that we're proud of

Not only connecting the chat bot to our business logic but doing so through Twilio's SMS API for simple chat based interactions. To take it a step further we added a computer vision layer to analyse and catalogue images sent to the end point 

What we learned

That dialogflow is a massively powerful tool for quickly assembling & deploying chat bots. 

What's next for maintainFlow

Stay Tuned ;-)
",,,,"dialog-flow, python, gcp, twilio, machine-learning","Penn State University, NYU, Rutgers","",Dell XPS,zphill15,Zachary,Phillips,zap7@scarletmail.rutgers.edu,New York University,1,ss11341,siddharth,singh,ss11341@nyu.edu
Nittany AI Alliance - AI Challenge,maintainFlow,75,https://hackpsu-fall-2018.devpost.com/submissions/102290-maintainflow,"Inspiration

From our personal experience as both renters & owners of property we know how cumbersome 

What it does

Simplifies maintenance issue reporting with an intelligent chatbot assistant (Argo) to facilitate transparent & easy sms/chat based exchanges. Next time you have a broken pipe, the heater is on the Fritz, or any other issue just text Argo. 

How we built it

The chatbot was built with DialogFlow, which is accessed through the Twilio SMS service which is written in python. The data from this is stored on an SQL database which is hosted on a google cloud instance along with the google vision API

Challenges we ran into

Twilio is built mainly for javascript & when we tried to build using their node.js starter we ran into a major roadblock & had to switch to python. Otherwise the major hurdles were just connecting all the pieces together.

Accomplishments that we're proud of

Not only connecting the chat bot to our business logic but doing so through Twilio's SMS API for simple chat based interactions. To take it a step further we added a computer vision layer to analyse and catalogue images sent to the end point 

What we learned

That dialogflow is a massively powerful tool for quickly assembling & deploying chat bots. 

What's next for maintainFlow

Stay Tuned ;-)
",,,,"dialog-flow, python, gcp, twilio, machine-learning","Penn State University, NYU, Rutgers","",Dell XPS,zphill15,Zachary,Phillips,zap7@scarletmail.rutgers.edu,New York University,1,ss11341,siddharth,singh,ss11341@nyu.edu
HackPSU Overall - Tech,maintainFlow,75,https://hackpsu-fall-2018.devpost.com/submissions/102290-maintainflow,"Inspiration

From our personal experience as both renters & owners of property we know how cumbersome 

What it does

Simplifies maintenance issue reporting with an intelligent chatbot assistant (Argo) to facilitate transparent & easy sms/chat based exchanges. Next time you have a broken pipe, the heater is on the Fritz, or any other issue just text Argo. 

How we built it

The chatbot was built with DialogFlow, which is accessed through the Twilio SMS service which is written in python. The data from this is stored on an SQL database which is hosted on a google cloud instance along with the google vision API

Challenges we ran into

Twilio is built mainly for javascript & when we tried to build using their node.js starter we ran into a major roadblock & had to switch to python. Otherwise the major hurdles were just connecting all the pieces together.

Accomplishments that we're proud of

Not only connecting the chat bot to our business logic but doing so through Twilio's SMS API for simple chat based interactions. To take it a step further we added a computer vision layer to analyse and catalogue images sent to the end point 

What we learned

That dialogflow is a massively powerful tool for quickly assembling & deploying chat bots. 

What's next for maintainFlow

Stay Tuned ;-)
",,,,"dialog-flow, python, gcp, twilio, machine-learning","Penn State University, NYU, Rutgers","",Dell XPS,zphill15,Zachary,Phillips,zap7@scarletmail.rutgers.edu,New York University,1,ss11341,siddharth,singh,ss11341@nyu.edu
Capital One - Best Financial Hack,maintainFlow,75,https://hackpsu-fall-2018.devpost.com/submissions/102290-maintainflow,"Inspiration

From our personal experience as both renters & owners of property we know how cumbersome 

What it does

Simplifies maintenance issue reporting with an intelligent chatbot assistant (Argo) to facilitate transparent & easy sms/chat based exchanges. Next time you have a broken pipe, the heater is on the Fritz, or any other issue just text Argo. 

How we built it

The chatbot was built with DialogFlow, which is accessed through the Twilio SMS service which is written in python. The data from this is stored on an SQL database which is hosted on a google cloud instance along with the google vision API

Challenges we ran into

Twilio is built mainly for javascript & when we tried to build using their node.js starter we ran into a major roadblock & had to switch to python. Otherwise the major hurdles were just connecting all the pieces together.

Accomplishments that we're proud of

Not only connecting the chat bot to our business logic but doing so through Twilio's SMS API for simple chat based interactions. To take it a step further we added a computer vision layer to analyse and catalogue images sent to the end point 

What we learned

That dialogflow is a massively powerful tool for quickly assembling & deploying chat bots. 

What's next for maintainFlow

Stay Tuned ;-)
",,,,"dialog-flow, python, gcp, twilio, machine-learning","Penn State University, NYU, Rutgers","",Dell XPS,zphill15,Zachary,Phillips,zap7@scarletmail.rutgers.edu,New York University,1,ss11341,siddharth,singh,ss11341@nyu.edu
Best use of Algolia,CourseCat: A smarter course catalog,66,https://hackpsu-fall-2018.devpost.com/submissions/102291-coursecat-a-smarter-course-catalog,"Inspiration

Each semester Penn State (and many other universities) offer thousands of courses to their students. Many times students have a variety of courses that they can choose from but no easy way to search through them. We wanted to provide students a smarter and more robust course search engine to help them find courses they'll enjoy. 

How we built it

Our search engine is built on Algolia, which allows users to efficiently search through course data that we've collected from online listings. We also used natural language processing to analyze course descriptions and find similar courses. This lets us recommend courses to users based on their searches. 
",,http://CourseCat.net,,"python, algolia, javascript, html",Penn State University,"Domain.com,Algolia","",mzh5263,Michael,Hoffman,mzh5263@psu.edu,Pennsylvania State University,2,aqa5547,Akhil,Akkiraju,akkirajuakhil123@gmail.com,jkv5,Jay,Vyas,jkv5@psu.edu
Best Domain Name from Domain.com,CourseCat: A smarter course catalog,66,https://hackpsu-fall-2018.devpost.com/submissions/102291-coursecat-a-smarter-course-catalog,"Inspiration

Each semester Penn State (and many other universities) offer thousands of courses to their students. Many times students have a variety of courses that they can choose from but no easy way to search through them. We wanted to provide students a smarter and more robust course search engine to help them find courses they'll enjoy. 

How we built it

Our search engine is built on Algolia, which allows users to efficiently search through course data that we've collected from online listings. We also used natural language processing to analyze course descriptions and find similar courses. This lets us recommend courses to users based on their searches. 
",,http://CourseCat.net,,"python, algolia, javascript, html",Penn State University,"Domain.com,Algolia","",mzh5263,Michael,Hoffman,mzh5263@psu.edu,Pennsylvania State University,2,aqa5547,Akhil,Akkiraju,akkirajuakhil123@gmail.com,jkv5,Jay,Vyas,jkv5@psu.edu
Nittany AI Alliance - AI Challenge,CourseCat: A smarter course catalog,66,https://hackpsu-fall-2018.devpost.com/submissions/102291-coursecat-a-smarter-course-catalog,"Inspiration

Each semester Penn State (and many other universities) offer thousands of courses to their students. Many times students have a variety of courses that they can choose from but no easy way to search through them. We wanted to provide students a smarter and more robust course search engine to help them find courses they'll enjoy. 

How we built it

Our search engine is built on Algolia, which allows users to efficiently search through course data that we've collected from online listings. We also used natural language processing to analyze course descriptions and find similar courses. This lets us recommend courses to users based on their searches. 
",,http://CourseCat.net,,"python, algolia, javascript, html",Penn State University,"Domain.com,Algolia","",mzh5263,Michael,Hoffman,mzh5263@psu.edu,Pennsylvania State University,2,aqa5547,Akhil,Akkiraju,akkirajuakhil123@gmail.com,jkv5,Jay,Vyas,jkv5@psu.edu
HackPSU Overall - Tech,CourseCat: A smarter course catalog,66,https://hackpsu-fall-2018.devpost.com/submissions/102291-coursecat-a-smarter-course-catalog,"Inspiration

Each semester Penn State (and many other universities) offer thousands of courses to their students. Many times students have a variety of courses that they can choose from but no easy way to search through them. We wanted to provide students a smarter and more robust course search engine to help them find courses they'll enjoy. 

How we built it

Our search engine is built on Algolia, which allows users to efficiently search through course data that we've collected from online listings. We also used natural language processing to analyze course descriptions and find similar courses. This lets us recommend courses to users based on their searches. 
",,http://CourseCat.net,,"python, algolia, javascript, html",Penn State University,"Domain.com,Algolia","",mzh5263,Michael,Hoffman,mzh5263@psu.edu,Pennsylvania State University,2,aqa5547,Akhil,Akkiraju,akkirajuakhil123@gmail.com,jkv5,Jay,Vyas,jkv5@psu.edu
Accuweather Challenge,A-weatheR,5,https://hackpsu-fall-2018.devpost.com/submissions/102297-a-weather,"A-weatheR

iOS Application using AccuWeather API for HACKPSU Fall 2018.
Augmented Reality integrated for observing the weather condition directly from indoor. 
Also, image tracking (interesting feature) is also integrated. 

Authors:


Zheng (Wilson) Zhang
Yao (Luke) Yao
Xixian (Max) Jiang


Target Audience:

We developed this app mainly for those patients, elders and disables who are unable to move easily to go outside, with our app, they can comprehend and experience the outside weather when they're alone. 
Also, we also have a lively cat integrated inside, so they can feel the warmth of those cute animals. 

Features:


Details about real-time weather condition. 
Automatically obtain user location and retrieve local weather data. 
Conveniently observing the weather condition via Augmented Reality indoors.
Give the user a chance to experience and interact with various weathers. 
High resolution, cute cat integrated and can be directly projected on your hands (demo card needed). 
All data were collected via AccuWeather API. 


Outlook:


Density graph of future weather prediction hourly. 
More detailed models and animations will be implemented and projected in AR mode. 
More animals will join us and we can even interact with them!


FYI:

We changed the name from ""Weather alARm"" to ""A-weatheR app"" after completed it. 
",,https://github.com/SecantZhang/A-weatheR,,"swift, ruby",Pennsylvania State University,"","",SecantZhang,Secant,,zxz147@psu.edu,Pennsylvania State University,1,y58915,Yao,Yao,yjy5094@psu.edu
Best use of Google Cloud Platform,Picture Translator,51,https://hackpsu-fall-2018.devpost.com/submissions/102308-picture-translator,"Inspiration

As a new comer, it would be hard to read another language in pictures online.

What it does

Use OCR to recognize the words in the pictures and translate them into the language we want.

How we built it

We use google api from google cloud platform.

Challenges we ran into

'Best use of google platform'

Accomplishments that we're proud of

none

What we learned

The use of google api

What's next for Picture Translator

audio recognition
",https://www.youtube.com/watch?v=BIBHlt_b1ZE&feature=youtu.be,,https://s3.amazonaws.com/challengepost/zip_files/production/36299/zip_files/google_cloud_ver2.py.zip,"google-cloud-vision, google-cloud-translate",penn state,"","",LegendaryBear,Yixin,Xiong,ykx5070@psu.edu,Pennsylvania State University,2,sty1234567,,,tqs5537@qq.com,ybl5226,Yifeng,Leng,ybl5226@psu.edu
Accuweather Challenge,Natural Disaster Bot (NDB),63,https://hackpsu-fall-2018.devpost.com/submissions/102312-natural-disaster-bot-ndb,"Inspiration

Due to the recent recurring events of natural disasters such as the Manghut Typhoon and wildfires in california, we decided to contribute to the rescue missions with machine learning.

What it does


By using chatbot as an interface, it collects critical informations from the users and assist them with suggestions. 
We use Kmean Clustering algorithm to find multiple optimized coordinates to send mass transportation vehicles and visualizes it on an admin dashboard. 
The users can also query for the recent weather to check if there is going to be an alerts.


How we built it

We developed a chat bot using reactjs and google cloud platform - natural language and used accuweather APIs to get weather data and alarms. We store the data on sqlite3 with a backend server running ruby on rails and nodejs. Machine learning model, Kmean Clustering algorithm, is built with sklearn in python.

Challenges we ran into

We had some issues integrating the various systems. Making the UI simple on the frontend with complex data analysis, processing and communicating with various platforms on the backend was very challenging.

Accomplishments that we're proud of

The complex structure we built for this project.

What we learned


The experiences we gain from teamwork. 
The usage of Google Cloud Platform and Accuweather's API. 
Applications of machine learning models.
The experience of building a production application which can help so many people.


What's next for Natural Disaster Bot (NDB)


Improve our machine learning model and add more features for our relief suggestion tools. 
Make it more scalable and accessible.

",,https://github.com/NDLDisneyChatbot,,"google-cloud, accuweather, machine-learning, python, natural-language-processing, node.js, html5, ruby-on-rails, javascript, react, google-maps",The Pennsylvania State University,Google Cloud Platform,"",kevinkuo52,Kevin,Kuo,kevinkuo15@gmail.com,Pennsylvania State University,4,mycraftmw,Tongyu,Yue,mycraftmw@gmail.com,vishwas1020,Vishwa,Shankar,vishwas1020@gmail.com,asdeotale,Amey,Deotale,asdeotale@gmail.com,nikhilg777,Nikhil,Gumidelli,nikhil.g777@gmail.com
Best use of Google Cloud Platform,Natural Disaster Bot (NDB),63,https://hackpsu-fall-2018.devpost.com/submissions/102312-natural-disaster-bot-ndb,"Inspiration

Due to the recent recurring events of natural disasters such as the Manghut Typhoon and wildfires in california, we decided to contribute to the rescue missions with machine learning.

What it does


By using chatbot as an interface, it collects critical informations from the users and assist them with suggestions. 
We use Kmean Clustering algorithm to find multiple optimized coordinates to send mass transportation vehicles and visualizes it on an admin dashboard. 
The users can also query for the recent weather to check if there is going to be an alerts.


How we built it

We developed a chat bot using reactjs and google cloud platform - natural language and used accuweather APIs to get weather data and alarms. We store the data on sqlite3 with a backend server running ruby on rails and nodejs. Machine learning model, Kmean Clustering algorithm, is built with sklearn in python.

Challenges we ran into

We had some issues integrating the various systems. Making the UI simple on the frontend with complex data analysis, processing and communicating with various platforms on the backend was very challenging.

Accomplishments that we're proud of

The complex structure we built for this project.

What we learned


The experiences we gain from teamwork. 
The usage of Google Cloud Platform and Accuweather's API. 
Applications of machine learning models.
The experience of building a production application which can help so many people.


What's next for Natural Disaster Bot (NDB)


Improve our machine learning model and add more features for our relief suggestion tools. 
Make it more scalable and accessible.

",,https://github.com/NDLDisneyChatbot,,"google-cloud, accuweather, machine-learning, python, natural-language-processing, node.js, html5, ruby-on-rails, javascript, react, google-maps",The Pennsylvania State University,Google Cloud Platform,"",kevinkuo52,Kevin,Kuo,kevinkuo15@gmail.com,Pennsylvania State University,4,mycraftmw,Tongyu,Yue,mycraftmw@gmail.com,vishwas1020,Vishwa,Shankar,vishwas1020@gmail.com,asdeotale,Amey,Deotale,asdeotale@gmail.com,nikhilg777,Nikhil,Gumidelli,nikhil.g777@gmail.com
Booz Allen Hamilton - Best Machine Learning Hack,Natural Disaster Bot (NDB),63,https://hackpsu-fall-2018.devpost.com/submissions/102312-natural-disaster-bot-ndb,"Inspiration

Due to the recent recurring events of natural disasters such as the Manghut Typhoon and wildfires in california, we decided to contribute to the rescue missions with machine learning.

What it does


By using chatbot as an interface, it collects critical informations from the users and assist them with suggestions. 
We use Kmean Clustering algorithm to find multiple optimized coordinates to send mass transportation vehicles and visualizes it on an admin dashboard. 
The users can also query for the recent weather to check if there is going to be an alerts.


How we built it

We developed a chat bot using reactjs and google cloud platform - natural language and used accuweather APIs to get weather data and alarms. We store the data on sqlite3 with a backend server running ruby on rails and nodejs. Machine learning model, Kmean Clustering algorithm, is built with sklearn in python.

Challenges we ran into

We had some issues integrating the various systems. Making the UI simple on the frontend with complex data analysis, processing and communicating with various platforms on the backend was very challenging.

Accomplishments that we're proud of

The complex structure we built for this project.

What we learned


The experiences we gain from teamwork. 
The usage of Google Cloud Platform and Accuweather's API. 
Applications of machine learning models.
The experience of building a production application which can help so many people.


What's next for Natural Disaster Bot (NDB)


Improve our machine learning model and add more features for our relief suggestion tools. 
Make it more scalable and accessible.

",,https://github.com/NDLDisneyChatbot,,"google-cloud, accuweather, machine-learning, python, natural-language-processing, node.js, html5, ruby-on-rails, javascript, react, google-maps",The Pennsylvania State University,Google Cloud Platform,"",kevinkuo52,Kevin,Kuo,kevinkuo15@gmail.com,Pennsylvania State University,4,mycraftmw,Tongyu,Yue,mycraftmw@gmail.com,vishwas1020,Vishwa,Shankar,vishwas1020@gmail.com,asdeotale,Amey,Deotale,asdeotale@gmail.com,nikhilg777,Nikhil,Gumidelli,nikhil.g777@gmail.com
Nittany AI Alliance - AI Challenge,Natural Disaster Bot (NDB),63,https://hackpsu-fall-2018.devpost.com/submissions/102312-natural-disaster-bot-ndb,"Inspiration

Due to the recent recurring events of natural disasters such as the Manghut Typhoon and wildfires in california, we decided to contribute to the rescue missions with machine learning.

What it does


By using chatbot as an interface, it collects critical informations from the users and assist them with suggestions. 
We use Kmean Clustering algorithm to find multiple optimized coordinates to send mass transportation vehicles and visualizes it on an admin dashboard. 
The users can also query for the recent weather to check if there is going to be an alerts.


How we built it

We developed a chat bot using reactjs and google cloud platform - natural language and used accuweather APIs to get weather data and alarms. We store the data on sqlite3 with a backend server running ruby on rails and nodejs. Machine learning model, Kmean Clustering algorithm, is built with sklearn in python.

Challenges we ran into

We had some issues integrating the various systems. Making the UI simple on the frontend with complex data analysis, processing and communicating with various platforms on the backend was very challenging.

Accomplishments that we're proud of

The complex structure we built for this project.

What we learned


The experiences we gain from teamwork. 
The usage of Google Cloud Platform and Accuweather's API. 
Applications of machine learning models.
The experience of building a production application which can help so many people.


What's next for Natural Disaster Bot (NDB)


Improve our machine learning model and add more features for our relief suggestion tools. 
Make it more scalable and accessible.

",,https://github.com/NDLDisneyChatbot,,"google-cloud, accuweather, machine-learning, python, natural-language-processing, node.js, html5, ruby-on-rails, javascript, react, google-maps",The Pennsylvania State University,Google Cloud Platform,"",kevinkuo52,Kevin,Kuo,kevinkuo15@gmail.com,Pennsylvania State University,4,mycraftmw,Tongyu,Yue,mycraftmw@gmail.com,vishwas1020,Vishwa,Shankar,vishwas1020@gmail.com,asdeotale,Amey,Deotale,asdeotale@gmail.com,nikhilg777,Nikhil,Gumidelli,nikhil.g777@gmail.com
HackPSU Overall - Tech,Natural Disaster Bot (NDB),63,https://hackpsu-fall-2018.devpost.com/submissions/102312-natural-disaster-bot-ndb,"Inspiration

Due to the recent recurring events of natural disasters such as the Manghut Typhoon and wildfires in california, we decided to contribute to the rescue missions with machine learning.

What it does


By using chatbot as an interface, it collects critical informations from the users and assist them with suggestions. 
We use Kmean Clustering algorithm to find multiple optimized coordinates to send mass transportation vehicles and visualizes it on an admin dashboard. 
The users can also query for the recent weather to check if there is going to be an alerts.


How we built it

We developed a chat bot using reactjs and google cloud platform - natural language and used accuweather APIs to get weather data and alarms. We store the data on sqlite3 with a backend server running ruby on rails and nodejs. Machine learning model, Kmean Clustering algorithm, is built with sklearn in python.

Challenges we ran into

We had some issues integrating the various systems. Making the UI simple on the frontend with complex data analysis, processing and communicating with various platforms on the backend was very challenging.

Accomplishments that we're proud of

The complex structure we built for this project.

What we learned


The experiences we gain from teamwork. 
The usage of Google Cloud Platform and Accuweather's API. 
Applications of machine learning models.
The experience of building a production application which can help so many people.


What's next for Natural Disaster Bot (NDB)


Improve our machine learning model and add more features for our relief suggestion tools. 
Make it more scalable and accessible.

",,https://github.com/NDLDisneyChatbot,,"google-cloud, accuweather, machine-learning, python, natural-language-processing, node.js, html5, ruby-on-rails, javascript, react, google-maps",The Pennsylvania State University,Google Cloud Platform,"",kevinkuo52,Kevin,Kuo,kevinkuo15@gmail.com,Pennsylvania State University,4,mycraftmw,Tongyu,Yue,mycraftmw@gmail.com,vishwas1020,Vishwa,Shankar,vishwas1020@gmail.com,asdeotale,Amey,Deotale,asdeotale@gmail.com,nikhilg777,Nikhil,Gumidelli,nikhil.g777@gmail.com
Best Social Good Hack from Fidelity Weekly Challenge,Natural Disaster Bot (NDB),63,https://hackpsu-fall-2018.devpost.com/submissions/102312-natural-disaster-bot-ndb,"Inspiration

Due to the recent recurring events of natural disasters such as the Manghut Typhoon and wildfires in california, we decided to contribute to the rescue missions with machine learning.

What it does


By using chatbot as an interface, it collects critical informations from the users and assist them with suggestions. 
We use Kmean Clustering algorithm to find multiple optimized coordinates to send mass transportation vehicles and visualizes it on an admin dashboard. 
The users can also query for the recent weather to check if there is going to be an alerts.


How we built it

We developed a chat bot using reactjs and google cloud platform - natural language and used accuweather APIs to get weather data and alarms. We store the data on sqlite3 with a backend server running ruby on rails and nodejs. Machine learning model, Kmean Clustering algorithm, is built with sklearn in python.

Challenges we ran into

We had some issues integrating the various systems. Making the UI simple on the frontend with complex data analysis, processing and communicating with various platforms on the backend was very challenging.

Accomplishments that we're proud of

The complex structure we built for this project.

What we learned


The experiences we gain from teamwork. 
The usage of Google Cloud Platform and Accuweather's API. 
Applications of machine learning models.
The experience of building a production application which can help so many people.


What's next for Natural Disaster Bot (NDB)


Improve our machine learning model and add more features for our relief suggestion tools. 
Make it more scalable and accessible.

",,https://github.com/NDLDisneyChatbot,,"google-cloud, accuweather, machine-learning, python, natural-language-processing, node.js, html5, ruby-on-rails, javascript, react, google-maps",The Pennsylvania State University,Google Cloud Platform,"",kevinkuo52,Kevin,Kuo,kevinkuo15@gmail.com,Pennsylvania State University,4,mycraftmw,Tongyu,Yue,mycraftmw@gmail.com,vishwas1020,Vishwa,Shankar,vishwas1020@gmail.com,asdeotale,Amey,Deotale,asdeotale@gmail.com,nikhilg777,Nikhil,Gumidelli,nikhil.g777@gmail.com
JPMC - Best Social Good Hack,Natural Disaster Bot (NDB),63,https://hackpsu-fall-2018.devpost.com/submissions/102312-natural-disaster-bot-ndb,"Inspiration

Due to the recent recurring events of natural disasters such as the Manghut Typhoon and wildfires in california, we decided to contribute to the rescue missions with machine learning.

What it does


By using chatbot as an interface, it collects critical informations from the users and assist them with suggestions. 
We use Kmean Clustering algorithm to find multiple optimized coordinates to send mass transportation vehicles and visualizes it on an admin dashboard. 
The users can also query for the recent weather to check if there is going to be an alerts.


How we built it

We developed a chat bot using reactjs and google cloud platform - natural language and used accuweather APIs to get weather data and alarms. We store the data on sqlite3 with a backend server running ruby on rails and nodejs. Machine learning model, Kmean Clustering algorithm, is built with sklearn in python.

Challenges we ran into

We had some issues integrating the various systems. Making the UI simple on the frontend with complex data analysis, processing and communicating with various platforms on the backend was very challenging.

Accomplishments that we're proud of

The complex structure we built for this project.

What we learned


The experiences we gain from teamwork. 
The usage of Google Cloud Platform and Accuweather's API. 
Applications of machine learning models.
The experience of building a production application which can help so many people.


What's next for Natural Disaster Bot (NDB)


Improve our machine learning model and add more features for our relief suggestion tools. 
Make it more scalable and accessible.

",,https://github.com/NDLDisneyChatbot,,"google-cloud, accuweather, machine-learning, python, natural-language-processing, node.js, html5, ruby-on-rails, javascript, react, google-maps",The Pennsylvania State University,Google Cloud Platform,"",kevinkuo52,Kevin,Kuo,kevinkuo15@gmail.com,Pennsylvania State University,4,mycraftmw,Tongyu,Yue,mycraftmw@gmail.com,vishwas1020,Vishwa,Shankar,vishwas1020@gmail.com,asdeotale,Amey,Deotale,asdeotale@gmail.com,nikhilg777,Nikhil,Gumidelli,nikhil.g777@gmail.com
JPMC - Best Social Good Hack,Kidnopoly,13,https://hackpsu-fall-2018.devpost.com/submissions/102316-kidnopoly,"Inspiration

Monopoly

What it does

Help Kids Learn Computer Science 

How I built it

Java, SQL Databases, HTML and CSS

Challenges I ran into

The demand for computer science graduates will continue to grow in the US over the next five years, vastly outpacing the supply of Computer Science grads. Kidnopoly will help introduce kids to computer science and develope with some algorithmic thinking. This game will also experienced by a group of kids working together and have a competitive element for them to compete in real time against other teams.

Accomplishments that I'm proud of

What I learned

What's next for Kidnopoly
",,https://github.com/chenzhao0613/Kidnopoly,,game,Pennsylvania State University,Domain.com,"",chenzhao0613656,Zhao,Chen,chenzhao0613@gmail.com,"",0
Best use of Clarifai’s API Weekly Challenge,Image 2 Haiku,37,https://hackpsu-fall-2018.devpost.com/submissions/102337-image-2-haiku,"Inspiration

The inspiration from this project came from an introduction keynote at an MIT hackathon, talking about improving the human condition with technology. 

What it does

The Image 2 Haiku website allows the user to upload an image to the website and submit it for analysis. The website then submits the image to multiple APIs including the Google Cloud Platform and Clarifai to generate a list of words describing it, analyze the weather in the location the image was taken, and analyze the mood and emotion of the image. These three factors are then brought together and utilized to generate a haiku that reflects the subject, weather, and mood of the image. As they say, ""a picture is worth a thousand words.""

How we built it

We built it using more than four different online APIs as well as the Python Flask library and PIL image analysis library. Each person took responsibility for one distinct API and became an expert in it, implementing it themselves and allowing us to come together at the end to pull them together into one unified program.

Challenges we ran into

We ran into some challenges implementing various APIs because of issues installing and utilizing them. However, working together as a team, we managed to overcome those difficulties and implement them.

Accomplishments that we're proud of

We were able to complete over 4 of the challenges offered with our application, including various weather, image recognition, and social good challenges. We also did not know each other before this hackathon, so we are proud of our ability to work as a team and develop an advanced product together.

What we learned

We learned how to use iterative design as well as work together as a team to produce a major product. We learned valuable teamwork skills and had frequent meeting to discuss both our progress and what still needed to be done, as well as determine whether anyone needed help. Overall, very valuable teamwork and development skills were gained from this.

What's next for Image 2 Haiku

If we have the chance to work more on this project, we had thrown around different ideas including integrating the Snapchat API to allow this to be directly used from Snapchat, implementing a refresh button to generate a fresh new poem without having to refresh, and improving the user frontend even more.
",,https://image2haiku.com,,"python, flask, gcp, clarifai, merriam-webster-dictionary, accuweather, pil",Pennsylvania State University,"Domain.com,Google Cloud Platform,Clarifai","",mikexcao,Michael,Cao,mike.x.cao@gmail.com,Pennsylvania State University,2,sophiabeyda,Sophia,Beyda,sophiabeyda@gmail.com,Pandaboi3010,Sriparno,Majumdar,szm6174@psu.edu
Best Domain Name from Domain.com,Image 2 Haiku,37,https://hackpsu-fall-2018.devpost.com/submissions/102337-image-2-haiku,"Inspiration

The inspiration from this project came from an introduction keynote at an MIT hackathon, talking about improving the human condition with technology. 

What it does

The Image 2 Haiku website allows the user to upload an image to the website and submit it for analysis. The website then submits the image to multiple APIs including the Google Cloud Platform and Clarifai to generate a list of words describing it, analyze the weather in the location the image was taken, and analyze the mood and emotion of the image. These three factors are then brought together and utilized to generate a haiku that reflects the subject, weather, and mood of the image. As they say, ""a picture is worth a thousand words.""

How we built it

We built it using more than four different online APIs as well as the Python Flask library and PIL image analysis library. Each person took responsibility for one distinct API and became an expert in it, implementing it themselves and allowing us to come together at the end to pull them together into one unified program.

Challenges we ran into

We ran into some challenges implementing various APIs because of issues installing and utilizing them. However, working together as a team, we managed to overcome those difficulties and implement them.

Accomplishments that we're proud of

We were able to complete over 4 of the challenges offered with our application, including various weather, image recognition, and social good challenges. We also did not know each other before this hackathon, so we are proud of our ability to work as a team and develop an advanced product together.

What we learned

We learned how to use iterative design as well as work together as a team to produce a major product. We learned valuable teamwork skills and had frequent meeting to discuss both our progress and what still needed to be done, as well as determine whether anyone needed help. Overall, very valuable teamwork and development skills were gained from this.

What's next for Image 2 Haiku

If we have the chance to work more on this project, we had thrown around different ideas including integrating the Snapchat API to allow this to be directly used from Snapchat, implementing a refresh button to generate a fresh new poem without having to refresh, and improving the user frontend even more.
",,https://image2haiku.com,,"python, flask, gcp, clarifai, merriam-webster-dictionary, accuweather, pil",Pennsylvania State University,"Domain.com,Google Cloud Platform,Clarifai","",mikexcao,Michael,Cao,mike.x.cao@gmail.com,Pennsylvania State University,2,sophiabeyda,Sophia,Beyda,sophiabeyda@gmail.com,Pandaboi3010,Sriparno,Majumdar,szm6174@psu.edu
Accuweather Challenge,Image 2 Haiku,37,https://hackpsu-fall-2018.devpost.com/submissions/102337-image-2-haiku,"Inspiration

The inspiration from this project came from an introduction keynote at an MIT hackathon, talking about improving the human condition with technology. 

What it does

The Image 2 Haiku website allows the user to upload an image to the website and submit it for analysis. The website then submits the image to multiple APIs including the Google Cloud Platform and Clarifai to generate a list of words describing it, analyze the weather in the location the image was taken, and analyze the mood and emotion of the image. These three factors are then brought together and utilized to generate a haiku that reflects the subject, weather, and mood of the image. As they say, ""a picture is worth a thousand words.""

How we built it

We built it using more than four different online APIs as well as the Python Flask library and PIL image analysis library. Each person took responsibility for one distinct API and became an expert in it, implementing it themselves and allowing us to come together at the end to pull them together into one unified program.

Challenges we ran into

We ran into some challenges implementing various APIs because of issues installing and utilizing them. However, working together as a team, we managed to overcome those difficulties and implement them.

Accomplishments that we're proud of

We were able to complete over 4 of the challenges offered with our application, including various weather, image recognition, and social good challenges. We also did not know each other before this hackathon, so we are proud of our ability to work as a team and develop an advanced product together.

What we learned

We learned how to use iterative design as well as work together as a team to produce a major product. We learned valuable teamwork skills and had frequent meeting to discuss both our progress and what still needed to be done, as well as determine whether anyone needed help. Overall, very valuable teamwork and development skills were gained from this.

What's next for Image 2 Haiku

If we have the chance to work more on this project, we had thrown around different ideas including integrating the Snapchat API to allow this to be directly used from Snapchat, implementing a refresh button to generate a fresh new poem without having to refresh, and improving the user frontend even more.
",,https://image2haiku.com,,"python, flask, gcp, clarifai, merriam-webster-dictionary, accuweather, pil",Pennsylvania State University,"Domain.com,Google Cloud Platform,Clarifai","",mikexcao,Michael,Cao,mike.x.cao@gmail.com,Pennsylvania State University,2,sophiabeyda,Sophia,Beyda,sophiabeyda@gmail.com,Pandaboi3010,Sriparno,Majumdar,szm6174@psu.edu
Best use of Google Cloud Platform,Image 2 Haiku,37,https://hackpsu-fall-2018.devpost.com/submissions/102337-image-2-haiku,"Inspiration

The inspiration from this project came from an introduction keynote at an MIT hackathon, talking about improving the human condition with technology. 

What it does

The Image 2 Haiku website allows the user to upload an image to the website and submit it for analysis. The website then submits the image to multiple APIs including the Google Cloud Platform and Clarifai to generate a list of words describing it, analyze the weather in the location the image was taken, and analyze the mood and emotion of the image. These three factors are then brought together and utilized to generate a haiku that reflects the subject, weather, and mood of the image. As they say, ""a picture is worth a thousand words.""

How we built it

We built it using more than four different online APIs as well as the Python Flask library and PIL image analysis library. Each person took responsibility for one distinct API and became an expert in it, implementing it themselves and allowing us to come together at the end to pull them together into one unified program.

Challenges we ran into

We ran into some challenges implementing various APIs because of issues installing and utilizing them. However, working together as a team, we managed to overcome those difficulties and implement them.

Accomplishments that we're proud of

We were able to complete over 4 of the challenges offered with our application, including various weather, image recognition, and social good challenges. We also did not know each other before this hackathon, so we are proud of our ability to work as a team and develop an advanced product together.

What we learned

We learned how to use iterative design as well as work together as a team to produce a major product. We learned valuable teamwork skills and had frequent meeting to discuss both our progress and what still needed to be done, as well as determine whether anyone needed help. Overall, very valuable teamwork and development skills were gained from this.

What's next for Image 2 Haiku

If we have the chance to work more on this project, we had thrown around different ideas including integrating the Snapchat API to allow this to be directly used from Snapchat, implementing a refresh button to generate a fresh new poem without having to refresh, and improving the user frontend even more.
",,https://image2haiku.com,,"python, flask, gcp, clarifai, merriam-webster-dictionary, accuweather, pil",Pennsylvania State University,"Domain.com,Google Cloud Platform,Clarifai","",mikexcao,Michael,Cao,mike.x.cao@gmail.com,Pennsylvania State University,2,sophiabeyda,Sophia,Beyda,sophiabeyda@gmail.com,Pandaboi3010,Sriparno,Majumdar,szm6174@psu.edu
Booz Allen Hamilton - Best Machine Learning Hack,Image 2 Haiku,37,https://hackpsu-fall-2018.devpost.com/submissions/102337-image-2-haiku,"Inspiration

The inspiration from this project came from an introduction keynote at an MIT hackathon, talking about improving the human condition with technology. 

What it does

The Image 2 Haiku website allows the user to upload an image to the website and submit it for analysis. The website then submits the image to multiple APIs including the Google Cloud Platform and Clarifai to generate a list of words describing it, analyze the weather in the location the image was taken, and analyze the mood and emotion of the image. These three factors are then brought together and utilized to generate a haiku that reflects the subject, weather, and mood of the image. As they say, ""a picture is worth a thousand words.""

How we built it

We built it using more than four different online APIs as well as the Python Flask library and PIL image analysis library. Each person took responsibility for one distinct API and became an expert in it, implementing it themselves and allowing us to come together at the end to pull them together into one unified program.

Challenges we ran into

We ran into some challenges implementing various APIs because of issues installing and utilizing them. However, working together as a team, we managed to overcome those difficulties and implement them.

Accomplishments that we're proud of

We were able to complete over 4 of the challenges offered with our application, including various weather, image recognition, and social good challenges. We also did not know each other before this hackathon, so we are proud of our ability to work as a team and develop an advanced product together.

What we learned

We learned how to use iterative design as well as work together as a team to produce a major product. We learned valuable teamwork skills and had frequent meeting to discuss both our progress and what still needed to be done, as well as determine whether anyone needed help. Overall, very valuable teamwork and development skills were gained from this.

What's next for Image 2 Haiku

If we have the chance to work more on this project, we had thrown around different ideas including integrating the Snapchat API to allow this to be directly used from Snapchat, implementing a refresh button to generate a fresh new poem without having to refresh, and improving the user frontend even more.
",,https://image2haiku.com,,"python, flask, gcp, clarifai, merriam-webster-dictionary, accuweather, pil",Pennsylvania State University,"Domain.com,Google Cloud Platform,Clarifai","",mikexcao,Michael,Cao,mike.x.cao@gmail.com,Pennsylvania State University,2,sophiabeyda,Sophia,Beyda,sophiabeyda@gmail.com,Pandaboi3010,Sriparno,Majumdar,szm6174@psu.edu
HackPSU Overall - Tech,Image 2 Haiku,37,https://hackpsu-fall-2018.devpost.com/submissions/102337-image-2-haiku,"Inspiration

The inspiration from this project came from an introduction keynote at an MIT hackathon, talking about improving the human condition with technology. 

What it does

The Image 2 Haiku website allows the user to upload an image to the website and submit it for analysis. The website then submits the image to multiple APIs including the Google Cloud Platform and Clarifai to generate a list of words describing it, analyze the weather in the location the image was taken, and analyze the mood and emotion of the image. These three factors are then brought together and utilized to generate a haiku that reflects the subject, weather, and mood of the image. As they say, ""a picture is worth a thousand words.""

How we built it

We built it using more than four different online APIs as well as the Python Flask library and PIL image analysis library. Each person took responsibility for one distinct API and became an expert in it, implementing it themselves and allowing us to come together at the end to pull them together into one unified program.

Challenges we ran into

We ran into some challenges implementing various APIs because of issues installing and utilizing them. However, working together as a team, we managed to overcome those difficulties and implement them.

Accomplishments that we're proud of

We were able to complete over 4 of the challenges offered with our application, including various weather, image recognition, and social good challenges. We also did not know each other before this hackathon, so we are proud of our ability to work as a team and develop an advanced product together.

What we learned

We learned how to use iterative design as well as work together as a team to produce a major product. We learned valuable teamwork skills and had frequent meeting to discuss both our progress and what still needed to be done, as well as determine whether anyone needed help. Overall, very valuable teamwork and development skills were gained from this.

What's next for Image 2 Haiku

If we have the chance to work more on this project, we had thrown around different ideas including integrating the Snapchat API to allow this to be directly used from Snapchat, implementing a refresh button to generate a fresh new poem without having to refresh, and improving the user frontend even more.
",,https://image2haiku.com,,"python, flask, gcp, clarifai, merriam-webster-dictionary, accuweather, pil",Pennsylvania State University,"Domain.com,Google Cloud Platform,Clarifai","",mikexcao,Michael,Cao,mike.x.cao@gmail.com,Pennsylvania State University,2,sophiabeyda,Sophia,Beyda,sophiabeyda@gmail.com,Pandaboi3010,Sriparno,Majumdar,szm6174@psu.edu
JPMC - Best Social Good Hack,Image 2 Haiku,37,https://hackpsu-fall-2018.devpost.com/submissions/102337-image-2-haiku,"Inspiration

The inspiration from this project came from an introduction keynote at an MIT hackathon, talking about improving the human condition with technology. 

What it does

The Image 2 Haiku website allows the user to upload an image to the website and submit it for analysis. The website then submits the image to multiple APIs including the Google Cloud Platform and Clarifai to generate a list of words describing it, analyze the weather in the location the image was taken, and analyze the mood and emotion of the image. These three factors are then brought together and utilized to generate a haiku that reflects the subject, weather, and mood of the image. As they say, ""a picture is worth a thousand words.""

How we built it

We built it using more than four different online APIs as well as the Python Flask library and PIL image analysis library. Each person took responsibility for one distinct API and became an expert in it, implementing it themselves and allowing us to come together at the end to pull them together into one unified program.

Challenges we ran into

We ran into some challenges implementing various APIs because of issues installing and utilizing them. However, working together as a team, we managed to overcome those difficulties and implement them.

Accomplishments that we're proud of

We were able to complete over 4 of the challenges offered with our application, including various weather, image recognition, and social good challenges. We also did not know each other before this hackathon, so we are proud of our ability to work as a team and develop an advanced product together.

What we learned

We learned how to use iterative design as well as work together as a team to produce a major product. We learned valuable teamwork skills and had frequent meeting to discuss both our progress and what still needed to be done, as well as determine whether anyone needed help. Overall, very valuable teamwork and development skills were gained from this.

What's next for Image 2 Haiku

If we have the chance to work more on this project, we had thrown around different ideas including integrating the Snapchat API to allow this to be directly used from Snapchat, implementing a refresh button to generate a fresh new poem without having to refresh, and improving the user frontend even more.
",,https://image2haiku.com,,"python, flask, gcp, clarifai, merriam-webster-dictionary, accuweather, pil",Pennsylvania State University,"Domain.com,Google Cloud Platform,Clarifai","",mikexcao,Michael,Cao,mike.x.cao@gmail.com,Pennsylvania State University,2,sophiabeyda,Sophia,Beyda,sophiabeyda@gmail.com,Pandaboi3010,Sriparno,Majumdar,szm6174@psu.edu
Accuweather Challenge,The Whether App,35,https://hackpsu-fall-2018.devpost.com/submissions/102342-the-whether-app,"Inspiration Solving a daily problem for many people

What it does A personalized weather app that suggests to the user what to wear based on the weather

How we built it Javascript and Hard Work

Challenges we ran into React Native Troubleshooting

Accomplishments that we're proud of Finishing

What we learned UI enhancement and application of Accuweather API

What's next for The Whether App Incorporating more conditions, better specified conditions, and a more personalized criteria.
",,https://expo.io/@/the-whether-app,https://s3.amazonaws.com/challengepost/zip_files/production/36302/zip_files/TheWhetherApp.zip,"javascript, react-native, accuweather, sublime-text",Penn State,"","",MichaelMadden,Michael,Madden,michaeltm98@gmail.com,Pennsylvania State University,1,VietPham,Viet,Pham,vhp4@psu.edu
HackPSU Overall - Tech,flag.go,61,https://hackpsu-fall-2018.devpost.com/submissions/102356-flag-go,"Inspiration

Wanted to create an entertaining mobile game that can be played with friends in the real world, while collecting virtual objectives.

What it does

It is an Android app that multiple people can get on their phones to play together and race to capture the most flags.

How we built it

We used the Google Maps API, Java, and Flask with Python

Challenges we ran into

Figuring out how to find current location and continuously update it, figuring out how to get flask working so that we could keep track of player locations and scores, as well as losing teammates along the way.

Accomplishments that we're proud of

Got most of the features working that we set out to accomplish. We only had two people for a majority of the project and were still able to work through and get our project done.

What we learned

Android Studio can be pretty frustrating to use, to say the least.

What's next for flag.go


Get on Shark Tank
Funding
???
Profit

",,https://github.com/gcb5083/flag.go,,"java, python, flask, android",Penn State,"","",sahilbhanderi,Sahil,Bhanderi,sahil.bhanderi@gmail.com,Pennsylvania State University,1,gcb5083,Geoff,,gcb5083@psu.edu
KCF - Hack the Waiting Room Challenge,Human Sensor,80,https://hackpsu-fall-2018.devpost.com/submissions/102368-human-sensor,"Inspiration

What it does

Our human sensor is placed around the door, which can judge whether people come in or get out of the room and display the total number in the room.

How I built it

We use Arduino 101 with, a sonic sensor(Ultrasonic Sensor), a light sensor(Photoresistor) and a motion detector(HC-SR501 PIR Sensor) to build this human sensor. 

Challenges I ran into

The main challenge is that all members of our team do not have any experience of how to use Arduino. 
The second challenge we met is where to put our sensors. We used the ultrasonic sensor to detect the position of the door, the motion sensor to determine if there is a person near the door and the photoresistor to determine which direction the person is moving. 

Accomplishments that I'm proud of

Our display was not working and I fixed it. 

What I learned

We learned lots of knowledge about Arduino and how to set up for digit display.

What's next for Human Sensor

For the future, we need to improve the sensitivity of our sensors. What's more, we can set up our database to store the number of people in that room during each time of the day. Using this database to predict how many people will in the room at a specific time. 
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36308/zip_files/Door.zip,arduino,Penn State Behrend,"","",yvd5140,Yilu,Dong,yvd5140@psu.edu,"Pennsylvania State University, PSU",3,zmz5105,Zihao,Zhang,zmz5105@psu.edu,1505338162,Sheng,Su,1505338162@qq.com,xinpengzhao,Xinpeng,Zhao,xinpengzhao@gmail.com
HackPSU Overall - Tech,Human Sensor,80,https://hackpsu-fall-2018.devpost.com/submissions/102368-human-sensor,"Inspiration

What it does

Our human sensor is placed around the door, which can judge whether people come in or get out of the room and display the total number in the room.

How I built it

We use Arduino 101 with, a sonic sensor(Ultrasonic Sensor), a light sensor(Photoresistor) and a motion detector(HC-SR501 PIR Sensor) to build this human sensor. 

Challenges I ran into

The main challenge is that all members of our team do not have any experience of how to use Arduino. 
The second challenge we met is where to put our sensors. We used the ultrasonic sensor to detect the position of the door, the motion sensor to determine if there is a person near the door and the photoresistor to determine which direction the person is moving. 

Accomplishments that I'm proud of

Our display was not working and I fixed it. 

What I learned

We learned lots of knowledge about Arduino and how to set up for digit display.

What's next for Human Sensor

For the future, we need to improve the sensitivity of our sensors. What's more, we can set up our database to store the number of people in that room during each time of the day. Using this database to predict how many people will in the room at a specific time. 
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36308/zip_files/Door.zip,arduino,Penn State Behrend,"","",yvd5140,Yilu,Dong,yvd5140@psu.edu,"Pennsylvania State University, PSU",3,zmz5105,Zihao,Zhang,zmz5105@psu.edu,1505338162,Sheng,Su,1505338162@qq.com,xinpengzhao,Xinpeng,Zhao,xinpengzhao@gmail.com
JPMC - Best Social Good Hack,Human Sensor,80,https://hackpsu-fall-2018.devpost.com/submissions/102368-human-sensor,"Inspiration

What it does

Our human sensor is placed around the door, which can judge whether people come in or get out of the room and display the total number in the room.

How I built it

We use Arduino 101 with, a sonic sensor(Ultrasonic Sensor), a light sensor(Photoresistor) and a motion detector(HC-SR501 PIR Sensor) to build this human sensor. 

Challenges I ran into

The main challenge is that all members of our team do not have any experience of how to use Arduino. 
The second challenge we met is where to put our sensors. We used the ultrasonic sensor to detect the position of the door, the motion sensor to determine if there is a person near the door and the photoresistor to determine which direction the person is moving. 

Accomplishments that I'm proud of

Our display was not working and I fixed it. 

What I learned

We learned lots of knowledge about Arduino and how to set up for digit display.

What's next for Human Sensor

For the future, we need to improve the sensitivity of our sensors. What's more, we can set up our database to store the number of people in that room during each time of the day. Using this database to predict how many people will in the room at a specific time. 
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36308/zip_files/Door.zip,arduino,Penn State Behrend,"","",yvd5140,Yilu,Dong,yvd5140@psu.edu,"Pennsylvania State University, PSU",3,zmz5105,Zihao,Zhang,zmz5105@psu.edu,1505338162,Sheng,Su,1505338162@qq.com,xinpengzhao,Xinpeng,Zhao,xinpengzhao@gmail.com
Best Domain Name from Domain.com,Can I Go Outside?,18,https://hackpsu-fall-2018.devpost.com/submissions/102387-can-i-go-outside,"Inspiration

We are all developers who don't go outside, mostly due to inclement weather. This caused us to make a website to know if it's safe to step outside and avoid rain, snow, hot temperatures, cold temperatures, etc. 

What it does

This website informs you on whether or not you can go outside right now, based on the weather.
http://canigooutside.somee.com/

How we built it

We built this in C# using MVC in Visual Studio. This uses the AccuWeather API to get all of its data.

Challenges we ran into

Staying on track, we had a larger team than usual and this contributed to a lot of lost time.

Accomplishments that we're proud of

We actually got it to work.

What we learned

How to make a website in MVC, use HTML and CSS to make a nice website, as well as design minimalist backgrounds.

What's next for Can I Go Outside?

Can I Stay Inside?
",,https://github.com/illuzio571/CanIGoOutside,,"c#, mvc, .net, javascript, html5, css",Penn State Altoona; GACTC;,"","",jpm6492,Jeromy,McCorriston,jpm6492@psu.edu,"",0
Accuweather Challenge,Can I Go Outside?,18,https://hackpsu-fall-2018.devpost.com/submissions/102387-can-i-go-outside,"Inspiration

We are all developers who don't go outside, mostly due to inclement weather. This caused us to make a website to know if it's safe to step outside and avoid rain, snow, hot temperatures, cold temperatures, etc. 

What it does

This website informs you on whether or not you can go outside right now, based on the weather.
http://canigooutside.somee.com/

How we built it

We built this in C# using MVC in Visual Studio. This uses the AccuWeather API to get all of its data.

Challenges we ran into

Staying on track, we had a larger team than usual and this contributed to a lot of lost time.

Accomplishments that we're proud of

We actually got it to work.

What we learned

How to make a website in MVC, use HTML and CSS to make a nice website, as well as design minimalist backgrounds.

What's next for Can I Go Outside?

Can I Stay Inside?
",,https://github.com/illuzio571/CanIGoOutside,,"c#, mvc, .net, javascript, html5, css",Penn State Altoona; GACTC;,"","",jpm6492,Jeromy,McCorriston,jpm6492@psu.edu,"",0
HackPSU Overall - Tech,Can I Go Outside?,18,https://hackpsu-fall-2018.devpost.com/submissions/102387-can-i-go-outside,"Inspiration

We are all developers who don't go outside, mostly due to inclement weather. This caused us to make a website to know if it's safe to step outside and avoid rain, snow, hot temperatures, cold temperatures, etc. 

What it does

This website informs you on whether or not you can go outside right now, based on the weather.
http://canigooutside.somee.com/

How we built it

We built this in C# using MVC in Visual Studio. This uses the AccuWeather API to get all of its data.

Challenges we ran into

Staying on track, we had a larger team than usual and this contributed to a lot of lost time.

Accomplishments that we're proud of

We actually got it to work.

What we learned

How to make a website in MVC, use HTML and CSS to make a nice website, as well as design minimalist backgrounds.

What's next for Can I Go Outside?

Can I Stay Inside?
",,https://github.com/illuzio571/CanIGoOutside,,"c#, mvc, .net, javascript, html5, css",Penn State Altoona; GACTC;,"","",jpm6492,Jeromy,McCorriston,jpm6492@psu.edu,"",0
JPMC - Best Social Good Hack,Can I Go Outside?,18,https://hackpsu-fall-2018.devpost.com/submissions/102387-can-i-go-outside,"Inspiration

We are all developers who don't go outside, mostly due to inclement weather. This caused us to make a website to know if it's safe to step outside and avoid rain, snow, hot temperatures, cold temperatures, etc. 

What it does

This website informs you on whether or not you can go outside right now, based on the weather.
http://canigooutside.somee.com/

How we built it

We built this in C# using MVC in Visual Studio. This uses the AccuWeather API to get all of its data.

Challenges we ran into

Staying on track, we had a larger team than usual and this contributed to a lot of lost time.

Accomplishments that we're proud of

We actually got it to work.

What we learned

How to make a website in MVC, use HTML and CSS to make a nice website, as well as design minimalist backgrounds.

What's next for Can I Go Outside?

Can I Stay Inside?
",,https://github.com/illuzio571/CanIGoOutside,,"c#, mvc, .net, javascript, html5, css",Penn State Altoona; GACTC;,"","",jpm6492,Jeromy,McCorriston,jpm6492@psu.edu,"",0
Booz Allen Hamilton - Best Machine Learning Hack,Recruit'r,27,https://hackpsu-fall-2018.devpost.com/submissions/102395-recruit-r,"Inspiration

The team working on this project has recently endured the pain of the job search process and wanted to create this project in order to completely streamline the process in a trustworthy and controlled way. The current method a majority of students hunt for jobs is by sporadically throwing an application at every company you can and expecting a 90% rejection rate or more and just seeing what sticks. 

What it does

This process solves this issue by providing a trustworthy platform for companies so that they know every student application is accurate and genuine. It also eases the pain of the process for students because they only have to create one application to be used everywhere instead of having to create a new application per company they are applying to. Once a student is registered in the system using their university issued id, they are matched to job postings using a neural network that decides which student matches to what job posting using a supervised single dense layer neural network.

How we built it

The frontend of our service is built using semantic-ui for its appearance and also uses jQuery to handle http transactions from the backend to the frontend.

The backend is hosting on top of express.js which handles the database interactions such as storing and retrieving student and company data. The backend also interfaces with a java server using Spring Boot which houses a neural network written using the deeplearning4j library which trains the pairing AI based on if a student has successfully gotten a job that they were matched to. This neural network is further used also to make judgements and create recommended pairings between students and available job postings.

Challenges we ran into

The frontend team was inexperienced with semantic-ui and they quickly learned the documentation and implementation of the stylesheets. 
The backend team was initially uncertain of what data to track for both students and job postings but we decided upon a set of data that we felt was most accurate given the amount of time we had. 
An important part of Neural Networks is the information which is fed into the AI, usually requiring careful data normalization for the inputs. Given the time constraint, we were able to eventually create a reasonable set of data to be used by the neural network which will show some progress of learning over time, however we were not able to make a completely optimized function that would turn these values into optimal inputs. 

Accomplishments that we're proud of

We feel as though our project idea is well thought out as it is generally desirable by both companies and students. Recruit'r also avoids a key issue of fake student data because it ties student information to the university and student ids.
Another big accomplishment for the project is that we are drawing from a lot of student data that is not commonly tracked. This is critically important for the neural network because the AI is able to discover connections between data that humans are unable to see.

What we learned

The frontend team successfully learned the notation of semantic-ui. The development team overall feels as though we have sharpened our skills with javascript and gained confidence in our use of the language. The backend team also greatly appreciated the additional experience with mongodb and connecting to databases.

What's next for Recruit'r

If our team had more time to work on Recruit'r, we would have implemented a second AI that would normalize the input data which would then be used in our primary neural network. We would also increase the amount of customization of the project as it would allow for even more varied applicants to be successfully matched to job postings. Lastly, we would improve the appearance of the interface for companies in order to allow companies to specify what traits a company is looking for even more accurately.
",,https://github.com/ConradWeiser/HackPSU-2018-Fall,https://s3.amazonaws.com/challengepost/zip_files/production/36319/zip_files/HackPSU-2018-Fall-master.zip,"semantic-ui, typescript, mongodb, express.js, deeplearning4j, html5, spring-framework",The Pennsylvania State University,"",Dell XPS,JordonTorunian,JordonTorunian,,jordontorunian@gmail.com,Pennsylvania State University,2,ConradWeiser,Conrad,Weiser,bluecrecent0@gmail.com,gap5265,gap5265,,gap5265@psu.edu
Nittany AI Alliance - AI Challenge,Recruit'r,27,https://hackpsu-fall-2018.devpost.com/submissions/102395-recruit-r,"Inspiration

The team working on this project has recently endured the pain of the job search process and wanted to create this project in order to completely streamline the process in a trustworthy and controlled way. The current method a majority of students hunt for jobs is by sporadically throwing an application at every company you can and expecting a 90% rejection rate or more and just seeing what sticks. 

What it does

This process solves this issue by providing a trustworthy platform for companies so that they know every student application is accurate and genuine. It also eases the pain of the process for students because they only have to create one application to be used everywhere instead of having to create a new application per company they are applying to. Once a student is registered in the system using their university issued id, they are matched to job postings using a neural network that decides which student matches to what job posting using a supervised single dense layer neural network.

How we built it

The frontend of our service is built using semantic-ui for its appearance and also uses jQuery to handle http transactions from the backend to the frontend.

The backend is hosting on top of express.js which handles the database interactions such as storing and retrieving student and company data. The backend also interfaces with a java server using Spring Boot which houses a neural network written using the deeplearning4j library which trains the pairing AI based on if a student has successfully gotten a job that they were matched to. This neural network is further used also to make judgements and create recommended pairings between students and available job postings.

Challenges we ran into

The frontend team was inexperienced with semantic-ui and they quickly learned the documentation and implementation of the stylesheets. 
The backend team was initially uncertain of what data to track for both students and job postings but we decided upon a set of data that we felt was most accurate given the amount of time we had. 
An important part of Neural Networks is the information which is fed into the AI, usually requiring careful data normalization for the inputs. Given the time constraint, we were able to eventually create a reasonable set of data to be used by the neural network which will show some progress of learning over time, however we were not able to make a completely optimized function that would turn these values into optimal inputs. 

Accomplishments that we're proud of

We feel as though our project idea is well thought out as it is generally desirable by both companies and students. Recruit'r also avoids a key issue of fake student data because it ties student information to the university and student ids.
Another big accomplishment for the project is that we are drawing from a lot of student data that is not commonly tracked. This is critically important for the neural network because the AI is able to discover connections between data that humans are unable to see.

What we learned

The frontend team successfully learned the notation of semantic-ui. The development team overall feels as though we have sharpened our skills with javascript and gained confidence in our use of the language. The backend team also greatly appreciated the additional experience with mongodb and connecting to databases.

What's next for Recruit'r

If our team had more time to work on Recruit'r, we would have implemented a second AI that would normalize the input data which would then be used in our primary neural network. We would also increase the amount of customization of the project as it would allow for even more varied applicants to be successfully matched to job postings. Lastly, we would improve the appearance of the interface for companies in order to allow companies to specify what traits a company is looking for even more accurately.
",,https://github.com/ConradWeiser/HackPSU-2018-Fall,https://s3.amazonaws.com/challengepost/zip_files/production/36319/zip_files/HackPSU-2018-Fall-master.zip,"semantic-ui, typescript, mongodb, express.js, deeplearning4j, html5, spring-framework",The Pennsylvania State University,"",Dell XPS,JordonTorunian,JordonTorunian,,jordontorunian@gmail.com,Pennsylvania State University,2,ConradWeiser,Conrad,Weiser,bluecrecent0@gmail.com,gap5265,gap5265,,gap5265@psu.edu
HackPSU Overall - Tech,Recruit'r,27,https://hackpsu-fall-2018.devpost.com/submissions/102395-recruit-r,"Inspiration

The team working on this project has recently endured the pain of the job search process and wanted to create this project in order to completely streamline the process in a trustworthy and controlled way. The current method a majority of students hunt for jobs is by sporadically throwing an application at every company you can and expecting a 90% rejection rate or more and just seeing what sticks. 

What it does

This process solves this issue by providing a trustworthy platform for companies so that they know every student application is accurate and genuine. It also eases the pain of the process for students because they only have to create one application to be used everywhere instead of having to create a new application per company they are applying to. Once a student is registered in the system using their university issued id, they are matched to job postings using a neural network that decides which student matches to what job posting using a supervised single dense layer neural network.

How we built it

The frontend of our service is built using semantic-ui for its appearance and also uses jQuery to handle http transactions from the backend to the frontend.

The backend is hosting on top of express.js which handles the database interactions such as storing and retrieving student and company data. The backend also interfaces with a java server using Spring Boot which houses a neural network written using the deeplearning4j library which trains the pairing AI based on if a student has successfully gotten a job that they were matched to. This neural network is further used also to make judgements and create recommended pairings between students and available job postings.

Challenges we ran into

The frontend team was inexperienced with semantic-ui and they quickly learned the documentation and implementation of the stylesheets. 
The backend team was initially uncertain of what data to track for both students and job postings but we decided upon a set of data that we felt was most accurate given the amount of time we had. 
An important part of Neural Networks is the information which is fed into the AI, usually requiring careful data normalization for the inputs. Given the time constraint, we were able to eventually create a reasonable set of data to be used by the neural network which will show some progress of learning over time, however we were not able to make a completely optimized function that would turn these values into optimal inputs. 

Accomplishments that we're proud of

We feel as though our project idea is well thought out as it is generally desirable by both companies and students. Recruit'r also avoids a key issue of fake student data because it ties student information to the university and student ids.
Another big accomplishment for the project is that we are drawing from a lot of student data that is not commonly tracked. This is critically important for the neural network because the AI is able to discover connections between data that humans are unable to see.

What we learned

The frontend team successfully learned the notation of semantic-ui. The development team overall feels as though we have sharpened our skills with javascript and gained confidence in our use of the language. The backend team also greatly appreciated the additional experience with mongodb and connecting to databases.

What's next for Recruit'r

If our team had more time to work on Recruit'r, we would have implemented a second AI that would normalize the input data which would then be used in our primary neural network. We would also increase the amount of customization of the project as it would allow for even more varied applicants to be successfully matched to job postings. Lastly, we would improve the appearance of the interface for companies in order to allow companies to specify what traits a company is looking for even more accurately.
",,https://github.com/ConradWeiser/HackPSU-2018-Fall,https://s3.amazonaws.com/challengepost/zip_files/production/36319/zip_files/HackPSU-2018-Fall-master.zip,"semantic-ui, typescript, mongodb, express.js, deeplearning4j, html5, spring-framework",The Pennsylvania State University,"",Dell XPS,JordonTorunian,JordonTorunian,,jordontorunian@gmail.com,Pennsylvania State University,2,ConradWeiser,Conrad,Weiser,bluecrecent0@gmail.com,gap5265,gap5265,,gap5265@psu.edu
HackPSU Overall - Design,NPAPR (National Park App for Park Rangers),14,https://hackpsu-fall-2018.devpost.com/submissions/102401-npapr-national-park-app-for-park-rangers,"NPAPR

Our professor kept pushing us to try and compete, as there is no repercussion in attempting a competition, and gaining knowledge #

This app allows the park ranger keep up with tending to the park whether its the wildlife or how dry it is out side

We started out with the Adobe xd cc, and just solved one problem at a time until everything was finished

Figuring out how we could make the rangers lives easier and implementing that into our app

Getting the look side of this app finished and running smoothly

We learned more about file sharing and about Frameworks making this base app #

Making the code for it then testing it before releasing it#
",https://vimeo.com/293815317,,https://s3.amazonaws.com/challengepost/zip_files/production/36322/zip_files/NPAPR.zip,"adobe-creative-suite, youtube, windows-10",South Hills School of Business and Technology (Altoona),"","",jschopp99,jschopp99,,jschopp99@southhills.edu,South Hills School of Business and Technology - State College,2,pollyjofrantz,,,pollyjofrantz@gmail.com,sking67,Shedaisy,King,sking67@southhills.edu
"",National Ranger Web Design,71,https://hackpsu-fall-2018.devpost.com/submissions/102420-national-ranger-web-design,"Inspiration

We researched and dug deep into the daily lives of National Forest Rangers, evaluating their day to day jobs as well as rare requirements. This inspired us to create an aesthetically pleasing, easy and quick to use and wholesome website and mobile app for the Rangers to be able to conduct their responsibilities on an interface which reflects their love for nature.

What it does

The interface has a live and interactive map which displays the latest emergencies and activities occurring within the national park. In addition, it provides a wholesome and easy to use scheduling system for rangers to not only schedule in their work but also book any equipment that may be required during the event. Furthermore, the interface has a running inventory of the animals, plants and the environment, providing latest data about the park as well as any general information a Ranger might find helpful to know for themselves or Additionally, the website has an exclusive eLearning center with training videos for new rangers and knowledgeable videos for all rangers.  Finally, as it is an employee website, there are also personal performance reviews for a ranger to view and assess.

How I built it

We first drafted the specification for the design, based upon which we sketched out various ideas for each page relating to content. We displayed this in technical drawing through our wireframes, which further allowed us to build a logical and comprehensive user flow. Incorporating all of this work we finally built mockups to bring our idea to life and represent the aesthetics we wish to incorporate.

Challenges I ran into

It was not only difficult to find information on Nature Rangers and their managerial activies, but It also proved difficult to find the best softwares to create our mockups and wireframs. Thus time was our greatest challenge.

Accomplishments that I'm proud of

Despite all the hurdles we went through, we have created a user interface we are proud of with detailed wireframes, logical user flow and aesthetic mockups.

What I learned

It is important to prioritize the work and spend less time on low risk parts of the project. 

What's next for National Ranger Web Design

To make them user friendly, modern, comprehensive (filled with information) and most importantly live updates and interactive maps.
",,https://pennstateoffice365-my.sharepoint.com/:f:/g/personal/aoa5671_psu_edu/EkwF3xpzBg5FtQHwxH4W6R4BfmixQvzX3m86cfHQi5KHaA?e=rCG6eV,,"indesign, figma, mockplus",The Penssylvania State University,"","",monoblack21,Ayokanmi,Aloko,kalming@yahoo.com,Pennsylvania State University,0
"",instatute,57,https://hackpsu-fall-2018.devpost.com/submissions/102422-instatute,"Inspiration Teachers have to check many answer sheets. So to reduce the workload, instatute is here to help in checking those answers.

What it does

How we built it

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for instatute
",,https://www.dropbox.com/s/191zte4s6s5etik/instatute2.0.py?dl=0,https://s3.amazonaws.com/challengepost/zip_files/production/36329/zip_files/instatute2.0.zip,amazon-web-services,Pennsylvania State University,"","",tza38,Taksh,Anand,tza38@outlook.com,Pennsylvania State University,3,agarwalvibhor2305,Vibhor,Agarwal,agarwalvibhor2305@gmail.com,safrimuayyad,Muayyad,Safri,safrimuayyad@gmail.com,pdasgm2015,Pallavi,Das,pdasgm2015@gmail.com
Best Domain Name from Domain.com,chore.store,83,https://hackpsu-fall-2018.devpost.com/submissions/102423-chore-store,"Inspiration

The inspiration comes from identifying and understanding the struggle of being in a low income situation. Having additional forms of income by selling your services when you're available could be a great way to help those in this scenario. Additionally, if you have disposable income, you can buy the services to free up additional time for yourself.

What it does

Create listings to buy and sell specific services on a competitive marketplace such as Lawn mowing, Laundry, Babysitting, Car Washing.

How we built it

Using React Native,  JavaScript, HTML, CSS, Expo.io and Visual Studio Code we created a phone application front-end. For the back-end we used Facebook's login API, JavaScript and React Native.

Challenges we ran into

Lack of documentation and experience with new frameworks we're our largest challenges throughout this hackathon.

Accomplishments that we're proud of

We're very proud of the front end and branding that we created. More than anything we are most proud of what we were able to create with the limited knowledge of the frameworks going into this project.

What we learned

We learned that persistence is key.  Without it this project would not have been created. It was incredibly difficult to get everything to work together correctly, but it was very rewarding.

What's next for chore.store

We hope to continue to develop our project together moving forward with the intentions of releasing an alpha to college campuses initially and scaling up to larger locations as seen fit.
",,http://chore.store,,"react-native, javascript, css, firebase, google-cloud, facebook-login-api, expo.io, photoshop, adobe-illustrator, visual-studio-code, github, node.js, slack",Pennsylvania State University Erie,"","",Austin-Higgins,Austin,Higgins,ahiggins.dev@gmail.com,Pennsylvania State University,3,helloimali,Ali,Malik,toalisaeedmalik@gmail.com,jakdvis,Jake,Davis,jakdvis@gmail.com,bjBartosek,Brandon,Bartosek,bjb5565@psu.edu
HackPSU Overall - Tech,chore.store,83,https://hackpsu-fall-2018.devpost.com/submissions/102423-chore-store,"Inspiration

The inspiration comes from identifying and understanding the struggle of being in a low income situation. Having additional forms of income by selling your services when you're available could be a great way to help those in this scenario. Additionally, if you have disposable income, you can buy the services to free up additional time for yourself.

What it does

Create listings to buy and sell specific services on a competitive marketplace such as Lawn mowing, Laundry, Babysitting, Car Washing.

How we built it

Using React Native,  JavaScript, HTML, CSS, Expo.io and Visual Studio Code we created a phone application front-end. For the back-end we used Facebook's login API, JavaScript and React Native.

Challenges we ran into

Lack of documentation and experience with new frameworks we're our largest challenges throughout this hackathon.

Accomplishments that we're proud of

We're very proud of the front end and branding that we created. More than anything we are most proud of what we were able to create with the limited knowledge of the frameworks going into this project.

What we learned

We learned that persistence is key.  Without it this project would not have been created. It was incredibly difficult to get everything to work together correctly, but it was very rewarding.

What's next for chore.store

We hope to continue to develop our project together moving forward with the intentions of releasing an alpha to college campuses initially and scaling up to larger locations as seen fit.
",,http://chore.store,,"react-native, javascript, css, firebase, google-cloud, facebook-login-api, expo.io, photoshop, adobe-illustrator, visual-studio-code, github, node.js, slack",Pennsylvania State University Erie,"","",Austin-Higgins,Austin,Higgins,ahiggins.dev@gmail.com,Pennsylvania State University,3,helloimali,Ali,Malik,toalisaeedmalik@gmail.com,jakdvis,Jake,Davis,jakdvis@gmail.com,bjBartosek,Brandon,Bartosek,bjb5565@psu.edu
Best Social Good Hack from Fidelity Weekly Challenge,chore.store,83,https://hackpsu-fall-2018.devpost.com/submissions/102423-chore-store,"Inspiration

The inspiration comes from identifying and understanding the struggle of being in a low income situation. Having additional forms of income by selling your services when you're available could be a great way to help those in this scenario. Additionally, if you have disposable income, you can buy the services to free up additional time for yourself.

What it does

Create listings to buy and sell specific services on a competitive marketplace such as Lawn mowing, Laundry, Babysitting, Car Washing.

How we built it

Using React Native,  JavaScript, HTML, CSS, Expo.io and Visual Studio Code we created a phone application front-end. For the back-end we used Facebook's login API, JavaScript and React Native.

Challenges we ran into

Lack of documentation and experience with new frameworks we're our largest challenges throughout this hackathon.

Accomplishments that we're proud of

We're very proud of the front end and branding that we created. More than anything we are most proud of what we were able to create with the limited knowledge of the frameworks going into this project.

What we learned

We learned that persistence is key.  Without it this project would not have been created. It was incredibly difficult to get everything to work together correctly, but it was very rewarding.

What's next for chore.store

We hope to continue to develop our project together moving forward with the intentions of releasing an alpha to college campuses initially and scaling up to larger locations as seen fit.
",,http://chore.store,,"react-native, javascript, css, firebase, google-cloud, facebook-login-api, expo.io, photoshop, adobe-illustrator, visual-studio-code, github, node.js, slack",Pennsylvania State University Erie,"","",Austin-Higgins,Austin,Higgins,ahiggins.dev@gmail.com,Pennsylvania State University,3,helloimali,Ali,Malik,toalisaeedmalik@gmail.com,jakdvis,Jake,Davis,jakdvis@gmail.com,bjBartosek,Brandon,Bartosek,bjb5565@psu.edu
JPMC - Best Social Good Hack,chore.store,83,https://hackpsu-fall-2018.devpost.com/submissions/102423-chore-store,"Inspiration

The inspiration comes from identifying and understanding the struggle of being in a low income situation. Having additional forms of income by selling your services when you're available could be a great way to help those in this scenario. Additionally, if you have disposable income, you can buy the services to free up additional time for yourself.

What it does

Create listings to buy and sell specific services on a competitive marketplace such as Lawn mowing, Laundry, Babysitting, Car Washing.

How we built it

Using React Native,  JavaScript, HTML, CSS, Expo.io and Visual Studio Code we created a phone application front-end. For the back-end we used Facebook's login API, JavaScript and React Native.

Challenges we ran into

Lack of documentation and experience with new frameworks we're our largest challenges throughout this hackathon.

Accomplishments that we're proud of

We're very proud of the front end and branding that we created. More than anything we are most proud of what we were able to create with the limited knowledge of the frameworks going into this project.

What we learned

We learned that persistence is key.  Without it this project would not have been created. It was incredibly difficult to get everything to work together correctly, but it was very rewarding.

What's next for chore.store

We hope to continue to develop our project together moving forward with the intentions of releasing an alpha to college campuses initially and scaling up to larger locations as seen fit.
",,http://chore.store,,"react-native, javascript, css, firebase, google-cloud, facebook-login-api, expo.io, photoshop, adobe-illustrator, visual-studio-code, github, node.js, slack",Pennsylvania State University Erie,"","",Austin-Higgins,Austin,Higgins,ahiggins.dev@gmail.com,Pennsylvania State University,3,helloimali,Ali,Malik,toalisaeedmalik@gmail.com,jakdvis,Jake,Davis,jakdvis@gmail.com,bjBartosek,Brandon,Bartosek,bjb5565@psu.edu
Capital One - Best Financial Hack,chore.store,83,https://hackpsu-fall-2018.devpost.com/submissions/102423-chore-store,"Inspiration

The inspiration comes from identifying and understanding the struggle of being in a low income situation. Having additional forms of income by selling your services when you're available could be a great way to help those in this scenario. Additionally, if you have disposable income, you can buy the services to free up additional time for yourself.

What it does

Create listings to buy and sell specific services on a competitive marketplace such as Lawn mowing, Laundry, Babysitting, Car Washing.

How we built it

Using React Native,  JavaScript, HTML, CSS, Expo.io and Visual Studio Code we created a phone application front-end. For the back-end we used Facebook's login API, JavaScript and React Native.

Challenges we ran into

Lack of documentation and experience with new frameworks we're our largest challenges throughout this hackathon.

Accomplishments that we're proud of

We're very proud of the front end and branding that we created. More than anything we are most proud of what we were able to create with the limited knowledge of the frameworks going into this project.

What we learned

We learned that persistence is key.  Without it this project would not have been created. It was incredibly difficult to get everything to work together correctly, but it was very rewarding.

What's next for chore.store

We hope to continue to develop our project together moving forward with the intentions of releasing an alpha to college campuses initially and scaling up to larger locations as seen fit.
",,http://chore.store,,"react-native, javascript, css, firebase, google-cloud, facebook-login-api, expo.io, photoshop, adobe-illustrator, visual-studio-code, github, node.js, slack",Pennsylvania State University Erie,"","",Austin-Higgins,Austin,Higgins,ahiggins.dev@gmail.com,Pennsylvania State University,3,helloimali,Ali,Malik,toalisaeedmalik@gmail.com,jakdvis,Jake,Davis,jakdvis@gmail.com,bjBartosek,Brandon,Bartosek,bjb5565@psu.edu
Booz Allen Hamilton - Best Machine Learning Hack,PeerSkills,50,https://hackpsu-fall-2018.devpost.com/submissions/102424-peerskills,"Inspiration

Uncertainty of what skills my peers have, can be overwhelming. Being able to find the top skills amongst my peers, I can feel confident in what I should learn next.

What it does

Creates a database of resumes within an area of study, and aggregates the skills amongst them. Any new search leads to a direct comparison to the existing database, and at the same time gets added to it as well!

How we built it

Used a Natural Language Processing framework Spacy to parse various resume formats and search for skills. Use existing dictionary to segment these skills in their relative fields(programming, databases, hobbies). Used bokeh to visualize the top skills in a domain of study relative to any resume. Lastly built a wrapper using Flask to pull new data and push visualizations to the front end. 

Challenges we ran into

Finding resumes from our peers, being able to integrate html with flask. 

Accomplishments that we're proud of

Being able to provide highly relevant data to any student who wants to learn more and be able to understand what skills he/she should pursue next. 

What we learned

We learned to create a much bigger vision from our proof of concept. The immense amount of relevant data and insights we can get from people around us will always be helpful!

What's next for PeerSkills

Expand the database to all subjects, not just at Penn State, but to Universities around the world. 
Building a recommendation system based on the data from current students and alumni, to predict what skill set is most valuable to land dream jobs!
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36358/zip_files/PeerSkills.zip,"python, spacy, flask, machine-learning, bokeh, pandas, math",penn state,"","",rwg5289,,,rwg5289@psu.edu,Pennsylvania State University,1,aka5704,Abhishek,Adhikari,aka5704@psu.edu
Nittany AI Alliance - AI Challenge,PeerSkills,50,https://hackpsu-fall-2018.devpost.com/submissions/102424-peerskills,"Inspiration

Uncertainty of what skills my peers have, can be overwhelming. Being able to find the top skills amongst my peers, I can feel confident in what I should learn next.

What it does

Creates a database of resumes within an area of study, and aggregates the skills amongst them. Any new search leads to a direct comparison to the existing database, and at the same time gets added to it as well!

How we built it

Used a Natural Language Processing framework Spacy to parse various resume formats and search for skills. Use existing dictionary to segment these skills in their relative fields(programming, databases, hobbies). Used bokeh to visualize the top skills in a domain of study relative to any resume. Lastly built a wrapper using Flask to pull new data and push visualizations to the front end. 

Challenges we ran into

Finding resumes from our peers, being able to integrate html with flask. 

Accomplishments that we're proud of

Being able to provide highly relevant data to any student who wants to learn more and be able to understand what skills he/she should pursue next. 

What we learned

We learned to create a much bigger vision from our proof of concept. The immense amount of relevant data and insights we can get from people around us will always be helpful!

What's next for PeerSkills

Expand the database to all subjects, not just at Penn State, but to Universities around the world. 
Building a recommendation system based on the data from current students and alumni, to predict what skill set is most valuable to land dream jobs!
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36358/zip_files/PeerSkills.zip,"python, spacy, flask, machine-learning, bokeh, pandas, math",penn state,"","",rwg5289,,,rwg5289@psu.edu,Pennsylvania State University,1,aka5704,Abhishek,Adhikari,aka5704@psu.edu
HackPSU Overall - Tech,PeerSkills,50,https://hackpsu-fall-2018.devpost.com/submissions/102424-peerskills,"Inspiration

Uncertainty of what skills my peers have, can be overwhelming. Being able to find the top skills amongst my peers, I can feel confident in what I should learn next.

What it does

Creates a database of resumes within an area of study, and aggregates the skills amongst them. Any new search leads to a direct comparison to the existing database, and at the same time gets added to it as well!

How we built it

Used a Natural Language Processing framework Spacy to parse various resume formats and search for skills. Use existing dictionary to segment these skills in their relative fields(programming, databases, hobbies). Used bokeh to visualize the top skills in a domain of study relative to any resume. Lastly built a wrapper using Flask to pull new data and push visualizations to the front end. 

Challenges we ran into

Finding resumes from our peers, being able to integrate html with flask. 

Accomplishments that we're proud of

Being able to provide highly relevant data to any student who wants to learn more and be able to understand what skills he/she should pursue next. 

What we learned

We learned to create a much bigger vision from our proof of concept. The immense amount of relevant data and insights we can get from people around us will always be helpful!

What's next for PeerSkills

Expand the database to all subjects, not just at Penn State, but to Universities around the world. 
Building a recommendation system based on the data from current students and alumni, to predict what skill set is most valuable to land dream jobs!
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36358/zip_files/PeerSkills.zip,"python, spacy, flask, machine-learning, bokeh, pandas, math",penn state,"","",rwg5289,,,rwg5289@psu.edu,Pennsylvania State University,1,aka5704,Abhishek,Adhikari,aka5704@psu.edu
Best Social Good Hack from Fidelity Weekly Challenge,PeerSkills,50,https://hackpsu-fall-2018.devpost.com/submissions/102424-peerskills,"Inspiration

Uncertainty of what skills my peers have, can be overwhelming. Being able to find the top skills amongst my peers, I can feel confident in what I should learn next.

What it does

Creates a database of resumes within an area of study, and aggregates the skills amongst them. Any new search leads to a direct comparison to the existing database, and at the same time gets added to it as well!

How we built it

Used a Natural Language Processing framework Spacy to parse various resume formats and search for skills. Use existing dictionary to segment these skills in their relative fields(programming, databases, hobbies). Used bokeh to visualize the top skills in a domain of study relative to any resume. Lastly built a wrapper using Flask to pull new data and push visualizations to the front end. 

Challenges we ran into

Finding resumes from our peers, being able to integrate html with flask. 

Accomplishments that we're proud of

Being able to provide highly relevant data to any student who wants to learn more and be able to understand what skills he/she should pursue next. 

What we learned

We learned to create a much bigger vision from our proof of concept. The immense amount of relevant data and insights we can get from people around us will always be helpful!

What's next for PeerSkills

Expand the database to all subjects, not just at Penn State, but to Universities around the world. 
Building a recommendation system based on the data from current students and alumni, to predict what skill set is most valuable to land dream jobs!
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36358/zip_files/PeerSkills.zip,"python, spacy, flask, machine-learning, bokeh, pandas, math",penn state,"","",rwg5289,,,rwg5289@psu.edu,Pennsylvania State University,1,aka5704,Abhishek,Adhikari,aka5704@psu.edu
JPMC - Best Social Good Hack,PeerSkills,50,https://hackpsu-fall-2018.devpost.com/submissions/102424-peerskills,"Inspiration

Uncertainty of what skills my peers have, can be overwhelming. Being able to find the top skills amongst my peers, I can feel confident in what I should learn next.

What it does

Creates a database of resumes within an area of study, and aggregates the skills amongst them. Any new search leads to a direct comparison to the existing database, and at the same time gets added to it as well!

How we built it

Used a Natural Language Processing framework Spacy to parse various resume formats and search for skills. Use existing dictionary to segment these skills in their relative fields(programming, databases, hobbies). Used bokeh to visualize the top skills in a domain of study relative to any resume. Lastly built a wrapper using Flask to pull new data and push visualizations to the front end. 

Challenges we ran into

Finding resumes from our peers, being able to integrate html with flask. 

Accomplishments that we're proud of

Being able to provide highly relevant data to any student who wants to learn more and be able to understand what skills he/she should pursue next. 

What we learned

We learned to create a much bigger vision from our proof of concept. The immense amount of relevant data and insights we can get from people around us will always be helpful!

What's next for PeerSkills

Expand the database to all subjects, not just at Penn State, but to Universities around the world. 
Building a recommendation system based on the data from current students and alumni, to predict what skill set is most valuable to land dream jobs!
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36358/zip_files/PeerSkills.zip,"python, spacy, flask, machine-learning, bokeh, pandas, math",penn state,"","",rwg5289,,,rwg5289@psu.edu,Pennsylvania State University,1,aka5704,Abhishek,Adhikari,aka5704@psu.edu
Snap Kit Weekly Challenge,AIODA,31,https://hackpsu-fall-2018.devpost.com/submissions/102425-aioda,"Inspiration

** We understand how annoying it is to wait for weeks speak to an adviser, and just for a simple question that wouldn't even take 5 minutes to answer, so we wanted to create a chat bot that could answer simple advising questions to help ease the load advisers have to work, while simultaneously answering advising questions for students so they don't have to wait so long for an appointment with their academic divisors at the same time.

What it does

It creates a chat bot that, when asked specific questions like how many credits do I need to graduate, will read the students academic requirements and inform the student on what they need and print out a response that will answer their questions.

How we built it

Used student Transcript data, read what we needed into python scripts, imported the data received into Google's Firebase, connected with DialogFlow's chat bot, and save all conversations to perform sentiment analysis.

Challenges we ran into

Using the sentiment analysis properly.
Integrating multiple platforms.

Accomplishments that we're proud of

Creating the chat bot using dialogflow to help students have on-demand access to an advisor
Providing sentimental analysis for advisors to better understand their students 

What we learned

How to use sentiment analysis, and Google's FIrebase. Integrating multiple platforms. 

What's next for AIODA

In the future, we want to accomplish the following objectives:
-Integrate the system into devices such as Google Home & Amazon Alexa
-Live chat with an actual advisor upon request
-Expand Use Cases to customized schedules for students
-Cloud produced reports of student queries for Advisors to keep track of their students
-Integrate into other universities’ existing systems
-Generate visualization for sentimental analysis using the Google Charts API
",https://www.youtube.com/watch?v=FrQeg_mXV48&feature=youtu.be,https://github.com/spearman666/HackPSU,,"natural-language-processing, ai-applied-sentiment-analysis, python, live2support-live-chat",Penn State University,Google Cloud Platform,"",austingongora13,Austin,Gongora,austingongora13@gmail.com,Pennsylvania State University,4,spearman666,Marshall,Malino,mr.marshalls.email@gmail.com,nitya-govind,nitya-govind,,nityagovind16@gmail.com,muk246,muk246,,mukeshkandamaran@hotmail.com,kamakayasilva,Rommel,Silva,kamakayasilva@gmail.com
Best use of Google Cloud Platform,AIODA,31,https://hackpsu-fall-2018.devpost.com/submissions/102425-aioda,"Inspiration

** We understand how annoying it is to wait for weeks speak to an adviser, and just for a simple question that wouldn't even take 5 minutes to answer, so we wanted to create a chat bot that could answer simple advising questions to help ease the load advisers have to work, while simultaneously answering advising questions for students so they don't have to wait so long for an appointment with their academic divisors at the same time.

What it does

It creates a chat bot that, when asked specific questions like how many credits do I need to graduate, will read the students academic requirements and inform the student on what they need and print out a response that will answer their questions.

How we built it

Used student Transcript data, read what we needed into python scripts, imported the data received into Google's Firebase, connected with DialogFlow's chat bot, and save all conversations to perform sentiment analysis.

Challenges we ran into

Using the sentiment analysis properly.
Integrating multiple platforms.

Accomplishments that we're proud of

Creating the chat bot using dialogflow to help students have on-demand access to an advisor
Providing sentimental analysis for advisors to better understand their students 

What we learned

How to use sentiment analysis, and Google's FIrebase. Integrating multiple platforms. 

What's next for AIODA

In the future, we want to accomplish the following objectives:
-Integrate the system into devices such as Google Home & Amazon Alexa
-Live chat with an actual advisor upon request
-Expand Use Cases to customized schedules for students
-Cloud produced reports of student queries for Advisors to keep track of their students
-Integrate into other universities’ existing systems
-Generate visualization for sentimental analysis using the Google Charts API
",https://www.youtube.com/watch?v=FrQeg_mXV48&feature=youtu.be,https://github.com/spearman666/HackPSU,,"natural-language-processing, ai-applied-sentiment-analysis, python, live2support-live-chat",Penn State University,Google Cloud Platform,"",austingongora13,Austin,Gongora,austingongora13@gmail.com,Pennsylvania State University,4,spearman666,Marshall,Malino,mr.marshalls.email@gmail.com,nitya-govind,nitya-govind,,nityagovind16@gmail.com,muk246,muk246,,mukeshkandamaran@hotmail.com,kamakayasilva,Rommel,Silva,kamakayasilva@gmail.com
Booz Allen Hamilton - Best Machine Learning Hack,AIODA,31,https://hackpsu-fall-2018.devpost.com/submissions/102425-aioda,"Inspiration

** We understand how annoying it is to wait for weeks speak to an adviser, and just for a simple question that wouldn't even take 5 minutes to answer, so we wanted to create a chat bot that could answer simple advising questions to help ease the load advisers have to work, while simultaneously answering advising questions for students so they don't have to wait so long for an appointment with their academic divisors at the same time.

What it does

It creates a chat bot that, when asked specific questions like how many credits do I need to graduate, will read the students academic requirements and inform the student on what they need and print out a response that will answer their questions.

How we built it

Used student Transcript data, read what we needed into python scripts, imported the data received into Google's Firebase, connected with DialogFlow's chat bot, and save all conversations to perform sentiment analysis.

Challenges we ran into

Using the sentiment analysis properly.
Integrating multiple platforms.

Accomplishments that we're proud of

Creating the chat bot using dialogflow to help students have on-demand access to an advisor
Providing sentimental analysis for advisors to better understand their students 

What we learned

How to use sentiment analysis, and Google's FIrebase. Integrating multiple platforms. 

What's next for AIODA

In the future, we want to accomplish the following objectives:
-Integrate the system into devices such as Google Home & Amazon Alexa
-Live chat with an actual advisor upon request
-Expand Use Cases to customized schedules for students
-Cloud produced reports of student queries for Advisors to keep track of their students
-Integrate into other universities’ existing systems
-Generate visualization for sentimental analysis using the Google Charts API
",https://www.youtube.com/watch?v=FrQeg_mXV48&feature=youtu.be,https://github.com/spearman666/HackPSU,,"natural-language-processing, ai-applied-sentiment-analysis, python, live2support-live-chat",Penn State University,Google Cloud Platform,"",austingongora13,Austin,Gongora,austingongora13@gmail.com,Pennsylvania State University,4,spearman666,Marshall,Malino,mr.marshalls.email@gmail.com,nitya-govind,nitya-govind,,nityagovind16@gmail.com,muk246,muk246,,mukeshkandamaran@hotmail.com,kamakayasilva,Rommel,Silva,kamakayasilva@gmail.com
Nittany AI Alliance - AI Challenge,AIODA,31,https://hackpsu-fall-2018.devpost.com/submissions/102425-aioda,"Inspiration

** We understand how annoying it is to wait for weeks speak to an adviser, and just for a simple question that wouldn't even take 5 minutes to answer, so we wanted to create a chat bot that could answer simple advising questions to help ease the load advisers have to work, while simultaneously answering advising questions for students so they don't have to wait so long for an appointment with their academic divisors at the same time.

What it does

It creates a chat bot that, when asked specific questions like how many credits do I need to graduate, will read the students academic requirements and inform the student on what they need and print out a response that will answer their questions.

How we built it

Used student Transcript data, read what we needed into python scripts, imported the data received into Google's Firebase, connected with DialogFlow's chat bot, and save all conversations to perform sentiment analysis.

Challenges we ran into

Using the sentiment analysis properly.
Integrating multiple platforms.

Accomplishments that we're proud of

Creating the chat bot using dialogflow to help students have on-demand access to an advisor
Providing sentimental analysis for advisors to better understand their students 

What we learned

How to use sentiment analysis, and Google's FIrebase. Integrating multiple platforms. 

What's next for AIODA

In the future, we want to accomplish the following objectives:
-Integrate the system into devices such as Google Home & Amazon Alexa
-Live chat with an actual advisor upon request
-Expand Use Cases to customized schedules for students
-Cloud produced reports of student queries for Advisors to keep track of their students
-Integrate into other universities’ existing systems
-Generate visualization for sentimental analysis using the Google Charts API
",https://www.youtube.com/watch?v=FrQeg_mXV48&feature=youtu.be,https://github.com/spearman666/HackPSU,,"natural-language-processing, ai-applied-sentiment-analysis, python, live2support-live-chat",Penn State University,Google Cloud Platform,"",austingongora13,Austin,Gongora,austingongora13@gmail.com,Pennsylvania State University,4,spearman666,Marshall,Malino,mr.marshalls.email@gmail.com,nitya-govind,nitya-govind,,nityagovind16@gmail.com,muk246,muk246,,mukeshkandamaran@hotmail.com,kamakayasilva,Rommel,Silva,kamakayasilva@gmail.com
Best Social Good Hack from Fidelity Weekly Challenge,AIODA,31,https://hackpsu-fall-2018.devpost.com/submissions/102425-aioda,"Inspiration

** We understand how annoying it is to wait for weeks speak to an adviser, and just for a simple question that wouldn't even take 5 minutes to answer, so we wanted to create a chat bot that could answer simple advising questions to help ease the load advisers have to work, while simultaneously answering advising questions for students so they don't have to wait so long for an appointment with their academic divisors at the same time.

What it does

It creates a chat bot that, when asked specific questions like how many credits do I need to graduate, will read the students academic requirements and inform the student on what they need and print out a response that will answer their questions.

How we built it

Used student Transcript data, read what we needed into python scripts, imported the data received into Google's Firebase, connected with DialogFlow's chat bot, and save all conversations to perform sentiment analysis.

Challenges we ran into

Using the sentiment analysis properly.
Integrating multiple platforms.

Accomplishments that we're proud of

Creating the chat bot using dialogflow to help students have on-demand access to an advisor
Providing sentimental analysis for advisors to better understand their students 

What we learned

How to use sentiment analysis, and Google's FIrebase. Integrating multiple platforms. 

What's next for AIODA

In the future, we want to accomplish the following objectives:
-Integrate the system into devices such as Google Home & Amazon Alexa
-Live chat with an actual advisor upon request
-Expand Use Cases to customized schedules for students
-Cloud produced reports of student queries for Advisors to keep track of their students
-Integrate into other universities’ existing systems
-Generate visualization for sentimental analysis using the Google Charts API
",https://www.youtube.com/watch?v=FrQeg_mXV48&feature=youtu.be,https://github.com/spearman666/HackPSU,,"natural-language-processing, ai-applied-sentiment-analysis, python, live2support-live-chat",Penn State University,Google Cloud Platform,"",austingongora13,Austin,Gongora,austingongora13@gmail.com,Pennsylvania State University,4,spearman666,Marshall,Malino,mr.marshalls.email@gmail.com,nitya-govind,nitya-govind,,nityagovind16@gmail.com,muk246,muk246,,mukeshkandamaran@hotmail.com,kamakayasilva,Rommel,Silva,kamakayasilva@gmail.com
JPMC - Best Social Good Hack,AIODA,31,https://hackpsu-fall-2018.devpost.com/submissions/102425-aioda,"Inspiration

** We understand how annoying it is to wait for weeks speak to an adviser, and just for a simple question that wouldn't even take 5 minutes to answer, so we wanted to create a chat bot that could answer simple advising questions to help ease the load advisers have to work, while simultaneously answering advising questions for students so they don't have to wait so long for an appointment with their academic divisors at the same time.

What it does

It creates a chat bot that, when asked specific questions like how many credits do I need to graduate, will read the students academic requirements and inform the student on what they need and print out a response that will answer their questions.

How we built it

Used student Transcript data, read what we needed into python scripts, imported the data received into Google's Firebase, connected with DialogFlow's chat bot, and save all conversations to perform sentiment analysis.

Challenges we ran into

Using the sentiment analysis properly.
Integrating multiple platforms.

Accomplishments that we're proud of

Creating the chat bot using dialogflow to help students have on-demand access to an advisor
Providing sentimental analysis for advisors to better understand their students 

What we learned

How to use sentiment analysis, and Google's FIrebase. Integrating multiple platforms. 

What's next for AIODA

In the future, we want to accomplish the following objectives:
-Integrate the system into devices such as Google Home & Amazon Alexa
-Live chat with an actual advisor upon request
-Expand Use Cases to customized schedules for students
-Cloud produced reports of student queries for Advisors to keep track of their students
-Integrate into other universities’ existing systems
-Generate visualization for sentimental analysis using the Google Charts API
",https://www.youtube.com/watch?v=FrQeg_mXV48&feature=youtu.be,https://github.com/spearman666/HackPSU,,"natural-language-processing, ai-applied-sentiment-analysis, python, live2support-live-chat",Penn State University,Google Cloud Platform,"",austingongora13,Austin,Gongora,austingongora13@gmail.com,Pennsylvania State University,4,spearman666,Marshall,Malino,mr.marshalls.email@gmail.com,nitya-govind,nitya-govind,,nityagovind16@gmail.com,muk246,muk246,,mukeshkandamaran@hotmail.com,kamakayasilva,Rommel,Silva,kamakayasilva@gmail.com
HackPSU Overall - Design,Vallis,25,https://hackpsu-fall-2018.devpost.com/submissions/102426-vallis,"Inspiration

Park Rangers currently have no way to conveniently and effectively organize their data on visitors, conservation, co-workers, and incidents.

What it does

Vallis provides a web-based solution for Park Rangers to help manage their data while in the office or at home. It also provides a solution to help manage their team and other visitors that they encounter. This helps complement in-field communication, where radio is the most effective.

How I built it

Performed user research on Park Rangers and their day-to-day duties and struggles. Then, took these ideas and built content sketches and wireframes to organize screens and ideas. From there, built high fidelity mockups to showcase branding and styling.

Challenges I ran into

Finding the right platform based on restrictions and user needs, organizing use cases into certain pages based on functions.

Accomplishments that I'm proud of

Aesthetics and page organization, finding the best platform for the end-user.

What I learned

How to best create a product tailored for the end-user by utilizing user research and wireframes.

What's next for Vallis

Development!
",,https://sketch.cloud/s/bamgO,https://s3.amazonaws.com/challengepost/zip_files/production/36331/zip_files/vallis.zip,sketch,Penn State University,"","",ScottLuttmann,Scott,Luttmann,scottlutt8@gmail.com,Pennsylvania State University,1,AidenSmith,Aiden,Smith,aiden.s.98@gmail.com
Best IoT Hack Using a Qualcomm Device,Trigger Happy,24,https://hackpsu-fall-2018.devpost.com/submissions/102427-trigger-happy,"Inspiration

Our team was inspired by the current news in the media involving deaths that could have been preventable with better technology. A large amount of police brutality news articles showed up, and we realized maybe we can't solve all the sentiment behind the police in the world, but maybe we can improve the statistics with a bit of machine learning.

What it does

We've invented an augmented police handgun that scans an individual while out of holster, and prevents firing lethal bullets. We know that guns protect, but they can also kill. However, shots that occur on the arms and below the waist are less likely to cause death while still getting the job done in stopping or preventing an individual from continuing fire.

How we built it

We used a webcam held on the front of the handgun to feed in footage to a machine learning algorithm that has been trained with a human pose recognition model. Then we calculate where the projectile will impact, and enable/disable the safety lock on the handgun appropriately. There is a visual screen to display whether the safety is on or off, as well as a mobile app accompaniment.

Challenges we ran into

The original plan was to make the processing completely run on the handgun. We checked out every Dragonboard offered by MLH, and all of them had a hardware issue at some point limiting us from implementing our development package. So we resorted to an arduino and on computer computation.

We also ran into issues with AWS. We met with AWS mentors at the booth and they were also unsure why the tutorial provided by Amazon was not working. They ended up filing a help ticket for us. As a result, we downloaded and executed our selected ML model locally on a Node.js server. 

Accomplishments that we're proud of

Our nerf gun looks realy cool. Our pose detection UI looks amazing. The arduino perfectly implements the visuals on the nerf gun.

What we learned

We learned how to implement TenserFlow onto Dragonboards, AWS, and Node.js servers. We learned how to use arduino to power lcd displays. We learned about how to access a webcam as a peripheral. We learned Dragonboards are not worth the time that MLH wants us to put into them. 

What's next for Trigger Happy

In the future, we would like for out handgun to be more compact and all onboard the handgun. We would furthermore attach our mobile app to registered gun users as a way to track the history and environment surrounding each fire of the weapon. The hope is that this can be used by law enforcement or individuals in legal matters as well as lower the number of shooting related deaths. 
Removing guns is an answer, but it's not a practical one. With technology, we can make them safer, without losing the effectiveness in their purpose.
",,https://github.com/tkbeal/trigger-happy,,"tenserflow, node.js, arduino, java, 5-below-not-nerf-guns, amazon-web-services, react-native, expo.io","University or Maryland, College Park","","",Esaych,Sam,Holmberg,holmberg.d.samuel@gmail.com,University of Maryland - College Park,3,09wakharet,Tanay,Wakhare,twakhare@gmail.com,robbieguy98,Robbie,Morrison,robbieguy98@gmail.com,kev3200,Kevin,Beal,kev3200@gmail.com
AWS Challenge,Trigger Happy,24,https://hackpsu-fall-2018.devpost.com/submissions/102427-trigger-happy,"Inspiration

Our team was inspired by the current news in the media involving deaths that could have been preventable with better technology. A large amount of police brutality news articles showed up, and we realized maybe we can't solve all the sentiment behind the police in the world, but maybe we can improve the statistics with a bit of machine learning.

What it does

We've invented an augmented police handgun that scans an individual while out of holster, and prevents firing lethal bullets. We know that guns protect, but they can also kill. However, shots that occur on the arms and below the waist are less likely to cause death while still getting the job done in stopping or preventing an individual from continuing fire.

How we built it

We used a webcam held on the front of the handgun to feed in footage to a machine learning algorithm that has been trained with a human pose recognition model. Then we calculate where the projectile will impact, and enable/disable the safety lock on the handgun appropriately. There is a visual screen to display whether the safety is on or off, as well as a mobile app accompaniment.

Challenges we ran into

The original plan was to make the processing completely run on the handgun. We checked out every Dragonboard offered by MLH, and all of them had a hardware issue at some point limiting us from implementing our development package. So we resorted to an arduino and on computer computation.

We also ran into issues with AWS. We met with AWS mentors at the booth and they were also unsure why the tutorial provided by Amazon was not working. They ended up filing a help ticket for us. As a result, we downloaded and executed our selected ML model locally on a Node.js server. 

Accomplishments that we're proud of

Our nerf gun looks realy cool. Our pose detection UI looks amazing. The arduino perfectly implements the visuals on the nerf gun.

What we learned

We learned how to implement TenserFlow onto Dragonboards, AWS, and Node.js servers. We learned how to use arduino to power lcd displays. We learned about how to access a webcam as a peripheral. We learned Dragonboards are not worth the time that MLH wants us to put into them. 

What's next for Trigger Happy

In the future, we would like for out handgun to be more compact and all onboard the handgun. We would furthermore attach our mobile app to registered gun users as a way to track the history and environment surrounding each fire of the weapon. The hope is that this can be used by law enforcement or individuals in legal matters as well as lower the number of shooting related deaths. 
Removing guns is an answer, but it's not a practical one. With technology, we can make them safer, without losing the effectiveness in their purpose.
",,https://github.com/tkbeal/trigger-happy,,"tenserflow, node.js, arduino, java, 5-below-not-nerf-guns, amazon-web-services, react-native, expo.io","University or Maryland, College Park","","",Esaych,Sam,Holmberg,holmberg.d.samuel@gmail.com,University of Maryland - College Park,3,09wakharet,Tanay,Wakhare,twakhare@gmail.com,robbieguy98,Robbie,Morrison,robbieguy98@gmail.com,kev3200,Kevin,Beal,kev3200@gmail.com
Booz Allen Hamilton - Best Machine Learning Hack,Trigger Happy,24,https://hackpsu-fall-2018.devpost.com/submissions/102427-trigger-happy,"Inspiration

Our team was inspired by the current news in the media involving deaths that could have been preventable with better technology. A large amount of police brutality news articles showed up, and we realized maybe we can't solve all the sentiment behind the police in the world, but maybe we can improve the statistics with a bit of machine learning.

What it does

We've invented an augmented police handgun that scans an individual while out of holster, and prevents firing lethal bullets. We know that guns protect, but they can also kill. However, shots that occur on the arms and below the waist are less likely to cause death while still getting the job done in stopping or preventing an individual from continuing fire.

How we built it

We used a webcam held on the front of the handgun to feed in footage to a machine learning algorithm that has been trained with a human pose recognition model. Then we calculate where the projectile will impact, and enable/disable the safety lock on the handgun appropriately. There is a visual screen to display whether the safety is on or off, as well as a mobile app accompaniment.

Challenges we ran into

The original plan was to make the processing completely run on the handgun. We checked out every Dragonboard offered by MLH, and all of them had a hardware issue at some point limiting us from implementing our development package. So we resorted to an arduino and on computer computation.

We also ran into issues with AWS. We met with AWS mentors at the booth and they were also unsure why the tutorial provided by Amazon was not working. They ended up filing a help ticket for us. As a result, we downloaded and executed our selected ML model locally on a Node.js server. 

Accomplishments that we're proud of

Our nerf gun looks realy cool. Our pose detection UI looks amazing. The arduino perfectly implements the visuals on the nerf gun.

What we learned

We learned how to implement TenserFlow onto Dragonboards, AWS, and Node.js servers. We learned how to use arduino to power lcd displays. We learned about how to access a webcam as a peripheral. We learned Dragonboards are not worth the time that MLH wants us to put into them. 

What's next for Trigger Happy

In the future, we would like for out handgun to be more compact and all onboard the handgun. We would furthermore attach our mobile app to registered gun users as a way to track the history and environment surrounding each fire of the weapon. The hope is that this can be used by law enforcement or individuals in legal matters as well as lower the number of shooting related deaths. 
Removing guns is an answer, but it's not a practical one. With technology, we can make them safer, without losing the effectiveness in their purpose.
",,https://github.com/tkbeal/trigger-happy,,"tenserflow, node.js, arduino, java, 5-below-not-nerf-guns, amazon-web-services, react-native, expo.io","University or Maryland, College Park","","",Esaych,Sam,Holmberg,holmberg.d.samuel@gmail.com,University of Maryland - College Park,3,09wakharet,Tanay,Wakhare,twakhare@gmail.com,robbieguy98,Robbie,Morrison,robbieguy98@gmail.com,kev3200,Kevin,Beal,kev3200@gmail.com
Nittany AI Alliance - AI Challenge,Trigger Happy,24,https://hackpsu-fall-2018.devpost.com/submissions/102427-trigger-happy,"Inspiration

Our team was inspired by the current news in the media involving deaths that could have been preventable with better technology. A large amount of police brutality news articles showed up, and we realized maybe we can't solve all the sentiment behind the police in the world, but maybe we can improve the statistics with a bit of machine learning.

What it does

We've invented an augmented police handgun that scans an individual while out of holster, and prevents firing lethal bullets. We know that guns protect, but they can also kill. However, shots that occur on the arms and below the waist are less likely to cause death while still getting the job done in stopping or preventing an individual from continuing fire.

How we built it

We used a webcam held on the front of the handgun to feed in footage to a machine learning algorithm that has been trained with a human pose recognition model. Then we calculate where the projectile will impact, and enable/disable the safety lock on the handgun appropriately. There is a visual screen to display whether the safety is on or off, as well as a mobile app accompaniment.

Challenges we ran into

The original plan was to make the processing completely run on the handgun. We checked out every Dragonboard offered by MLH, and all of them had a hardware issue at some point limiting us from implementing our development package. So we resorted to an arduino and on computer computation.

We also ran into issues with AWS. We met with AWS mentors at the booth and they were also unsure why the tutorial provided by Amazon was not working. They ended up filing a help ticket for us. As a result, we downloaded and executed our selected ML model locally on a Node.js server. 

Accomplishments that we're proud of

Our nerf gun looks realy cool. Our pose detection UI looks amazing. The arduino perfectly implements the visuals on the nerf gun.

What we learned

We learned how to implement TenserFlow onto Dragonboards, AWS, and Node.js servers. We learned how to use arduino to power lcd displays. We learned about how to access a webcam as a peripheral. We learned Dragonboards are not worth the time that MLH wants us to put into them. 

What's next for Trigger Happy

In the future, we would like for out handgun to be more compact and all onboard the handgun. We would furthermore attach our mobile app to registered gun users as a way to track the history and environment surrounding each fire of the weapon. The hope is that this can be used by law enforcement or individuals in legal matters as well as lower the number of shooting related deaths. 
Removing guns is an answer, but it's not a practical one. With technology, we can make them safer, without losing the effectiveness in their purpose.
",,https://github.com/tkbeal/trigger-happy,,"tenserflow, node.js, arduino, java, 5-below-not-nerf-guns, amazon-web-services, react-native, expo.io","University or Maryland, College Park","","",Esaych,Sam,Holmberg,holmberg.d.samuel@gmail.com,University of Maryland - College Park,3,09wakharet,Tanay,Wakhare,twakhare@gmail.com,robbieguy98,Robbie,Morrison,robbieguy98@gmail.com,kev3200,Kevin,Beal,kev3200@gmail.com
HackPSU Overall - Tech,Trigger Happy,24,https://hackpsu-fall-2018.devpost.com/submissions/102427-trigger-happy,"Inspiration

Our team was inspired by the current news in the media involving deaths that could have been preventable with better technology. A large amount of police brutality news articles showed up, and we realized maybe we can't solve all the sentiment behind the police in the world, but maybe we can improve the statistics with a bit of machine learning.

What it does

We've invented an augmented police handgun that scans an individual while out of holster, and prevents firing lethal bullets. We know that guns protect, but they can also kill. However, shots that occur on the arms and below the waist are less likely to cause death while still getting the job done in stopping or preventing an individual from continuing fire.

How we built it

We used a webcam held on the front of the handgun to feed in footage to a machine learning algorithm that has been trained with a human pose recognition model. Then we calculate where the projectile will impact, and enable/disable the safety lock on the handgun appropriately. There is a visual screen to display whether the safety is on or off, as well as a mobile app accompaniment.

Challenges we ran into

The original plan was to make the processing completely run on the handgun. We checked out every Dragonboard offered by MLH, and all of them had a hardware issue at some point limiting us from implementing our development package. So we resorted to an arduino and on computer computation.

We also ran into issues with AWS. We met with AWS mentors at the booth and they were also unsure why the tutorial provided by Amazon was not working. They ended up filing a help ticket for us. As a result, we downloaded and executed our selected ML model locally on a Node.js server. 

Accomplishments that we're proud of

Our nerf gun looks realy cool. Our pose detection UI looks amazing. The arduino perfectly implements the visuals on the nerf gun.

What we learned

We learned how to implement TenserFlow onto Dragonboards, AWS, and Node.js servers. We learned how to use arduino to power lcd displays. We learned about how to access a webcam as a peripheral. We learned Dragonboards are not worth the time that MLH wants us to put into them. 

What's next for Trigger Happy

In the future, we would like for out handgun to be more compact and all onboard the handgun. We would furthermore attach our mobile app to registered gun users as a way to track the history and environment surrounding each fire of the weapon. The hope is that this can be used by law enforcement or individuals in legal matters as well as lower the number of shooting related deaths. 
Removing guns is an answer, but it's not a practical one. With technology, we can make them safer, without losing the effectiveness in their purpose.
",,https://github.com/tkbeal/trigger-happy,,"tenserflow, node.js, arduino, java, 5-below-not-nerf-guns, amazon-web-services, react-native, expo.io","University or Maryland, College Park","","",Esaych,Sam,Holmberg,holmberg.d.samuel@gmail.com,University of Maryland - College Park,3,09wakharet,Tanay,Wakhare,twakhare@gmail.com,robbieguy98,Robbie,Morrison,robbieguy98@gmail.com,kev3200,Kevin,Beal,kev3200@gmail.com
Best Social Good Hack from Fidelity Weekly Challenge,Trigger Happy,24,https://hackpsu-fall-2018.devpost.com/submissions/102427-trigger-happy,"Inspiration

Our team was inspired by the current news in the media involving deaths that could have been preventable with better technology. A large amount of police brutality news articles showed up, and we realized maybe we can't solve all the sentiment behind the police in the world, but maybe we can improve the statistics with a bit of machine learning.

What it does

We've invented an augmented police handgun that scans an individual while out of holster, and prevents firing lethal bullets. We know that guns protect, but they can also kill. However, shots that occur on the arms and below the waist are less likely to cause death while still getting the job done in stopping or preventing an individual from continuing fire.

How we built it

We used a webcam held on the front of the handgun to feed in footage to a machine learning algorithm that has been trained with a human pose recognition model. Then we calculate where the projectile will impact, and enable/disable the safety lock on the handgun appropriately. There is a visual screen to display whether the safety is on or off, as well as a mobile app accompaniment.

Challenges we ran into

The original plan was to make the processing completely run on the handgun. We checked out every Dragonboard offered by MLH, and all of them had a hardware issue at some point limiting us from implementing our development package. So we resorted to an arduino and on computer computation.

We also ran into issues with AWS. We met with AWS mentors at the booth and they were also unsure why the tutorial provided by Amazon was not working. They ended up filing a help ticket for us. As a result, we downloaded and executed our selected ML model locally on a Node.js server. 

Accomplishments that we're proud of

Our nerf gun looks realy cool. Our pose detection UI looks amazing. The arduino perfectly implements the visuals on the nerf gun.

What we learned

We learned how to implement TenserFlow onto Dragonboards, AWS, and Node.js servers. We learned how to use arduino to power lcd displays. We learned about how to access a webcam as a peripheral. We learned Dragonboards are not worth the time that MLH wants us to put into them. 

What's next for Trigger Happy

In the future, we would like for out handgun to be more compact and all onboard the handgun. We would furthermore attach our mobile app to registered gun users as a way to track the history and environment surrounding each fire of the weapon. The hope is that this can be used by law enforcement or individuals in legal matters as well as lower the number of shooting related deaths. 
Removing guns is an answer, but it's not a practical one. With technology, we can make them safer, without losing the effectiveness in their purpose.
",,https://github.com/tkbeal/trigger-happy,,"tenserflow, node.js, arduino, java, 5-below-not-nerf-guns, amazon-web-services, react-native, expo.io","University or Maryland, College Park","","",Esaych,Sam,Holmberg,holmberg.d.samuel@gmail.com,University of Maryland - College Park,3,09wakharet,Tanay,Wakhare,twakhare@gmail.com,robbieguy98,Robbie,Morrison,robbieguy98@gmail.com,kev3200,Kevin,Beal,kev3200@gmail.com
JPMC - Best Social Good Hack,Trigger Happy,24,https://hackpsu-fall-2018.devpost.com/submissions/102427-trigger-happy,"Inspiration

Our team was inspired by the current news in the media involving deaths that could have been preventable with better technology. A large amount of police brutality news articles showed up, and we realized maybe we can't solve all the sentiment behind the police in the world, but maybe we can improve the statistics with a bit of machine learning.

What it does

We've invented an augmented police handgun that scans an individual while out of holster, and prevents firing lethal bullets. We know that guns protect, but they can also kill. However, shots that occur on the arms and below the waist are less likely to cause death while still getting the job done in stopping or preventing an individual from continuing fire.

How we built it

We used a webcam held on the front of the handgun to feed in footage to a machine learning algorithm that has been trained with a human pose recognition model. Then we calculate where the projectile will impact, and enable/disable the safety lock on the handgun appropriately. There is a visual screen to display whether the safety is on or off, as well as a mobile app accompaniment.

Challenges we ran into

The original plan was to make the processing completely run on the handgun. We checked out every Dragonboard offered by MLH, and all of them had a hardware issue at some point limiting us from implementing our development package. So we resorted to an arduino and on computer computation.

We also ran into issues with AWS. We met with AWS mentors at the booth and they were also unsure why the tutorial provided by Amazon was not working. They ended up filing a help ticket for us. As a result, we downloaded and executed our selected ML model locally on a Node.js server. 

Accomplishments that we're proud of

Our nerf gun looks realy cool. Our pose detection UI looks amazing. The arduino perfectly implements the visuals on the nerf gun.

What we learned

We learned how to implement TenserFlow onto Dragonboards, AWS, and Node.js servers. We learned how to use arduino to power lcd displays. We learned about how to access a webcam as a peripheral. We learned Dragonboards are not worth the time that MLH wants us to put into them. 

What's next for Trigger Happy

In the future, we would like for out handgun to be more compact and all onboard the handgun. We would furthermore attach our mobile app to registered gun users as a way to track the history and environment surrounding each fire of the weapon. The hope is that this can be used by law enforcement or individuals in legal matters as well as lower the number of shooting related deaths. 
Removing guns is an answer, but it's not a practical one. With technology, we can make them safer, without losing the effectiveness in their purpose.
",,https://github.com/tkbeal/trigger-happy,,"tenserflow, node.js, arduino, java, 5-below-not-nerf-guns, amazon-web-services, react-native, expo.io","University or Maryland, College Park","","",Esaych,Sam,Holmberg,holmberg.d.samuel@gmail.com,University of Maryland - College Park,3,09wakharet,Tanay,Wakhare,twakhare@gmail.com,robbieguy98,Robbie,Morrison,robbieguy98@gmail.com,kev3200,Kevin,Beal,kev3200@gmail.com
"",budget crusher,67,https://hackpsu-fall-2018.devpost.com/submissions/102428-budget-crusher,"Inspiration

For a long time, my partner wants me to record every expenditure, but I think those applications are troublesome because I always need to enter the amount and date. We want to develop a projects that makes the process easier.

What it does

BUDGET CRUSHER records and organizes your consumption records every day and helps you become rich!
First, set your weekly budget. When using it, take a picture of your receipt after shopping. This ""budget crusher"" would automatically generate the date, amount and the balance of this week. Once you exceed this week's budget, the bomb will explode.

Challenges we ran into

How our coding recognize text using OCR(Optical Character Recognition). 

Accomplishments that we're proud of

We generated our own ideas, cooperated perfectly and completed it.

What's next for budget crusher

More functions are on the way......
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36332/zip_files/budget_crusher.zip,"python, google-cloud-vision, machine-learning, optical-character-recognition",Penn State University,"","",qjc5030,Qingyuan,Chen,qjc5030@psu.edu,Pennsylvania State University,1,tigerwang3133,ziyang,wang,tigerwang3133@gmail.com
"",WeatherOrNot,34,https://hackpsu-fall-2018.devpost.com/submissions/102429-weatherornot,"Inspiration


Everyone has a bucketlist of places they want to visit. They just can't figure when is the best time to go. 
Even if they find that they find it difficult to get the best deals. 


We ourselves love to travel and we are from a small country where the weather is predictable and doesn't change much. We are not used to checking the weather before travelling. We just look outside and leave the house or book tickets. 

What if while booking tickets we could get smart suggestions of where to go next on the basis of the best weather conditions and the cheapest flight tickets for places in your bucketlist!

What it does


It scraps trip adviser to get the best weather condition for that place
It scraps Google Flights for Flight information
It queries AccuWeather's api to get the forecast of the next 15 days
Does some magic ! and BOOM you are presented with a sorted list of places with the best weather and cheapest tickets


How we built it

We built it using python scrapers - beautiful soup. The website framework used is flask. The UI framework is Bootstrap. The backend is mostly python code.

Challenges we ran into


Flights API are not free ! Skyscanner works with companies to get that data to you. But they take a lot of time to process and you are contacted by there representative. So, we just scraped the data for particular dates.
Dynamically getting weather data is possible but getting flight details is not. You require special access to do that for particular dates


Accomplishments that we're proud of


Our core algorithm works pretty well and the suggestions do make sense !
We were able to find workarounds by scraping the web
It saves you time. Just with simple clicks you can get something which earlier took a lot of time and effort 
Choosing from a list of things makes the bucketlist truly personal which we appreciate a lot
We get the best weather according to that place ! The ""best"" is dynamic and depends on the place.


What we learned


Getting flight booking details is tough !
Weather can make or break your vacation


What's next for WeatherOrNot


We would like to do it for further dates as well using the past years predictions
Partner with flight booking websites to get richer flight details
Add activities to the interface ! If it is sunny go for a hike/ go to the beach ! The users can define what they want to do and we can suggest the place

",,https://github.com/shauryr/WeatherOrNot,https://s3.amazonaws.com/challengepost/zip_files/production/36333/zip_files/Hack2018.zip,"python, accuweather, web-crawling, web-scrape-master",Penn State,"","",ShauryaRohatgi,Shaurya,Rohatgi,shauryr@gmail.com,Pennsylvania State University,0
Best Domain Name from Domain.com,Duckie Rodeo,65,https://hackpsu-fall-2018.devpost.com/submissions/102430-duckie-rodeo,"Duckie Rodeo

Overview

Duckie Rodeo is a web-controlled Duckie Bot that features multiple driving modes. Modes include:


Default
Mirror
Squid
Drunken


All modes allow users to drive the Duckie Bot remotely using the on-board camera and wasd inputs. The default mode presents the camera's view without modification and translates inputs directly. Other modes uniquely distort the user's view and inputs.

Components

Raspberry pi, motor control shield, 2x DC motors, camera  

Refer to flow charts for summary of software.

AdafruitMotorHAT used to drive DC motors.

This project has been set up using PyScaffold 3.0.3. For details and usage
information on PyScaffold see http://pyscaffold.org/.
",,https://github.com/gregjhansell97/DuckieBot,,"python, raspberry-pi, cv","Rensselaer Polytechnic, University of Maine, Capitol tech, UVA",Domain.com,"",taylorbrian77,taylorbrian77,,taylorbrian77@gmail.com,"University of Maine, Rensselaer Polytechnic Institute, Capitol Technology University, University of Virginia",4,gregjhansell97,Greg,Hansell,gregjhansell@gmail.com,randypowell10,randypowell10,,randypowell10@yahoo.com,arthurhhe,Arthur,He,arthurhe8@gmail.com,eliasa3,Alex,Elias,eliasa3@rpi.edu
HackPSU Overall - Design,Duckie Rodeo,65,https://hackpsu-fall-2018.devpost.com/submissions/102430-duckie-rodeo,"Duckie Rodeo

Overview

Duckie Rodeo is a web-controlled Duckie Bot that features multiple driving modes. Modes include:


Default
Mirror
Squid
Drunken


All modes allow users to drive the Duckie Bot remotely using the on-board camera and wasd inputs. The default mode presents the camera's view without modification and translates inputs directly. Other modes uniquely distort the user's view and inputs.

Components

Raspberry pi, motor control shield, 2x DC motors, camera  

Refer to flow charts for summary of software.

AdafruitMotorHAT used to drive DC motors.

This project has been set up using PyScaffold 3.0.3. For details and usage
information on PyScaffold see http://pyscaffold.org/.
",,https://github.com/gregjhansell97/DuckieBot,,"python, raspberry-pi, cv","Rensselaer Polytechnic, University of Maine, Capitol tech, UVA",Domain.com,"",taylorbrian77,taylorbrian77,,taylorbrian77@gmail.com,"University of Maine, Rensselaer Polytechnic Institute, Capitol Technology University, University of Virginia",4,gregjhansell97,Greg,Hansell,gregjhansell@gmail.com,randypowell10,randypowell10,,randypowell10@yahoo.com,arthurhhe,Arthur,He,arthurhe8@gmail.com,eliasa3,Alex,Elias,eliasa3@rpi.edu
HackPSU Overall - Tech,Duckie Rodeo,65,https://hackpsu-fall-2018.devpost.com/submissions/102430-duckie-rodeo,"Duckie Rodeo

Overview

Duckie Rodeo is a web-controlled Duckie Bot that features multiple driving modes. Modes include:


Default
Mirror
Squid
Drunken


All modes allow users to drive the Duckie Bot remotely using the on-board camera and wasd inputs. The default mode presents the camera's view without modification and translates inputs directly. Other modes uniquely distort the user's view and inputs.

Components

Raspberry pi, motor control shield, 2x DC motors, camera  

Refer to flow charts for summary of software.

AdafruitMotorHAT used to drive DC motors.

This project has been set up using PyScaffold 3.0.3. For details and usage
information on PyScaffold see http://pyscaffold.org/.
",,https://github.com/gregjhansell97/DuckieBot,,"python, raspberry-pi, cv","Rensselaer Polytechnic, University of Maine, Capitol tech, UVA",Domain.com,"",taylorbrian77,taylorbrian77,,taylorbrian77@gmail.com,"University of Maine, Rensselaer Polytechnic Institute, Capitol Technology University, University of Virginia",4,gregjhansell97,Greg,Hansell,gregjhansell@gmail.com,randypowell10,randypowell10,,randypowell10@yahoo.com,arthurhhe,Arthur,He,arthurhe8@gmail.com,eliasa3,Alex,Elias,eliasa3@rpi.edu
Best use of Google Cloud Platform,Toxicity,49,https://hackpsu-fall-2018.devpost.com/submissions/102431-toxicity,"Inspiration

Reddit is one of the most popular websites in the world. However, since it is so popular, a wide variety of people post on the website allowing for a range of both nice and mean comments. Users looking for a new subreddit may be worried about how negative (or mean) a subreddit is. Moderators of subreddits or even administrators may use this tool to gauge the the types of responses a subreddit as a whole can be described by.

What it does

Toxicity uses Google Cloud's Language API to calculate the ""sentiment"" of several comments. The average of all comments is then calculated in order to find the overall ""mood"" of the subreddit inputted. Matplotlib and cgi are used to display box plots of the sentiment sampled comments, as well as creation of a word cloud for visualization.

How we built it

The backend of the program uses python. The frontend is made with HTML and CSS. The frontend and the backend communicate using the cgi library in python.

Challenges we ran into

Getting python and html to communicate was probably the most difficult part. It took 2 hours to fix this problem.

Accomplishments that we're proud of

We made a clean looking website that functions almost exactly as we expected it to. We are especially proud of the data visualization and frontend aesthetics.

What we learned

We learned a lot about Reddit's API and the Google Cloud API for data analysis. With the frustrations that came along the way, perhaps Javascript would have been better for frontend-backend integration than Python, but we knew how to implement the solution in Python much more strongly.

What's next for Toxicity

Getting it to run from an actual server, and not just our computers.
",,https://github.com/PScottZero/Toxicity-HackPSU-Fall2018,https://s3.amazonaws.com/challengepost/zip_files/production/36343/zip_files/Toxicity.zip,"google-cloud, python, html, css, matplotlib, cgi, xampp, praw",Penn State University Park,"","",PScottZero,Paul,Scott,8pscott@gmail.com,Pennsylvania State University,1,sawyer-nye,Sawyer,Nye,sawyer.nye@live.com
HackPSU Overall - Tech,Toxicity,49,https://hackpsu-fall-2018.devpost.com/submissions/102431-toxicity,"Inspiration

Reddit is one of the most popular websites in the world. However, since it is so popular, a wide variety of people post on the website allowing for a range of both nice and mean comments. Users looking for a new subreddit may be worried about how negative (or mean) a subreddit is. Moderators of subreddits or even administrators may use this tool to gauge the the types of responses a subreddit as a whole can be described by.

What it does

Toxicity uses Google Cloud's Language API to calculate the ""sentiment"" of several comments. The average of all comments is then calculated in order to find the overall ""mood"" of the subreddit inputted. Matplotlib and cgi are used to display box plots of the sentiment sampled comments, as well as creation of a word cloud for visualization.

How we built it

The backend of the program uses python. The frontend is made with HTML and CSS. The frontend and the backend communicate using the cgi library in python.

Challenges we ran into

Getting python and html to communicate was probably the most difficult part. It took 2 hours to fix this problem.

Accomplishments that we're proud of

We made a clean looking website that functions almost exactly as we expected it to. We are especially proud of the data visualization and frontend aesthetics.

What we learned

We learned a lot about Reddit's API and the Google Cloud API for data analysis. With the frustrations that came along the way, perhaps Javascript would have been better for frontend-backend integration than Python, but we knew how to implement the solution in Python much more strongly.

What's next for Toxicity

Getting it to run from an actual server, and not just our computers.
",,https://github.com/PScottZero/Toxicity-HackPSU-Fall2018,https://s3.amazonaws.com/challengepost/zip_files/production/36343/zip_files/Toxicity.zip,"google-cloud, python, html, css, matplotlib, cgi, xampp, praw",Penn State University Park,"","",PScottZero,Paul,Scott,8pscott@gmail.com,Pennsylvania State University,1,sawyer-nye,Sawyer,Nye,sawyer.nye@live.com
Accuweather Challenge,Park Ranger Manager,81,https://hackpsu-fall-2018.devpost.com/submissions/102433-park-ranger-manager,"Inspiration

Our team was inspired by the want to learn more about working with a team, especially ones you don't know; pushing out a project is much harder but it ended up working very well.

What it does

Park Manager allows a park ranger to:


sign in with a ranger id and stay logged in or log out
record trails and log them in the map
record different types of trail warnings
view current geotagged location
view different recorded trails
see the current weather for the day using AccuWeather
send out an SOS message if they are in trouble and view the mark on a map inside the app
choose different types of maps including satellite, standard, and hybrid
It also allows the user to view the app in dark mode.


How we built it

We used Adobe XD for the design prototype, coded the app in Xcode using Swift 4, and used AWS for backend storage, tracking, notification systems and scheduling systems.

Challenges we ran into

We ran into many challenges with creating the trails and recording them, and also having the user be tracked while recording trails.

Accomplishments that we're proud of

We succeeded in making the design and nearly finishing the app completely for being pushed to the iOS store. 

What we learned

Swift 4 is a hard language, and is especially hard to code while trying to learn at the same time. Moving design to Xcode is not very hard, and AWS works well.

What's next for Park Ranger Manager

iOS <12, Come see me and I'll install it for you. It will possibly be pushed to the iOS store.
",,https://xd.adobe.com/view/0c21afef-65d3-46d6-84a2-de233c0ddc2b-5972/?fullscreen,,"swift, python, adobexd, amazon-web-services, xcode, ios",Penn State University,"","",dovedevic,Alexandar,Devic,dovedevic@gmail.com,Pennsylvania State University,1,JacobMakarsky,Jacob,Makarsky,jacobmakarsky@gmail.com
HackPSU Overall - Design,Park Ranger Manager,81,https://hackpsu-fall-2018.devpost.com/submissions/102433-park-ranger-manager,"Inspiration

Our team was inspired by the want to learn more about working with a team, especially ones you don't know; pushing out a project is much harder but it ended up working very well.

What it does

Park Manager allows a park ranger to:


sign in with a ranger id and stay logged in or log out
record trails and log them in the map
record different types of trail warnings
view current geotagged location
view different recorded trails
see the current weather for the day using AccuWeather
send out an SOS message if they are in trouble and view the mark on a map inside the app
choose different types of maps including satellite, standard, and hybrid
It also allows the user to view the app in dark mode.


How we built it

We used Adobe XD for the design prototype, coded the app in Xcode using Swift 4, and used AWS for backend storage, tracking, notification systems and scheduling systems.

Challenges we ran into

We ran into many challenges with creating the trails and recording them, and also having the user be tracked while recording trails.

Accomplishments that we're proud of

We succeeded in making the design and nearly finishing the app completely for being pushed to the iOS store. 

What we learned

Swift 4 is a hard language, and is especially hard to code while trying to learn at the same time. Moving design to Xcode is not very hard, and AWS works well.

What's next for Park Ranger Manager

iOS <12, Come see me and I'll install it for you. It will possibly be pushed to the iOS store.
",,https://xd.adobe.com/view/0c21afef-65d3-46d6-84a2-de233c0ddc2b-5972/?fullscreen,,"swift, python, adobexd, amazon-web-services, xcode, ios",Penn State University,"","",dovedevic,Alexandar,Devic,dovedevic@gmail.com,Pennsylvania State University,1,JacobMakarsky,Jacob,Makarsky,jacobmakarsky@gmail.com
HackPSU Overall - Tech,Park Ranger Manager,81,https://hackpsu-fall-2018.devpost.com/submissions/102433-park-ranger-manager,"Inspiration

Our team was inspired by the want to learn more about working with a team, especially ones you don't know; pushing out a project is much harder but it ended up working very well.

What it does

Park Manager allows a park ranger to:


sign in with a ranger id and stay logged in or log out
record trails and log them in the map
record different types of trail warnings
view current geotagged location
view different recorded trails
see the current weather for the day using AccuWeather
send out an SOS message if they are in trouble and view the mark on a map inside the app
choose different types of maps including satellite, standard, and hybrid
It also allows the user to view the app in dark mode.


How we built it

We used Adobe XD for the design prototype, coded the app in Xcode using Swift 4, and used AWS for backend storage, tracking, notification systems and scheduling systems.

Challenges we ran into

We ran into many challenges with creating the trails and recording them, and also having the user be tracked while recording trails.

Accomplishments that we're proud of

We succeeded in making the design and nearly finishing the app completely for being pushed to the iOS store. 

What we learned

Swift 4 is a hard language, and is especially hard to code while trying to learn at the same time. Moving design to Xcode is not very hard, and AWS works well.

What's next for Park Ranger Manager

iOS <12, Come see me and I'll install it for you. It will possibly be pushed to the iOS store.
",,https://xd.adobe.com/view/0c21afef-65d3-46d6-84a2-de233c0ddc2b-5972/?fullscreen,,"swift, python, adobexd, amazon-web-services, xcode, ios",Penn State University,"","",dovedevic,Alexandar,Devic,dovedevic@gmail.com,Pennsylvania State University,1,JacobMakarsky,Jacob,Makarsky,jacobmakarsky@gmail.com
Best use of Google Cloud Platform,Quantum Connect,19,https://hackpsu-fall-2018.devpost.com/submissions/102435-quantum-connect,"Inspiration

We were inspired by the concept of a social good challenge. We wanted to build something that we felt actually would make an impact - not just met the requirements of a challenge. We thought about the numerous natural disasters that have occurred lately and also of the helpless feeling most people get when one occurs and you feel like there isn't much you can do to help. We wanted to create a way to bring people willing to volunteer their time and resources together with people who need them. Cutting out the uncomfortable feeling of anonymous donations or the bureaucracy of a large corporation, we are bringing people together to solve problems and create meaningful change.

What it does

Our application provides a simple interface in the form of a chat bot which those in need can go to in order to make connections with people who are able to help. With a conversation-like interaction, it is a simple process for anyone to input their criteria and receive meaningful responses. In addition, people who are willing to donate their time and resources will use the same chat bot to input their contact information, availability, and how they are able to help. With a simple categorization of needs, such as Finance, Transportation, Supplies, Shelter, and Rebuilding- it is easy to make connections between those affected by tragedies and those who are compelled to help. When our database recognizes a match between a volunteer's criteria and a person in need's criteria, both are alerted to make them aware of the match and are provided each-others contact information.

How we built it

We built out chatbot using DialogFlow and Google's Natural Language Processor API. Using DialogFlow's inline editor, we implemented JavaScript to create a conversation-like interface for users, and simple queries to our database. We utilized Firebase Realtime Database and query it in order to make connections between user information. We then used SendGrid's Web Application Email API to alert users when a match has been made. Lastly, we used JavaScript(with Bootstrap), HTML5, and CSS3 to implement a simple web application for the users to gather data about about application and to use the chat bot.

Challenges we ran into

We struggled to correctly connect our data between the chat bot, the database, and the various API's- occationally needing to re-evaluate our data flow. We also ran into many challenges with the asynchronous nature of JavaScript and often needed to use taboo programming solutions due to the limited time frame of our project's development.

Accomplishments that we're proud of

We are very proud that we developed an application that will be able to have an impact on peoples lives and has meaningful uses outside the scope of the Hackathon. We discovered a gap in the system and found a solution for it- which feels like genuine entrepreneurship. We are also very satisfied with how much knowledge we are taking away from this Hackathon, just as we have for all previous Hackathons we have attended. 

What we learned

We learned many new technologies, including Firebase, DialogFlow, and SendGrid. In addition, we developed our JavaScript skills much beyond what they were when we came. Lastly, we learned the value of pair programming- often finding mistake and discovering solutions that the initial programmer did not. 

What's next for Quantum Connect

Considering the very scalable nature of this application, we have many things in mind for future development. First and foremost- we want to utilize the Google Translate API. This functionality will allow non-native English speakers to use our app and receive the necessary aid they require and are not limited by their knowledge of English. Also, we believe this application can be scaled to University Relations- including Police Service responding to non-urgent requests made by students, and finding the best availability for the requested services. Lastly, due to the limited time we had to develop this application, our program was mostly done with proof of concept in mind and we would hope to return and make our framework stronger and even more user friendly than it is now in order to reach the largest percentage of people possible.
",,https://hackpsu2018-mcatterholt.c9users.io/startbootstrap-creative-gh-pages/,https://s3.amazonaws.com/challengepost/zip_files/production/36338/zip_files/QuantumConect.zip,"javascript, dialogflow, natural-language-processing, sendgrid, firebase, node.js, html5, css3, bootstrap, cloud9, caffeine",Penn State University - The Behrend Campus,Google Cloud Platform,"",mcatterholt,Morgan,Atterholt,mcatterholt@gmail.com,Pennsylvania State University,1,shreyarora2198,shreyarora2198,Arora,shreyarora2198@gmail.com
Booz Allen Hamilton - Best Machine Learning Hack,Quantum Connect,19,https://hackpsu-fall-2018.devpost.com/submissions/102435-quantum-connect,"Inspiration

We were inspired by the concept of a social good challenge. We wanted to build something that we felt actually would make an impact - not just met the requirements of a challenge. We thought about the numerous natural disasters that have occurred lately and also of the helpless feeling most people get when one occurs and you feel like there isn't much you can do to help. We wanted to create a way to bring people willing to volunteer their time and resources together with people who need them. Cutting out the uncomfortable feeling of anonymous donations or the bureaucracy of a large corporation, we are bringing people together to solve problems and create meaningful change.

What it does

Our application provides a simple interface in the form of a chat bot which those in need can go to in order to make connections with people who are able to help. With a conversation-like interaction, it is a simple process for anyone to input their criteria and receive meaningful responses. In addition, people who are willing to donate their time and resources will use the same chat bot to input their contact information, availability, and how they are able to help. With a simple categorization of needs, such as Finance, Transportation, Supplies, Shelter, and Rebuilding- it is easy to make connections between those affected by tragedies and those who are compelled to help. When our database recognizes a match between a volunteer's criteria and a person in need's criteria, both are alerted to make them aware of the match and are provided each-others contact information.

How we built it

We built out chatbot using DialogFlow and Google's Natural Language Processor API. Using DialogFlow's inline editor, we implemented JavaScript to create a conversation-like interface for users, and simple queries to our database. We utilized Firebase Realtime Database and query it in order to make connections between user information. We then used SendGrid's Web Application Email API to alert users when a match has been made. Lastly, we used JavaScript(with Bootstrap), HTML5, and CSS3 to implement a simple web application for the users to gather data about about application and to use the chat bot.

Challenges we ran into

We struggled to correctly connect our data between the chat bot, the database, and the various API's- occationally needing to re-evaluate our data flow. We also ran into many challenges with the asynchronous nature of JavaScript and often needed to use taboo programming solutions due to the limited time frame of our project's development.

Accomplishments that we're proud of

We are very proud that we developed an application that will be able to have an impact on peoples lives and has meaningful uses outside the scope of the Hackathon. We discovered a gap in the system and found a solution for it- which feels like genuine entrepreneurship. We are also very satisfied with how much knowledge we are taking away from this Hackathon, just as we have for all previous Hackathons we have attended. 

What we learned

We learned many new technologies, including Firebase, DialogFlow, and SendGrid. In addition, we developed our JavaScript skills much beyond what they were when we came. Lastly, we learned the value of pair programming- often finding mistake and discovering solutions that the initial programmer did not. 

What's next for Quantum Connect

Considering the very scalable nature of this application, we have many things in mind for future development. First and foremost- we want to utilize the Google Translate API. This functionality will allow non-native English speakers to use our app and receive the necessary aid they require and are not limited by their knowledge of English. Also, we believe this application can be scaled to University Relations- including Police Service responding to non-urgent requests made by students, and finding the best availability for the requested services. Lastly, due to the limited time we had to develop this application, our program was mostly done with proof of concept in mind and we would hope to return and make our framework stronger and even more user friendly than it is now in order to reach the largest percentage of people possible.
",,https://hackpsu2018-mcatterholt.c9users.io/startbootstrap-creative-gh-pages/,https://s3.amazonaws.com/challengepost/zip_files/production/36338/zip_files/QuantumConect.zip,"javascript, dialogflow, natural-language-processing, sendgrid, firebase, node.js, html5, css3, bootstrap, cloud9, caffeine",Penn State University - The Behrend Campus,Google Cloud Platform,"",mcatterholt,Morgan,Atterholt,mcatterholt@gmail.com,Pennsylvania State University,1,shreyarora2198,shreyarora2198,Arora,shreyarora2198@gmail.com
Nittany AI Alliance - AI Challenge,Quantum Connect,19,https://hackpsu-fall-2018.devpost.com/submissions/102435-quantum-connect,"Inspiration

We were inspired by the concept of a social good challenge. We wanted to build something that we felt actually would make an impact - not just met the requirements of a challenge. We thought about the numerous natural disasters that have occurred lately and also of the helpless feeling most people get when one occurs and you feel like there isn't much you can do to help. We wanted to create a way to bring people willing to volunteer their time and resources together with people who need them. Cutting out the uncomfortable feeling of anonymous donations or the bureaucracy of a large corporation, we are bringing people together to solve problems and create meaningful change.

What it does

Our application provides a simple interface in the form of a chat bot which those in need can go to in order to make connections with people who are able to help. With a conversation-like interaction, it is a simple process for anyone to input their criteria and receive meaningful responses. In addition, people who are willing to donate their time and resources will use the same chat bot to input their contact information, availability, and how they are able to help. With a simple categorization of needs, such as Finance, Transportation, Supplies, Shelter, and Rebuilding- it is easy to make connections between those affected by tragedies and those who are compelled to help. When our database recognizes a match between a volunteer's criteria and a person in need's criteria, both are alerted to make them aware of the match and are provided each-others contact information.

How we built it

We built out chatbot using DialogFlow and Google's Natural Language Processor API. Using DialogFlow's inline editor, we implemented JavaScript to create a conversation-like interface for users, and simple queries to our database. We utilized Firebase Realtime Database and query it in order to make connections between user information. We then used SendGrid's Web Application Email API to alert users when a match has been made. Lastly, we used JavaScript(with Bootstrap), HTML5, and CSS3 to implement a simple web application for the users to gather data about about application and to use the chat bot.

Challenges we ran into

We struggled to correctly connect our data between the chat bot, the database, and the various API's- occationally needing to re-evaluate our data flow. We also ran into many challenges with the asynchronous nature of JavaScript and often needed to use taboo programming solutions due to the limited time frame of our project's development.

Accomplishments that we're proud of

We are very proud that we developed an application that will be able to have an impact on peoples lives and has meaningful uses outside the scope of the Hackathon. We discovered a gap in the system and found a solution for it- which feels like genuine entrepreneurship. We are also very satisfied with how much knowledge we are taking away from this Hackathon, just as we have for all previous Hackathons we have attended. 

What we learned

We learned many new technologies, including Firebase, DialogFlow, and SendGrid. In addition, we developed our JavaScript skills much beyond what they were when we came. Lastly, we learned the value of pair programming- often finding mistake and discovering solutions that the initial programmer did not. 

What's next for Quantum Connect

Considering the very scalable nature of this application, we have many things in mind for future development. First and foremost- we want to utilize the Google Translate API. This functionality will allow non-native English speakers to use our app and receive the necessary aid they require and are not limited by their knowledge of English. Also, we believe this application can be scaled to University Relations- including Police Service responding to non-urgent requests made by students, and finding the best availability for the requested services. Lastly, due to the limited time we had to develop this application, our program was mostly done with proof of concept in mind and we would hope to return and make our framework stronger and even more user friendly than it is now in order to reach the largest percentage of people possible.
",,https://hackpsu2018-mcatterholt.c9users.io/startbootstrap-creative-gh-pages/,https://s3.amazonaws.com/challengepost/zip_files/production/36338/zip_files/QuantumConect.zip,"javascript, dialogflow, natural-language-processing, sendgrid, firebase, node.js, html5, css3, bootstrap, cloud9, caffeine",Penn State University - The Behrend Campus,Google Cloud Platform,"",mcatterholt,Morgan,Atterholt,mcatterholt@gmail.com,Pennsylvania State University,1,shreyarora2198,shreyarora2198,Arora,shreyarora2198@gmail.com
HackPSU Overall - Tech,Quantum Connect,19,https://hackpsu-fall-2018.devpost.com/submissions/102435-quantum-connect,"Inspiration

We were inspired by the concept of a social good challenge. We wanted to build something that we felt actually would make an impact - not just met the requirements of a challenge. We thought about the numerous natural disasters that have occurred lately and also of the helpless feeling most people get when one occurs and you feel like there isn't much you can do to help. We wanted to create a way to bring people willing to volunteer their time and resources together with people who need them. Cutting out the uncomfortable feeling of anonymous donations or the bureaucracy of a large corporation, we are bringing people together to solve problems and create meaningful change.

What it does

Our application provides a simple interface in the form of a chat bot which those in need can go to in order to make connections with people who are able to help. With a conversation-like interaction, it is a simple process for anyone to input their criteria and receive meaningful responses. In addition, people who are willing to donate their time and resources will use the same chat bot to input their contact information, availability, and how they are able to help. With a simple categorization of needs, such as Finance, Transportation, Supplies, Shelter, and Rebuilding- it is easy to make connections between those affected by tragedies and those who are compelled to help. When our database recognizes a match between a volunteer's criteria and a person in need's criteria, both are alerted to make them aware of the match and are provided each-others contact information.

How we built it

We built out chatbot using DialogFlow and Google's Natural Language Processor API. Using DialogFlow's inline editor, we implemented JavaScript to create a conversation-like interface for users, and simple queries to our database. We utilized Firebase Realtime Database and query it in order to make connections between user information. We then used SendGrid's Web Application Email API to alert users when a match has been made. Lastly, we used JavaScript(with Bootstrap), HTML5, and CSS3 to implement a simple web application for the users to gather data about about application and to use the chat bot.

Challenges we ran into

We struggled to correctly connect our data between the chat bot, the database, and the various API's- occationally needing to re-evaluate our data flow. We also ran into many challenges with the asynchronous nature of JavaScript and often needed to use taboo programming solutions due to the limited time frame of our project's development.

Accomplishments that we're proud of

We are very proud that we developed an application that will be able to have an impact on peoples lives and has meaningful uses outside the scope of the Hackathon. We discovered a gap in the system and found a solution for it- which feels like genuine entrepreneurship. We are also very satisfied with how much knowledge we are taking away from this Hackathon, just as we have for all previous Hackathons we have attended. 

What we learned

We learned many new technologies, including Firebase, DialogFlow, and SendGrid. In addition, we developed our JavaScript skills much beyond what they were when we came. Lastly, we learned the value of pair programming- often finding mistake and discovering solutions that the initial programmer did not. 

What's next for Quantum Connect

Considering the very scalable nature of this application, we have many things in mind for future development. First and foremost- we want to utilize the Google Translate API. This functionality will allow non-native English speakers to use our app and receive the necessary aid they require and are not limited by their knowledge of English. Also, we believe this application can be scaled to University Relations- including Police Service responding to non-urgent requests made by students, and finding the best availability for the requested services. Lastly, due to the limited time we had to develop this application, our program was mostly done with proof of concept in mind and we would hope to return and make our framework stronger and even more user friendly than it is now in order to reach the largest percentage of people possible.
",,https://hackpsu2018-mcatterholt.c9users.io/startbootstrap-creative-gh-pages/,https://s3.amazonaws.com/challengepost/zip_files/production/36338/zip_files/QuantumConect.zip,"javascript, dialogflow, natural-language-processing, sendgrid, firebase, node.js, html5, css3, bootstrap, cloud9, caffeine",Penn State University - The Behrend Campus,Google Cloud Platform,"",mcatterholt,Morgan,Atterholt,mcatterholt@gmail.com,Pennsylvania State University,1,shreyarora2198,shreyarora2198,Arora,shreyarora2198@gmail.com
Best Social Good Hack from Fidelity Weekly Challenge,Quantum Connect,19,https://hackpsu-fall-2018.devpost.com/submissions/102435-quantum-connect,"Inspiration

We were inspired by the concept of a social good challenge. We wanted to build something that we felt actually would make an impact - not just met the requirements of a challenge. We thought about the numerous natural disasters that have occurred lately and also of the helpless feeling most people get when one occurs and you feel like there isn't much you can do to help. We wanted to create a way to bring people willing to volunteer their time and resources together with people who need them. Cutting out the uncomfortable feeling of anonymous donations or the bureaucracy of a large corporation, we are bringing people together to solve problems and create meaningful change.

What it does

Our application provides a simple interface in the form of a chat bot which those in need can go to in order to make connections with people who are able to help. With a conversation-like interaction, it is a simple process for anyone to input their criteria and receive meaningful responses. In addition, people who are willing to donate their time and resources will use the same chat bot to input their contact information, availability, and how they are able to help. With a simple categorization of needs, such as Finance, Transportation, Supplies, Shelter, and Rebuilding- it is easy to make connections between those affected by tragedies and those who are compelled to help. When our database recognizes a match between a volunteer's criteria and a person in need's criteria, both are alerted to make them aware of the match and are provided each-others contact information.

How we built it

We built out chatbot using DialogFlow and Google's Natural Language Processor API. Using DialogFlow's inline editor, we implemented JavaScript to create a conversation-like interface for users, and simple queries to our database. We utilized Firebase Realtime Database and query it in order to make connections between user information. We then used SendGrid's Web Application Email API to alert users when a match has been made. Lastly, we used JavaScript(with Bootstrap), HTML5, and CSS3 to implement a simple web application for the users to gather data about about application and to use the chat bot.

Challenges we ran into

We struggled to correctly connect our data between the chat bot, the database, and the various API's- occationally needing to re-evaluate our data flow. We also ran into many challenges with the asynchronous nature of JavaScript and often needed to use taboo programming solutions due to the limited time frame of our project's development.

Accomplishments that we're proud of

We are very proud that we developed an application that will be able to have an impact on peoples lives and has meaningful uses outside the scope of the Hackathon. We discovered a gap in the system and found a solution for it- which feels like genuine entrepreneurship. We are also very satisfied with how much knowledge we are taking away from this Hackathon, just as we have for all previous Hackathons we have attended. 

What we learned

We learned many new technologies, including Firebase, DialogFlow, and SendGrid. In addition, we developed our JavaScript skills much beyond what they were when we came. Lastly, we learned the value of pair programming- often finding mistake and discovering solutions that the initial programmer did not. 

What's next for Quantum Connect

Considering the very scalable nature of this application, we have many things in mind for future development. First and foremost- we want to utilize the Google Translate API. This functionality will allow non-native English speakers to use our app and receive the necessary aid they require and are not limited by their knowledge of English. Also, we believe this application can be scaled to University Relations- including Police Service responding to non-urgent requests made by students, and finding the best availability for the requested services. Lastly, due to the limited time we had to develop this application, our program was mostly done with proof of concept in mind and we would hope to return and make our framework stronger and even more user friendly than it is now in order to reach the largest percentage of people possible.
",,https://hackpsu2018-mcatterholt.c9users.io/startbootstrap-creative-gh-pages/,https://s3.amazonaws.com/challengepost/zip_files/production/36338/zip_files/QuantumConect.zip,"javascript, dialogflow, natural-language-processing, sendgrid, firebase, node.js, html5, css3, bootstrap, cloud9, caffeine",Penn State University - The Behrend Campus,Google Cloud Platform,"",mcatterholt,Morgan,Atterholt,mcatterholt@gmail.com,Pennsylvania State University,1,shreyarora2198,shreyarora2198,Arora,shreyarora2198@gmail.com
JPMC - Best Social Good Hack,Quantum Connect,19,https://hackpsu-fall-2018.devpost.com/submissions/102435-quantum-connect,"Inspiration

We were inspired by the concept of a social good challenge. We wanted to build something that we felt actually would make an impact - not just met the requirements of a challenge. We thought about the numerous natural disasters that have occurred lately and also of the helpless feeling most people get when one occurs and you feel like there isn't much you can do to help. We wanted to create a way to bring people willing to volunteer their time and resources together with people who need them. Cutting out the uncomfortable feeling of anonymous donations or the bureaucracy of a large corporation, we are bringing people together to solve problems and create meaningful change.

What it does

Our application provides a simple interface in the form of a chat bot which those in need can go to in order to make connections with people who are able to help. With a conversation-like interaction, it is a simple process for anyone to input their criteria and receive meaningful responses. In addition, people who are willing to donate their time and resources will use the same chat bot to input their contact information, availability, and how they are able to help. With a simple categorization of needs, such as Finance, Transportation, Supplies, Shelter, and Rebuilding- it is easy to make connections between those affected by tragedies and those who are compelled to help. When our database recognizes a match between a volunteer's criteria and a person in need's criteria, both are alerted to make them aware of the match and are provided each-others contact information.

How we built it

We built out chatbot using DialogFlow and Google's Natural Language Processor API. Using DialogFlow's inline editor, we implemented JavaScript to create a conversation-like interface for users, and simple queries to our database. We utilized Firebase Realtime Database and query it in order to make connections between user information. We then used SendGrid's Web Application Email API to alert users when a match has been made. Lastly, we used JavaScript(with Bootstrap), HTML5, and CSS3 to implement a simple web application for the users to gather data about about application and to use the chat bot.

Challenges we ran into

We struggled to correctly connect our data between the chat bot, the database, and the various API's- occationally needing to re-evaluate our data flow. We also ran into many challenges with the asynchronous nature of JavaScript and often needed to use taboo programming solutions due to the limited time frame of our project's development.

Accomplishments that we're proud of

We are very proud that we developed an application that will be able to have an impact on peoples lives and has meaningful uses outside the scope of the Hackathon. We discovered a gap in the system and found a solution for it- which feels like genuine entrepreneurship. We are also very satisfied with how much knowledge we are taking away from this Hackathon, just as we have for all previous Hackathons we have attended. 

What we learned

We learned many new technologies, including Firebase, DialogFlow, and SendGrid. In addition, we developed our JavaScript skills much beyond what they were when we came. Lastly, we learned the value of pair programming- often finding mistake and discovering solutions that the initial programmer did not. 

What's next for Quantum Connect

Considering the very scalable nature of this application, we have many things in mind for future development. First and foremost- we want to utilize the Google Translate API. This functionality will allow non-native English speakers to use our app and receive the necessary aid they require and are not limited by their knowledge of English. Also, we believe this application can be scaled to University Relations- including Police Service responding to non-urgent requests made by students, and finding the best availability for the requested services. Lastly, due to the limited time we had to develop this application, our program was mostly done with proof of concept in mind and we would hope to return and make our framework stronger and even more user friendly than it is now in order to reach the largest percentage of people possible.
",,https://hackpsu2018-mcatterholt.c9users.io/startbootstrap-creative-gh-pages/,https://s3.amazonaws.com/challengepost/zip_files/production/36338/zip_files/QuantumConect.zip,"javascript, dialogflow, natural-language-processing, sendgrid, firebase, node.js, html5, css3, bootstrap, cloud9, caffeine",Penn State University - The Behrend Campus,Google Cloud Platform,"",mcatterholt,Morgan,Atterholt,mcatterholt@gmail.com,Pennsylvania State University,1,shreyarora2198,shreyarora2198,Arora,shreyarora2198@gmail.com
Best Domain Name from Domain.com,Dining@PSU,73,https://hackpsu-fall-2018.devpost.com/submissions/102438-dining-psu,"Inspiration

_ Dining@PSU _ was created in response to the unexpected removal of Penn State's dining services application from the App Store in the Summer of 2018. Many students we know relied on this application when deciding where to go for their meals each day, so we figured composing a new stand-alone app from the ground up would be a fantastic way to give students the convenience they are looking for when quickly searching between classes.

What it does

-Our application provides Penn State students with a minimalistic and clean experience when accessing the dining hall menus each week. Our UI provides the end user with the ability to seamlessly choose which dining hall, day of the week, and precise restaurant in order to view their menu and nutritional facts. The app also provides people with allergies the opportunity to easily access which options they should stay away from on a day's menu. On the iOS application, we have also utilized iOS 12's Siri Shortcuts functionality in order for anyone to create custom shortcuts in order to search for each dining hall's menu, all from vocal commands. Simply stating, ""Hey Siri. What is the menu in East today?"" will prompt a quick and simple interface for the user to view each of the food options for the given meal.

How we built it

-Our team utilized Javascript for the initial data parsing, employed Swift for the iOS application, and utilized Kotlin for the Android app and denser data restructuring. 

Challenges we ran into

-Our team ran into some unique design challenges when utilizing Penn State's dining API in order to retrieve the information to use on our apps. We were faced with some difficult challenges regarding how we parsed through the data in Javascript, and we ended up having to restructure a poorly-designed hierarchy in Kotlin in order to methodically access the API data in a sensible manner.

Accomplishments that we're proud of

What we learned

-Our team developed a much stronger level of communication and problem-solving during the duration of the competition. The limited amount of time we had to design and implement our ideas forced our team to delegate each task to the member who possessed the most knowledge and experience on the topic. But at the same token, we were able to ask one another questions regarding syntax and overall design, making our team effort that much more of a learning experience for each of us.

What's next for Dining@PSU

-Our team's next step is to take our application to the head of dining services at Penn State to discuss their interest in utilizing this app as their official dining application in the future. We are optimistic that they will enjoy our design and choose to implement our design as the official university dining application. 
",,http://diningpsu.com,,"swift, kotlin","Penn State University, Georgia Tech University",Domain.com,"",nro337,Nick,Alico,nro337@gmail.com,Pennsylvania State University,3,Pear0,Will,Gulian,williamgulian@gmail.com,dsringari,Dhruv,Sringari,dhruvy427@gmail.com,nrubin29,Noah,Rubin,nrubin29@gmail.com
HackPSU Overall - Tech,Dining@PSU,73,https://hackpsu-fall-2018.devpost.com/submissions/102438-dining-psu,"Inspiration

_ Dining@PSU _ was created in response to the unexpected removal of Penn State's dining services application from the App Store in the Summer of 2018. Many students we know relied on this application when deciding where to go for their meals each day, so we figured composing a new stand-alone app from the ground up would be a fantastic way to give students the convenience they are looking for when quickly searching between classes.

What it does

-Our application provides Penn State students with a minimalistic and clean experience when accessing the dining hall menus each week. Our UI provides the end user with the ability to seamlessly choose which dining hall, day of the week, and precise restaurant in order to view their menu and nutritional facts. The app also provides people with allergies the opportunity to easily access which options they should stay away from on a day's menu. On the iOS application, we have also utilized iOS 12's Siri Shortcuts functionality in order for anyone to create custom shortcuts in order to search for each dining hall's menu, all from vocal commands. Simply stating, ""Hey Siri. What is the menu in East today?"" will prompt a quick and simple interface for the user to view each of the food options for the given meal.

How we built it

-Our team utilized Javascript for the initial data parsing, employed Swift for the iOS application, and utilized Kotlin for the Android app and denser data restructuring. 

Challenges we ran into

-Our team ran into some unique design challenges when utilizing Penn State's dining API in order to retrieve the information to use on our apps. We were faced with some difficult challenges regarding how we parsed through the data in Javascript, and we ended up having to restructure a poorly-designed hierarchy in Kotlin in order to methodically access the API data in a sensible manner.

Accomplishments that we're proud of

What we learned

-Our team developed a much stronger level of communication and problem-solving during the duration of the competition. The limited amount of time we had to design and implement our ideas forced our team to delegate each task to the member who possessed the most knowledge and experience on the topic. But at the same token, we were able to ask one another questions regarding syntax and overall design, making our team effort that much more of a learning experience for each of us.

What's next for Dining@PSU

-Our team's next step is to take our application to the head of dining services at Penn State to discuss their interest in utilizing this app as their official dining application in the future. We are optimistic that they will enjoy our design and choose to implement our design as the official university dining application. 
",,http://diningpsu.com,,"swift, kotlin","Penn State University, Georgia Tech University",Domain.com,"",nro337,Nick,Alico,nro337@gmail.com,Pennsylvania State University,3,Pear0,Will,Gulian,williamgulian@gmail.com,dsringari,Dhruv,Sringari,dhruvy427@gmail.com,nrubin29,Noah,Rubin,nrubin29@gmail.com
Best Social Good Hack from Fidelity Weekly Challenge,DndCombat,74,https://hackpsu-fall-2018.devpost.com/submissions/102440-dndcombat,"Inspiration

There are not any good online boards and we like to play dungeons and dragons together

What it does

Allows you to select a character and move them around in order to attack other players. You can remove players as well within the set map. 

How we built it

Using reactJS, javascript, and html

Challenges we ran into

reactJS was a new framework we were introduced to therefore adapting to it and learning how to use it was challenging

Accomplishments that we're proud of

While it is low in capabilities it is currently fully functional.

What we learned

ReactJs, Github

What's next for DndCombat

Adding pictures instead of letters for each character and implementing statistics for each character.
",,https://github.com/KellyMichael/DnDCombat,,"",Penn State,"","",othmangba,Othmangba,,othmangba@gmail.com,Pennsylvania State University,3,KellyMichael,KellyMichael,,rockymkelly@gmail.com,Chellz,Chellz,,mabbate14@yahoo.com,mua350,Marcello,Abbate,mua350@psu.edu
JPMC - Best Social Good Hack,DndCombat,74,https://hackpsu-fall-2018.devpost.com/submissions/102440-dndcombat,"Inspiration

There are not any good online boards and we like to play dungeons and dragons together

What it does

Allows you to select a character and move them around in order to attack other players. You can remove players as well within the set map. 

How we built it

Using reactJS, javascript, and html

Challenges we ran into

reactJS was a new framework we were introduced to therefore adapting to it and learning how to use it was challenging

Accomplishments that we're proud of

While it is low in capabilities it is currently fully functional.

What we learned

ReactJs, Github

What's next for DndCombat

Adding pictures instead of letters for each character and implementing statistics for each character.
",,https://github.com/KellyMichael/DnDCombat,,"",Penn State,"","",othmangba,Othmangba,,othmangba@gmail.com,Pennsylvania State University,3,KellyMichael,KellyMichael,,rockymkelly@gmail.com,Chellz,Chellz,,mabbate14@yahoo.com,mua350,Marcello,Abbate,mua350@psu.edu
Best use of Google Cloud Platform,BreakSpots,28,https://hackpsu-fall-2018.devpost.com/submissions/102441-breakspots,"Inspiration

I'm always pulling out my phone between classes: the time I should be enjoying before I've gotta sit though another 50 minute lecture is wasted as I pace around, worried about the EXACT time I'm supposed to leave wherever I am just to get to my next class in time.  BreakStops is dedicated to those who can't stand to waste a minute thinking about the present.

What it does

BreakStops reads, sorts, and intelligently measures walking distances with respect to class start and stop times. The script allows for customizable inputs, like a set script for siphoning in essential data for functionality and allows the user to ask BreakStops how long they have in [hour:minute] format to take a break and stop before their next class. Depending on how long you have between classes, BreakStop may make informed suggestions of how to spend the time you have left. If your next stop is halfway across campus and you only have 15 minutes to walk, the program may tell you HURRY! Or, if your classes are back-to-back in the same building and are generously spread throughout the day, BreakStops could calculate the time it may take for you to get to your dorm and back and subtract it from the total time you have free of lecture, steering stress away and allowing you to enjoy the little time you have to yourself by forwarding you the exact time you have to yourself.

How we built it

BreakStops was build entirely in Python. 

Challenges we ran into

We really wanted to incorporate some form of machine learning in the selection of key terms from a generic LionPath Schedule. We tried AWS services like Rekognition, but the confusing and nonobvious generic schedule would have taken too much time to fix, taking away from the actual project. We also tried to use Lex as a chatbot to extract information, but the lambda functions required to format the data into the way we needed it to feed into BreakStop was also far too complicated. 

Accomplishments that we're proud of

The program works, and it works well. The interface is fairly simple, and although at face-value it may not look like much, I think there's a real practicality with BreakStop.

What we learned

-How to use Google distance matrixes
-Some group members became more familiar with Python
-Although we didn't incorporate Lex in our final project, a lot of the effort here went to trying to understand how Lex  and chatbots in general can be used.

What's next for BreakSpots

I'd love to incorporate a campus-wide dictionary so any schedule plugged into BreakSpots can work flawlessly.
I also want to add more specific features for BreakSpots to inform the user about. Perhaps the program can specifically ask if the user wants to eat lunch around 1-3 or the program can be used directly as a schedule planner.  I also want to create a more user-friendly and attractive interface rather than it just be a script.
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36339/zip_files/BreakSpots.txt,"python, google-distance-matrix","Pennsylvania State University, Temple University",Google Cloud Platform,"",bouzomgi,Brian,Ouzomgi,bouzomgi@gmail.com,Pennsylvania State University,0
HackPSU Overall - Tech,Smart Sentiment Sensing Stock Service,69,https://hackpsu-fall-2018.devpost.com/submissions/102442-smart-sentiment-sensing-stock-service,"Inspiration

Our inspiration was in noticing how much popular news articles affect the price of stocks. We wanted to find a way to use that to improve our stock predictions

What it does

Uses natural language processing to create a ""sentiment"" feature to add to the stock price history. Then runs those through a Recurrent Neural Network, which is a specialize neural network which takes in time-series data. This enables our predictions to be intelligently based on the previous 200 days of stock valuation and sentiment rather than just a single day at a time.

How we built it

We used python for everything, the web front end was to be built in PHP using the Laravel framework, but we ran out of time. 

Challenges we ran into

The biggest challenge was handling the large data sets and combining the stock data and the sentiment data in such a way as to be useful to the training algorithm.

Also, the time needed for training and natural language processing for so many data points means that if something goes wrong, we have to wait another half an hour to see if our fix worked.

The data we used was rather dated, as any stock market data set with live values required a paid subscription, so our free data set contained data up to March 23rd 2018. 

What's next for Smart Sentiment Sensing Stock Service

We'd like to finish the front end, so that a user can go to our website and enter a stock ticker and receive a prediction for the next week's stock price.
",,https://github.com/aslomski/hackpsu2018.git,https://s3.amazonaws.com/challengepost/zip_files/production/36362/zip_files/5S.zip,python,Penn State University,"","",aslomski,Alec,Slomski,arslomski@gmail.com,Pennsylvania State University,1,osbo-zach,Zachary,Osborne,osbo.zach@gmail.com
Capital One - Best Financial Hack,Smart Sentiment Sensing Stock Service,69,https://hackpsu-fall-2018.devpost.com/submissions/102442-smart-sentiment-sensing-stock-service,"Inspiration

Our inspiration was in noticing how much popular news articles affect the price of stocks. We wanted to find a way to use that to improve our stock predictions

What it does

Uses natural language processing to create a ""sentiment"" feature to add to the stock price history. Then runs those through a Recurrent Neural Network, which is a specialize neural network which takes in time-series data. This enables our predictions to be intelligently based on the previous 200 days of stock valuation and sentiment rather than just a single day at a time.

How we built it

We used python for everything, the web front end was to be built in PHP using the Laravel framework, but we ran out of time. 

Challenges we ran into

The biggest challenge was handling the large data sets and combining the stock data and the sentiment data in such a way as to be useful to the training algorithm.

Also, the time needed for training and natural language processing for so many data points means that if something goes wrong, we have to wait another half an hour to see if our fix worked.

The data we used was rather dated, as any stock market data set with live values required a paid subscription, so our free data set contained data up to March 23rd 2018. 

What's next for Smart Sentiment Sensing Stock Service

We'd like to finish the front end, so that a user can go to our website and enter a stock ticker and receive a prediction for the next week's stock price.
",,https://github.com/aslomski/hackpsu2018.git,https://s3.amazonaws.com/challengepost/zip_files/production/36362/zip_files/5S.zip,python,Penn State University,"","",aslomski,Alec,Slomski,arslomski@gmail.com,Pennsylvania State University,1,osbo-zach,Zachary,Osborne,osbo.zach@gmail.com
GM - Autonomous RC Car Challenge,Auto Car 2,77,https://hackpsu-fall-2018.devpost.com/submissions/102443-auto-car-2,"We wanted to build a vehicle that is not just appealing to consumers but also is green, safe and autonmous.

It is a safe car with emergency breaking capabilities and an internal fire detection system. It is also a green vehicle that runs on electricity.

We built it using arduino boards and multiple sensors(4 ultrasonic sensors and 2 fire detector sensors).

We ran into many challenges in-terms of bugs in code but also in terms of hardware.

The car works well with very good autonmous functions and with indicators of direction and sound features.

We learnt a lot about the safety standards in the car industry and the effciency of batteries. We also learnt how to succesfully integrate light and sound systems.

We hope to further this project in terms of asthetics.
",,https://github.com/sparikh4/Auto-Car,,"arduino, foxonix, c++",Pennsylvania State University,"","",axs1192,Aneesh Kumar,Srinivasan,axs1192@psu.edu,Pennsylvania State University,3,sparikh4,Sahil,Parikh,s.parikh@hotmail.com,kkg5256,Krish,Gurdasani,kkg5256@psu.edu,nsp5182,Nilanshu,Patwa,nsp5182@psu.edu
HackPSU Overall - Tech,Auto Car 2,77,https://hackpsu-fall-2018.devpost.com/submissions/102443-auto-car-2,"We wanted to build a vehicle that is not just appealing to consumers but also is green, safe and autonmous.

It is a safe car with emergency breaking capabilities and an internal fire detection system. It is also a green vehicle that runs on electricity.

We built it using arduino boards and multiple sensors(4 ultrasonic sensors and 2 fire detector sensors).

We ran into many challenges in-terms of bugs in code but also in terms of hardware.

The car works well with very good autonmous functions and with indicators of direction and sound features.

We learnt a lot about the safety standards in the car industry and the effciency of batteries. We also learnt how to succesfully integrate light and sound systems.

We hope to further this project in terms of asthetics.
",,https://github.com/sparikh4/Auto-Car,,"arduino, foxonix, c++",Pennsylvania State University,"","",axs1192,Aneesh Kumar,Srinivasan,axs1192@psu.edu,Pennsylvania State University,3,sparikh4,Sahil,Parikh,s.parikh@hotmail.com,kkg5256,Krish,Gurdasani,kkg5256@psu.edu,nsp5182,Nilanshu,Patwa,nsp5182@psu.edu
Accuweather Challenge,Seather,55,https://hackpsu-fall-2018.devpost.com/submissions/102444-seather,"Inspiration

Lately, when I get out of class to go back to my dorms there always seem to be light showers, which while a small inconvenience gets me completely wet if I go without my raincoat/umbrella, which many times I forget. Hence I strived to create an app that will inform the user about the weather information before and after the class.

AIM| How it works

The App would take the user's school schedule from Mon-Fri (User would manually input/take from google calendar)
Compares time from the 12 hours from the Accuweather API to check if there are any weather problems before or after the class. Would Send notifications to the user about the weather before class if there is a problem. There are 5 classes, 4 to retrieve the data from the AccuWeather API and present them.
-AccuData
-AccuRequest
-WeatherAdapter
-Schedule
-Main

Challenges

Unfortunately, in my android studio, the manifest files failed to work, hence I wasn't able to complete the project as it could not be compiled. Currently, the code only consists of 4/5 classes, and only works like a normal weather app, as android studio problems occurred early.  

Future

With more time and a fixed android studio, the app would be completed, and I would try to improve the user UI. Because if the UI is not good user will not use the app, hence the use of a UI is important. 
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36350/zip_files/Seather.zip,"java, android-studio, accuweather",Penn State,"","",Chocolatefudge,,,hkpersonal007@gmail.com,Pennsylvania State University,0
HackPSU Overall - Tech,Seather,55,https://hackpsu-fall-2018.devpost.com/submissions/102444-seather,"Inspiration

Lately, when I get out of class to go back to my dorms there always seem to be light showers, which while a small inconvenience gets me completely wet if I go without my raincoat/umbrella, which many times I forget. Hence I strived to create an app that will inform the user about the weather information before and after the class.

AIM| How it works

The App would take the user's school schedule from Mon-Fri (User would manually input/take from google calendar)
Compares time from the 12 hours from the Accuweather API to check if there are any weather problems before or after the class. Would Send notifications to the user about the weather before class if there is a problem. There are 5 classes, 4 to retrieve the data from the AccuWeather API and present them.
-AccuData
-AccuRequest
-WeatherAdapter
-Schedule
-Main

Challenges

Unfortunately, in my android studio, the manifest files failed to work, hence I wasn't able to complete the project as it could not be compiled. Currently, the code only consists of 4/5 classes, and only works like a normal weather app, as android studio problems occurred early.  

Future

With more time and a fixed android studio, the app would be completed, and I would try to improve the user UI. Because if the UI is not good user will not use the app, hence the use of a UI is important. 
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36350/zip_files/Seather.zip,"java, android-studio, accuweather",Penn State,"","",Chocolatefudge,,,hkpersonal007@gmail.com,Pennsylvania State University,0
JPMC - Best Social Good Hack,Seather,55,https://hackpsu-fall-2018.devpost.com/submissions/102444-seather,"Inspiration

Lately, when I get out of class to go back to my dorms there always seem to be light showers, which while a small inconvenience gets me completely wet if I go without my raincoat/umbrella, which many times I forget. Hence I strived to create an app that will inform the user about the weather information before and after the class.

AIM| How it works

The App would take the user's school schedule from Mon-Fri (User would manually input/take from google calendar)
Compares time from the 12 hours from the Accuweather API to check if there are any weather problems before or after the class. Would Send notifications to the user about the weather before class if there is a problem. There are 5 classes, 4 to retrieve the data from the AccuWeather API and present them.
-AccuData
-AccuRequest
-WeatherAdapter
-Schedule
-Main

Challenges

Unfortunately, in my android studio, the manifest files failed to work, hence I wasn't able to complete the project as it could not be compiled. Currently, the code only consists of 4/5 classes, and only works like a normal weather app, as android studio problems occurred early.  

Future

With more time and a fixed android studio, the app would be completed, and I would try to improve the user UI. Because if the UI is not good user will not use the app, hence the use of a UI is important. 
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36350/zip_files/Seather.zip,"java, android-studio, accuweather",Penn State,"","",Chocolatefudge,,,hkpersonal007@gmail.com,Pennsylvania State University,0
"",Hunger Hunter,2,https://hackpsu-fall-2018.devpost.com/submissions/102445-hunger-hunter,"Inspiration

Team member, Trevor Knox, had experience in a catering service that would end up wasting a bunch of food after events because no one went through the effort to donate the food to a food bank. In order to solve this, Trevor suggested this app which connects donors and food banks together into one app in order to minimize food waste and to benefit the community as a whole.

What it does

Allows donors to find information on nearby food banks and to get in contact with them to donate food. The app streamlines the process by showing nearby food banks in the area and providing contact info right within the app.

How we built it

We utilized MIT's App Inventor to develop the application along with Google's Firebase Cloud to create the database to store information. Also utilizes Google Maps API to show local food banks near your location.

We also utilized Domain.com's free domain to embed our APK online for Android users to download and for consumers to appreciate the website and our mission.

Challenges we ran into

Firebase updated in the middle of the night which changed the API key which resulted in a lot of permission denied errors. Issues also included storage of data where data would be overwritten.

Accomplishments that we're proud of

Developing a visually pleasing application that is simple and easy to use.

What we learned

That we need to be more vigilant about our API keys as well as how we handle data.

What's next for Hunger Hunter

Better input validation as well as allowing food banks to input more data such as quantity of food they are willing to accept as well as type of food and business hours.
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36348/zip_files/FoodBank3_copy_%281%29.apk,"mit-app-inventor, firebase, google-maps",Penn State Behrend,"","",kvw5270,Kevin,Wang,kvw5270@psu.edu,Pennsylvania State University,4,aryanshaurya,Shaurya,Aryan,aryan.shaurya@gmail.com,sid251143,Siddartha Reddy,Regatte,sid251143@gmail.com,kdl5273,Kieran,Laverty,kdl5273@psu.edu,tkk5189,Trevor,Knox,tkk5189@psu.edu
HackPSU Overall - Tech,A E S T H E T I C Mii Portable Wii,3,https://hackpsu-fall-2018.devpost.com/submissions/102447-a-e-s-t-h-e-t-i-c-mii-portable-wii,"Inspiration

I was inspired to do this project because I have seen many people do similar projects with Wii's all adding their own special touch to them. I knew this challenge would be interesting doing it over just a hackathon but I figured my skills at circuit analysis and hardware development could get me through it.

What it does

To put it simple its a Wii that is independently self contained. All games are pre stored within the new OSs on a hard drive, The Wii has a 9800mAh battery to allow it to last around 4 hours and has a screen for you or your friends to play on. The device can still operate as a standard Wii regardless of the environment, additionally it can still be played and powered on a standard TV. 

How I built it

I started off with a regular wii, And the first thing I did was modify the OS to not require non-essential hardware from preventing it from posting on boot and additionally, on detection of an external drive point to start up off of that directory rather than the native one. This software side was done for the most part with pre developed tools Homebrew, HackMii and BitBuild that were customly modified upon development. Much of the documentation of pinout diagrams are made public by people who made findings during their own installations. 

Next was to tear the wii apart and run a test to find the amount of Amps it drew with all electrical systems attached. Upon this each modification was made by microscope assisted hand soldering to the surface mounted components of the motherboard then tested for failure. All new modifications were carefully insulated, EMD shielded as best as possible and recased in a hacky modified Wii shell and Arizona Tea cans.  

Challenges I ran into

Within the first hour I blew out my op amp to control the volume. This made me lose a realistic implementation of sound. Additionally I had to solder electrical components with the hands of a surgeon and the patience of a customer service phone operator while I worked at 3AM and later.   

Accomplishments that I'm proud of

I didn't short it, break it, leave an open connection or make any irreparable mistakes.

What I learned

Soldering at 3AM is hard and electronics can be extremely challenging to modify post production.

What's next for A E S T H E T I C Mii Portable Wii

I definitely would like to put a new op amp in for sound and fix the faulty video in connection.
",,,,"soidering, wii, linux, sweat-and-tears",Penn State,"","",mmaslakowski,Michael,Maslakowski,mum544@psu.edu,Pennsylvania State University,0
"",Ranger Assistant ,8,https://hackpsu-fall-2018.devpost.com/submissions/102448-ranger-assistant,"Ranger Assistant is an iOS application designed to assist the service rangers of the National Park Service in maintaining the park. In addition to that, it would provide them with the feature to keep track of the visitors present in the park, number of visitors assigned to them, maintain work reports and allow them to handle routine technical skills.

In order to design the application, we went through a design process focusing on creating the required pages and the components contained by these pages to make the jobs of the rangers easier. To begin with the design process, it was essential for us to consider having a real-time map, input fields, facility of tracking other rangers,  assigned visitors, maintaining the park, and the most important, a ‘Report Emergency’ button to notify all the rangers in case of any emergency, for them to be able to take required precautions.

Home Page
Check In / Check Out

First Aid check out
 Under the First-Aid Check Out page, the ranger is supposed to fill out the information of what first aid is checked out from the inventory before the visit, and the quantity. After submitting, the database will be updated and the manager will be notified about the stock in the inventory. Using this feature, the manager can always keep track of first aids in the inventory.

Management
Work Report of the ranger.
 Cleanliness Tracker.
Using this feature will provide the rangers with the facility to report complaints along with their real-time location. Following this, the complaints will be received by the manager and he will be able to take further actions relating to the issue notified.

Visitors Stats
Total Rangers on duty
Visitors Active
Visitors assigned to the ranger
Total Visitors on that day

Track Rangers
Show the real time position of all the rangers on duty for the rangers to keep themselves updated about visits and visitors.

Emergency 
In case of any emergency, by clicking the ‘Report Emergency’ button, the application would notify all the rangers and the managers on duty for them to take necessary precaution. For the ease of locating the button, the ‘Report Emergency’ button is placed on the top-right corner of the page.

Website links:
    https://www.nps.gov/index.htm
    https://en.wikipedia.org/wiki/National_Park_Service
    https://www.nps.gov/subjects/infrastructure/maintenance-backlog.htm
    https://www.usa.gov/federal-agencies/national-park-service
    https://www.nps.gov/aboutus/contactus.htm
",,https://drive.google.com/file/d/1OzVAHhr76q69eI2XN1WNG-4PnBTFF6D2/view?usp=sharing,https://s3.amazonaws.com/challengepost/zip_files/production/36342/zip_files/NPSR.zip,"swift, xcode, photoshop",Penn State university,"","",lpp5139,Lay,Patel,lpp5139@psu.edu,Pennsylvania State University,3,psusjk,psusjk,,sjk5953@psu.edu,rps5556,Randeep,Singh,rps5556@psu.edu,sfa5353,Saksham,Arora,sfa5353@psu.edu
Vanguard - Reducing Student Debt,College Fit,58,https://hackpsu-fall-2018.devpost.com/submissions/102449-college-fit,"Inspiration

As a student who struggled in high school to find a college that would be right for me. My goal is to create things that would have helped me out when I was younger. If this project is implemented, it could help many students find the right college.

What it does

College Fit comes into the picture in high school, when choosing colleges: a very proactive student could look at maybe 30 colleges, but likely less than that. This is a problem as there are hundreds if not thousands of colleges that he or she cannot consider. With College Fit, a student can tell an application what they want in an ideal college, and the application will give him or her a list of colleges that would best match that ideal college.
College Fit helps to streamline the process and use modern machine learning and web scrapping of first person sources/ reviews to build models that can establish a 'fit' of a person's college experience.

How I built it

The way it works on that back end is that there is a script that scrapes review data from sites like niche.com or U.S. News College Rankings. After gathering the reviews, the data would be combined and put though a program that uses a natural language processing API, such as Google Cloud Natural Language Processing, or IBM’s Watson. By running a sentiment analysis, the program can find the specific advantages and disadvantages of each aspect of a college.  From that point, there would need to be another program that weights the salience (importance/relevance) and of each general area (sports, academics, extra-curriculars, etc) as well as more specific groups (in sports: baseball, tennis, etc.) After all the information is sorted and weighted, it will be compared to the provided student data. The student data could be gathered in multiple ways including an few paragraphs about what they want in their ideal college, or a survey with choices such as “A good physics department is important to me, rate 1-5 with 1 being it is not important”. By using this data to create a profile of the student, we can used a combination of the college’s and student’s  difference in their weights and sentiments to arrive at a score that can predict how well a college would match a given student.

Web Scrapper to create local data source => Input into a usable form to run Natural language processing => Data math to find Universities with the best fit.

Challenges I ran into

-Writing a web scrapper with no knowledge of building of working with pulling info from web elements
-Working with Selenium to build a working prototype.
-Setting up a natural Language processing Algorithm with google google cloud and creating usable data.

Accomplishments that I'm proud of

-Building a working webscrapper.
-Learning about sentiment analysis and natural language processing.
-Using web API's and Tools to accelerate the Machine learning framework
-Learning to use cloud platforms NLP and ML with minimally explanatory documentation

What I learned

-Honestly, I learned: I knew nothing.
-It was a hefty and tedious learning curve. Filled with confusion, pain and the will to give up.

What's next for College Fit

Further expansion of this idea could integrate factors like specific scholarships made available to specific demographics

Here's the link to the git-hub: https://github.com/Osaila/CollegeFit/tree/master/HackPSU2018Fall
",,https://github.com/Osaila/CollegeFit/tree/master/HackPSU2018Fall,https://s3.amazonaws.com/challengepost/zip_files/production/36344/zip_files/HackPSU2018Fall.zip,"python, selenium, google-cloud",Penn State,Google Cloud Platform,"",Osaila,Alexander,So,osailabackwards@gmail.com,Pennsylvania State University,0
Best use of Google Cloud Platform,College Fit,58,https://hackpsu-fall-2018.devpost.com/submissions/102449-college-fit,"Inspiration

As a student who struggled in high school to find a college that would be right for me. My goal is to create things that would have helped me out when I was younger. If this project is implemented, it could help many students find the right college.

What it does

College Fit comes into the picture in high school, when choosing colleges: a very proactive student could look at maybe 30 colleges, but likely less than that. This is a problem as there are hundreds if not thousands of colleges that he or she cannot consider. With College Fit, a student can tell an application what they want in an ideal college, and the application will give him or her a list of colleges that would best match that ideal college.
College Fit helps to streamline the process and use modern machine learning and web scrapping of first person sources/ reviews to build models that can establish a 'fit' of a person's college experience.

How I built it

The way it works on that back end is that there is a script that scrapes review data from sites like niche.com or U.S. News College Rankings. After gathering the reviews, the data would be combined and put though a program that uses a natural language processing API, such as Google Cloud Natural Language Processing, or IBM’s Watson. By running a sentiment analysis, the program can find the specific advantages and disadvantages of each aspect of a college.  From that point, there would need to be another program that weights the salience (importance/relevance) and of each general area (sports, academics, extra-curriculars, etc) as well as more specific groups (in sports: baseball, tennis, etc.) After all the information is sorted and weighted, it will be compared to the provided student data. The student data could be gathered in multiple ways including an few paragraphs about what they want in their ideal college, or a survey with choices such as “A good physics department is important to me, rate 1-5 with 1 being it is not important”. By using this data to create a profile of the student, we can used a combination of the college’s and student’s  difference in their weights and sentiments to arrive at a score that can predict how well a college would match a given student.

Web Scrapper to create local data source => Input into a usable form to run Natural language processing => Data math to find Universities with the best fit.

Challenges I ran into

-Writing a web scrapper with no knowledge of building of working with pulling info from web elements
-Working with Selenium to build a working prototype.
-Setting up a natural Language processing Algorithm with google google cloud and creating usable data.

Accomplishments that I'm proud of

-Building a working webscrapper.
-Learning about sentiment analysis and natural language processing.
-Using web API's and Tools to accelerate the Machine learning framework
-Learning to use cloud platforms NLP and ML with minimally explanatory documentation

What I learned

-Honestly, I learned: I knew nothing.
-It was a hefty and tedious learning curve. Filled with confusion, pain and the will to give up.

What's next for College Fit

Further expansion of this idea could integrate factors like specific scholarships made available to specific demographics

Here's the link to the git-hub: https://github.com/Osaila/CollegeFit/tree/master/HackPSU2018Fall
",,https://github.com/Osaila/CollegeFit/tree/master/HackPSU2018Fall,https://s3.amazonaws.com/challengepost/zip_files/production/36344/zip_files/HackPSU2018Fall.zip,"python, selenium, google-cloud",Penn State,Google Cloud Platform,"",Osaila,Alexander,So,osailabackwards@gmail.com,Pennsylvania State University,0
Nittany AI Alliance - AI Challenge,College Fit,58,https://hackpsu-fall-2018.devpost.com/submissions/102449-college-fit,"Inspiration

As a student who struggled in high school to find a college that would be right for me. My goal is to create things that would have helped me out when I was younger. If this project is implemented, it could help many students find the right college.

What it does

College Fit comes into the picture in high school, when choosing colleges: a very proactive student could look at maybe 30 colleges, but likely less than that. This is a problem as there are hundreds if not thousands of colleges that he or she cannot consider. With College Fit, a student can tell an application what they want in an ideal college, and the application will give him or her a list of colleges that would best match that ideal college.
College Fit helps to streamline the process and use modern machine learning and web scrapping of first person sources/ reviews to build models that can establish a 'fit' of a person's college experience.

How I built it

The way it works on that back end is that there is a script that scrapes review data from sites like niche.com or U.S. News College Rankings. After gathering the reviews, the data would be combined and put though a program that uses a natural language processing API, such as Google Cloud Natural Language Processing, or IBM’s Watson. By running a sentiment analysis, the program can find the specific advantages and disadvantages of each aspect of a college.  From that point, there would need to be another program that weights the salience (importance/relevance) and of each general area (sports, academics, extra-curriculars, etc) as well as more specific groups (in sports: baseball, tennis, etc.) After all the information is sorted and weighted, it will be compared to the provided student data. The student data could be gathered in multiple ways including an few paragraphs about what they want in their ideal college, or a survey with choices such as “A good physics department is important to me, rate 1-5 with 1 being it is not important”. By using this data to create a profile of the student, we can used a combination of the college’s and student’s  difference in their weights and sentiments to arrive at a score that can predict how well a college would match a given student.

Web Scrapper to create local data source => Input into a usable form to run Natural language processing => Data math to find Universities with the best fit.

Challenges I ran into

-Writing a web scrapper with no knowledge of building of working with pulling info from web elements
-Working with Selenium to build a working prototype.
-Setting up a natural Language processing Algorithm with google google cloud and creating usable data.

Accomplishments that I'm proud of

-Building a working webscrapper.
-Learning about sentiment analysis and natural language processing.
-Using web API's and Tools to accelerate the Machine learning framework
-Learning to use cloud platforms NLP and ML with minimally explanatory documentation

What I learned

-Honestly, I learned: I knew nothing.
-It was a hefty and tedious learning curve. Filled with confusion, pain and the will to give up.

What's next for College Fit

Further expansion of this idea could integrate factors like specific scholarships made available to specific demographics

Here's the link to the git-hub: https://github.com/Osaila/CollegeFit/tree/master/HackPSU2018Fall
",,https://github.com/Osaila/CollegeFit/tree/master/HackPSU2018Fall,https://s3.amazonaws.com/challengepost/zip_files/production/36344/zip_files/HackPSU2018Fall.zip,"python, selenium, google-cloud",Penn State,Google Cloud Platform,"",Osaila,Alexander,So,osailabackwards@gmail.com,Pennsylvania State University,0
Accuweather Challenge,Project Goldilocks,84,https://hackpsu-fall-2018.devpost.com/submissions/102450-project-goldilocks,"Inspiration

We were inspired by the AccuWeather challenge and by the belief that everybody, regardless of how much time they have to sift through the weather, is entitled to a beautiful day outside. 

What it does

This web app takes a city name from the user and provides time slots within the next three days when the weather should be best suited for being outdoors. A simple algorithm determines when the weather outside will be nicest relative to other times within the window and displays these times with basic weather data like temperature, cloud cover, and the probability of precipitation.

How we built it

We employed two AccuWeather APIs: the city search Location API which yields the unique location key for a typed city name and the 72-hour forecast API which produces hourly weather data for a location given its unique location key. Linking these together allows a user to search for a city by name and see weather data for that location. This back end functionality was integrated with an HTML front end with CSS formatting via Flask to deliver our final web app.

Challenges we ran into

Initially, we intended to inform the user of the weather conditions at nearby points of interest (amusement or nature parks, etc) within a designated radius, but the AccuWeather Points of Interest Location API didn't yield expected or useful results. We knew Google's Maps API could replace this functionality, but time/energy constraints didn't allow us to implement this work-around. As a result, our final product is less utilitarian than we imagined.

Accomplishments that we're proud of

Successfully implementing two APIs within a Python back end to an HTML front end by the end of the short time frame given the number of obstacles we came up to felt an accomplishment, especially we hadn't particularly worked with these tools before. We had a varied set of skills within our group that we combined to produce something us individuals wouldn't have been able to alone in so short a period. As developing developers, meshing our skills to increase our combined utility was an accomplishment for us.

What we learned

We learned that JSON files can save you much time scraping/manipulating data if you take advantage of their structure. Also, we collectively learned much through the process of working with tools we hadn't used before. For example, a couple of us hadn't worked much in Python but were handy with HTML; Flask was a newly found tool for us; and now we understand the use of cURL.

What's next for Project Goldilocks

Our next step would definitely be to implement Google Maps API so we could show the user weather information about nearby attractions, which would take our web app to a higher level of utility. Currently, finding the weather data for a singular location is about 3 clicks away on your mobile weather app. However, if we could perform weather quality comparisons for a number of locations of interest, we'd be automating a task the user would have otherwise performed manually: a central goal of computing. After that, we would definitely want to sharpen and refine our HTML interface, improve the quality of our weather reports, and host the web app on a public domain. 
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36345/zip_files/Goldilocks.zip,"python, html, accuweather, curl, flask",PSU,"","",IsaacEinwechter,Isaac,E.,isaac.e@outlook.com,Pennsylvania State University,2,iharshbarger9,,,idh5029@psu.edu,loudenmaclay,Louden,Maclay,louden.maclay@yahoo.com
AWS Challenge,Lazy-Note,12,https://hackpsu-fall-2018.devpost.com/submissions/102451-lazy-note,"Inspiration

With the growing need for note-takers in classrooms and accurate, detailed notes in meetings, we decided to make an application that makes these things easily attainable. As students, we were all familiar with the countless emails the school faculty sends out all semester long, looking for students to help those who need assistance in taking notes. We came across Amazon Web Services Transcribe service, and decided we could do something about it. From there the possible use-cases grew to the average student looking for more exact note-taking tools and business professionals needing accurate meeting minutes.

What it does

lazyNote records audio in real-time, and sends it to one of our AWS S3 buckets. Once the user stops recording, our system, built entirely in AWS Serverless Lambda functions and coordinated by an AWS Step Function, begins running jobs to transcribe the user's audio data into a text file to be used at their convenience. Once our system is finished, an email is sent to the address the user supplies at the beginning of the process containing a link to the text object in S3. Once the link is clicked, a download of the file begins immediately. 

How we built it

The front-end is built entirely in HTML5, CSS3, and vanilla JavaScript with some Bootstrap4 elements for styling. Connecting the front-end to the back-end is an AWS API Gateway, which directs traffic to our AWS Step Function. We registered our domain, lazy-note.com with Domain.com, and connected it to our system with AWS's Route 53. Our back end is a series of AWS Lambda functions written in Python3 utilizing the boto3 library. 

Challenges we ran into

AWS permissions gave us a hard time for a while, as did getting browsers to give us access to the computer's microphone, and conversion between MP3 files and WAV files.

Accomplishments that we're proud of

Continuing to persist until the system worked. Creating an app that people (we) might actually want to use, and has to potential to help students who need learning support.

What we learned

Three of our members had never worked with AWS Serverless, so they learned a lot in a short amount of time. Two of them had never even worked with AWS at all. Our primary DevOps engineer learned how to add logic into a Step Function. We learned how to use the AWS Transcribe API and how to write API Gateways from scratch.

What's next for Lazy-Note

Eventually we want to increase security and establish user profiles with persistent data storage. 
",,http://lazy-note.com,https://s3.amazonaws.com/challengepost/zip_files/production/36361/zip_files/lazyNote.zip,"python, amazon-web-services, serverless, transcibe-api, api-gateway, step-functions, amazon-route-53, html5, javascript, css3, bootstrap, machine-learning",Indiana University of Pennsylvania,"","",skhx,jason,ricupero,skhx@iup.edu,Indiana University of Pennsylvania,4,mr64bit,James,,lutz.jamesa@gmail.com,atdaniel422,Andrew,Daniel,atdaniel422@gmail.com,bransynluther,Bransyn,Luther,bransynluther@gmail.com,hdvv,Dan,Richmond,hdvv@iup.edu
Best Domain Name from Domain.com,Lazy-Note,12,https://hackpsu-fall-2018.devpost.com/submissions/102451-lazy-note,"Inspiration

With the growing need for note-takers in classrooms and accurate, detailed notes in meetings, we decided to make an application that makes these things easily attainable. As students, we were all familiar with the countless emails the school faculty sends out all semester long, looking for students to help those who need assistance in taking notes. We came across Amazon Web Services Transcribe service, and decided we could do something about it. From there the possible use-cases grew to the average student looking for more exact note-taking tools and business professionals needing accurate meeting minutes.

What it does

lazyNote records audio in real-time, and sends it to one of our AWS S3 buckets. Once the user stops recording, our system, built entirely in AWS Serverless Lambda functions and coordinated by an AWS Step Function, begins running jobs to transcribe the user's audio data into a text file to be used at their convenience. Once our system is finished, an email is sent to the address the user supplies at the beginning of the process containing a link to the text object in S3. Once the link is clicked, a download of the file begins immediately. 

How we built it

The front-end is built entirely in HTML5, CSS3, and vanilla JavaScript with some Bootstrap4 elements for styling. Connecting the front-end to the back-end is an AWS API Gateway, which directs traffic to our AWS Step Function. We registered our domain, lazy-note.com with Domain.com, and connected it to our system with AWS's Route 53. Our back end is a series of AWS Lambda functions written in Python3 utilizing the boto3 library. 

Challenges we ran into

AWS permissions gave us a hard time for a while, as did getting browsers to give us access to the computer's microphone, and conversion between MP3 files and WAV files.

Accomplishments that we're proud of

Continuing to persist until the system worked. Creating an app that people (we) might actually want to use, and has to potential to help students who need learning support.

What we learned

Three of our members had never worked with AWS Serverless, so they learned a lot in a short amount of time. Two of them had never even worked with AWS at all. Our primary DevOps engineer learned how to add logic into a Step Function. We learned how to use the AWS Transcribe API and how to write API Gateways from scratch.

What's next for Lazy-Note

Eventually we want to increase security and establish user profiles with persistent data storage. 
",,http://lazy-note.com,https://s3.amazonaws.com/challengepost/zip_files/production/36361/zip_files/lazyNote.zip,"python, amazon-web-services, serverless, transcibe-api, api-gateway, step-functions, amazon-route-53, html5, javascript, css3, bootstrap, machine-learning",Indiana University of Pennsylvania,"","",skhx,jason,ricupero,skhx@iup.edu,Indiana University of Pennsylvania,4,mr64bit,James,,lutz.jamesa@gmail.com,atdaniel422,Andrew,Daniel,atdaniel422@gmail.com,bransynluther,Bransyn,Luther,bransynluther@gmail.com,hdvv,Dan,Richmond,hdvv@iup.edu
HackPSU Overall - Design,Lazy-Note,12,https://hackpsu-fall-2018.devpost.com/submissions/102451-lazy-note,"Inspiration

With the growing need for note-takers in classrooms and accurate, detailed notes in meetings, we decided to make an application that makes these things easily attainable. As students, we were all familiar with the countless emails the school faculty sends out all semester long, looking for students to help those who need assistance in taking notes. We came across Amazon Web Services Transcribe service, and decided we could do something about it. From there the possible use-cases grew to the average student looking for more exact note-taking tools and business professionals needing accurate meeting minutes.

What it does

lazyNote records audio in real-time, and sends it to one of our AWS S3 buckets. Once the user stops recording, our system, built entirely in AWS Serverless Lambda functions and coordinated by an AWS Step Function, begins running jobs to transcribe the user's audio data into a text file to be used at their convenience. Once our system is finished, an email is sent to the address the user supplies at the beginning of the process containing a link to the text object in S3. Once the link is clicked, a download of the file begins immediately. 

How we built it

The front-end is built entirely in HTML5, CSS3, and vanilla JavaScript with some Bootstrap4 elements for styling. Connecting the front-end to the back-end is an AWS API Gateway, which directs traffic to our AWS Step Function. We registered our domain, lazy-note.com with Domain.com, and connected it to our system with AWS's Route 53. Our back end is a series of AWS Lambda functions written in Python3 utilizing the boto3 library. 

Challenges we ran into

AWS permissions gave us a hard time for a while, as did getting browsers to give us access to the computer's microphone, and conversion between MP3 files and WAV files.

Accomplishments that we're proud of

Continuing to persist until the system worked. Creating an app that people (we) might actually want to use, and has to potential to help students who need learning support.

What we learned

Three of our members had never worked with AWS Serverless, so they learned a lot in a short amount of time. Two of them had never even worked with AWS at all. Our primary DevOps engineer learned how to add logic into a Step Function. We learned how to use the AWS Transcribe API and how to write API Gateways from scratch.

What's next for Lazy-Note

Eventually we want to increase security and establish user profiles with persistent data storage. 
",,http://lazy-note.com,https://s3.amazonaws.com/challengepost/zip_files/production/36361/zip_files/lazyNote.zip,"python, amazon-web-services, serverless, transcibe-api, api-gateway, step-functions, amazon-route-53, html5, javascript, css3, bootstrap, machine-learning",Indiana University of Pennsylvania,"","",skhx,jason,ricupero,skhx@iup.edu,Indiana University of Pennsylvania,4,mr64bit,James,,lutz.jamesa@gmail.com,atdaniel422,Andrew,Daniel,atdaniel422@gmail.com,bransynluther,Bransyn,Luther,bransynluther@gmail.com,hdvv,Dan,Richmond,hdvv@iup.edu
Booz Allen Hamilton - Best Machine Learning Hack,Lazy-Note,12,https://hackpsu-fall-2018.devpost.com/submissions/102451-lazy-note,"Inspiration

With the growing need for note-takers in classrooms and accurate, detailed notes in meetings, we decided to make an application that makes these things easily attainable. As students, we were all familiar with the countless emails the school faculty sends out all semester long, looking for students to help those who need assistance in taking notes. We came across Amazon Web Services Transcribe service, and decided we could do something about it. From there the possible use-cases grew to the average student looking for more exact note-taking tools and business professionals needing accurate meeting minutes.

What it does

lazyNote records audio in real-time, and sends it to one of our AWS S3 buckets. Once the user stops recording, our system, built entirely in AWS Serverless Lambda functions and coordinated by an AWS Step Function, begins running jobs to transcribe the user's audio data into a text file to be used at their convenience. Once our system is finished, an email is sent to the address the user supplies at the beginning of the process containing a link to the text object in S3. Once the link is clicked, a download of the file begins immediately. 

How we built it

The front-end is built entirely in HTML5, CSS3, and vanilla JavaScript with some Bootstrap4 elements for styling. Connecting the front-end to the back-end is an AWS API Gateway, which directs traffic to our AWS Step Function. We registered our domain, lazy-note.com with Domain.com, and connected it to our system with AWS's Route 53. Our back end is a series of AWS Lambda functions written in Python3 utilizing the boto3 library. 

Challenges we ran into

AWS permissions gave us a hard time for a while, as did getting browsers to give us access to the computer's microphone, and conversion between MP3 files and WAV files.

Accomplishments that we're proud of

Continuing to persist until the system worked. Creating an app that people (we) might actually want to use, and has to potential to help students who need learning support.

What we learned

Three of our members had never worked with AWS Serverless, so they learned a lot in a short amount of time. Two of them had never even worked with AWS at all. Our primary DevOps engineer learned how to add logic into a Step Function. We learned how to use the AWS Transcribe API and how to write API Gateways from scratch.

What's next for Lazy-Note

Eventually we want to increase security and establish user profiles with persistent data storage. 
",,http://lazy-note.com,https://s3.amazonaws.com/challengepost/zip_files/production/36361/zip_files/lazyNote.zip,"python, amazon-web-services, serverless, transcibe-api, api-gateway, step-functions, amazon-route-53, html5, javascript, css3, bootstrap, machine-learning",Indiana University of Pennsylvania,"","",skhx,jason,ricupero,skhx@iup.edu,Indiana University of Pennsylvania,4,mr64bit,James,,lutz.jamesa@gmail.com,atdaniel422,Andrew,Daniel,atdaniel422@gmail.com,bransynluther,Bransyn,Luther,bransynluther@gmail.com,hdvv,Dan,Richmond,hdvv@iup.edu
Nittany AI Alliance - AI Challenge,Lazy-Note,12,https://hackpsu-fall-2018.devpost.com/submissions/102451-lazy-note,"Inspiration

With the growing need for note-takers in classrooms and accurate, detailed notes in meetings, we decided to make an application that makes these things easily attainable. As students, we were all familiar with the countless emails the school faculty sends out all semester long, looking for students to help those who need assistance in taking notes. We came across Amazon Web Services Transcribe service, and decided we could do something about it. From there the possible use-cases grew to the average student looking for more exact note-taking tools and business professionals needing accurate meeting minutes.

What it does

lazyNote records audio in real-time, and sends it to one of our AWS S3 buckets. Once the user stops recording, our system, built entirely in AWS Serverless Lambda functions and coordinated by an AWS Step Function, begins running jobs to transcribe the user's audio data into a text file to be used at their convenience. Once our system is finished, an email is sent to the address the user supplies at the beginning of the process containing a link to the text object in S3. Once the link is clicked, a download of the file begins immediately. 

How we built it

The front-end is built entirely in HTML5, CSS3, and vanilla JavaScript with some Bootstrap4 elements for styling. Connecting the front-end to the back-end is an AWS API Gateway, which directs traffic to our AWS Step Function. We registered our domain, lazy-note.com with Domain.com, and connected it to our system with AWS's Route 53. Our back end is a series of AWS Lambda functions written in Python3 utilizing the boto3 library. 

Challenges we ran into

AWS permissions gave us a hard time for a while, as did getting browsers to give us access to the computer's microphone, and conversion between MP3 files and WAV files.

Accomplishments that we're proud of

Continuing to persist until the system worked. Creating an app that people (we) might actually want to use, and has to potential to help students who need learning support.

What we learned

Three of our members had never worked with AWS Serverless, so they learned a lot in a short amount of time. Two of them had never even worked with AWS at all. Our primary DevOps engineer learned how to add logic into a Step Function. We learned how to use the AWS Transcribe API and how to write API Gateways from scratch.

What's next for Lazy-Note

Eventually we want to increase security and establish user profiles with persistent data storage. 
",,http://lazy-note.com,https://s3.amazonaws.com/challengepost/zip_files/production/36361/zip_files/lazyNote.zip,"python, amazon-web-services, serverless, transcibe-api, api-gateway, step-functions, amazon-route-53, html5, javascript, css3, bootstrap, machine-learning",Indiana University of Pennsylvania,"","",skhx,jason,ricupero,skhx@iup.edu,Indiana University of Pennsylvania,4,mr64bit,James,,lutz.jamesa@gmail.com,atdaniel422,Andrew,Daniel,atdaniel422@gmail.com,bransynluther,Bransyn,Luther,bransynluther@gmail.com,hdvv,Dan,Richmond,hdvv@iup.edu
HackPSU Overall - Tech,Lazy-Note,12,https://hackpsu-fall-2018.devpost.com/submissions/102451-lazy-note,"Inspiration

With the growing need for note-takers in classrooms and accurate, detailed notes in meetings, we decided to make an application that makes these things easily attainable. As students, we were all familiar with the countless emails the school faculty sends out all semester long, looking for students to help those who need assistance in taking notes. We came across Amazon Web Services Transcribe service, and decided we could do something about it. From there the possible use-cases grew to the average student looking for more exact note-taking tools and business professionals needing accurate meeting minutes.

What it does

lazyNote records audio in real-time, and sends it to one of our AWS S3 buckets. Once the user stops recording, our system, built entirely in AWS Serverless Lambda functions and coordinated by an AWS Step Function, begins running jobs to transcribe the user's audio data into a text file to be used at their convenience. Once our system is finished, an email is sent to the address the user supplies at the beginning of the process containing a link to the text object in S3. Once the link is clicked, a download of the file begins immediately. 

How we built it

The front-end is built entirely in HTML5, CSS3, and vanilla JavaScript with some Bootstrap4 elements for styling. Connecting the front-end to the back-end is an AWS API Gateway, which directs traffic to our AWS Step Function. We registered our domain, lazy-note.com with Domain.com, and connected it to our system with AWS's Route 53. Our back end is a series of AWS Lambda functions written in Python3 utilizing the boto3 library. 

Challenges we ran into

AWS permissions gave us a hard time for a while, as did getting browsers to give us access to the computer's microphone, and conversion between MP3 files and WAV files.

Accomplishments that we're proud of

Continuing to persist until the system worked. Creating an app that people (we) might actually want to use, and has to potential to help students who need learning support.

What we learned

Three of our members had never worked with AWS Serverless, so they learned a lot in a short amount of time. Two of them had never even worked with AWS at all. Our primary DevOps engineer learned how to add logic into a Step Function. We learned how to use the AWS Transcribe API and how to write API Gateways from scratch.

What's next for Lazy-Note

Eventually we want to increase security and establish user profiles with persistent data storage. 
",,http://lazy-note.com,https://s3.amazonaws.com/challengepost/zip_files/production/36361/zip_files/lazyNote.zip,"python, amazon-web-services, serverless, transcibe-api, api-gateway, step-functions, amazon-route-53, html5, javascript, css3, bootstrap, machine-learning",Indiana University of Pennsylvania,"","",skhx,jason,ricupero,skhx@iup.edu,Indiana University of Pennsylvania,4,mr64bit,James,,lutz.jamesa@gmail.com,atdaniel422,Andrew,Daniel,atdaniel422@gmail.com,bransynluther,Bransyn,Luther,bransynluther@gmail.com,hdvv,Dan,Richmond,hdvv@iup.edu
Best use of Google Cloud Platform,Course Concepts Detector using Google APIs,38,https://hackpsu-fall-2018.devpost.com/submissions/102452-course-concepts-detector-using-google-apis,"Inspiration

Have you ever missed a class or felt so lost in a tediously long lecture that you feel like you don't have time to learn the material? Our Course Concepts Detector using Google's speech-to-text API helps solve just that problem!

What it does

Our project takes in a video file of a lecture or any other video, parses the video and separates it into the major concepts that are covered. From there, it prioritizes the words based on frequency of use in the video vs. frequency of use in US-en and displays the major concepts along with their time stamps, so that they are easily found in the video.

How we built it

We wrote our code using python to parse the text that the Google API outputted. Once the text was parsed, we created sets and lists and used Parse_Timestamps to get rid of the fluff words. From there we used an average frequency function to display the most commonly used nouns/concepts. Since we used a time stamp format, we also had access to the specific time these words were displayed. With this information, the user can easily find the most important information from the video.

Challenges we ran into


60 second time limit for converting video to text
Unfamiliarity with google APIs and how to integrate it with our program
Accuracy of the speech-to-text converter


Accomplishments that we're proud of

We're very proud that we now have a functional program that we can use to split videos into the major concepts. This project allows us to see, tangibly, the power of coding and using built-in libraries such as Google's APIs. We can all personally use this software to save us time with our coursework.

What we learned

Firstly, we learned to function effectively as a team and seek help from mentors/experts to help us with our questions. This is an indispensable lesson that will help us in any team scenario, regardless of the specific application.
Secondly, we learned how to break down a large problem into smaller, manageable problems that can be designated to specific individuals, so that it can be attacked efficiently as a team.
Thirdly, we fostered our creativity and confidence with coding by thinking of a problem that is both useful and doable, even on a short time notice.
Finally, we learned how to combine software at multiple layers in a way that academia hasn't taught us, which solidified our overall engineering capabilities.

What's next for Course Concepts Detector using Google APIs

We can use the Google Streaming service to input longer videos and make a more user-friendly/beautiful user interface that can more optimally provide value to the end-user.
This idea can be expanded on the industrial scale to assist employees/ users in finding important information from any video/audio they need to view.
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36363/zip_files/Untitled_document.pdf,"python, google-cloud, text-to-speech, google-text-to-speech-api",Penn State,Google Cloud Platform,"",JohnAnderson1,John,Anderson,john.j.anderson5@gmail.com,Pennsylvania State University,3,CyberMobius,Brian,,brimyth@gmail.com,azb281,Abdulaziz,Boudy,azb281@psu.edu,AbhinavAgarwal,Abhinav,Agarwal,abhinavagarwal1925@gmail.com
Nittany AI Alliance - AI Challenge,Course Concepts Detector using Google APIs,38,https://hackpsu-fall-2018.devpost.com/submissions/102452-course-concepts-detector-using-google-apis,"Inspiration

Have you ever missed a class or felt so lost in a tediously long lecture that you feel like you don't have time to learn the material? Our Course Concepts Detector using Google's speech-to-text API helps solve just that problem!

What it does

Our project takes in a video file of a lecture or any other video, parses the video and separates it into the major concepts that are covered. From there, it prioritizes the words based on frequency of use in the video vs. frequency of use in US-en and displays the major concepts along with their time stamps, so that they are easily found in the video.

How we built it

We wrote our code using python to parse the text that the Google API outputted. Once the text was parsed, we created sets and lists and used Parse_Timestamps to get rid of the fluff words. From there we used an average frequency function to display the most commonly used nouns/concepts. Since we used a time stamp format, we also had access to the specific time these words were displayed. With this information, the user can easily find the most important information from the video.

Challenges we ran into


60 second time limit for converting video to text
Unfamiliarity with google APIs and how to integrate it with our program
Accuracy of the speech-to-text converter


Accomplishments that we're proud of

We're very proud that we now have a functional program that we can use to split videos into the major concepts. This project allows us to see, tangibly, the power of coding and using built-in libraries such as Google's APIs. We can all personally use this software to save us time with our coursework.

What we learned

Firstly, we learned to function effectively as a team and seek help from mentors/experts to help us with our questions. This is an indispensable lesson that will help us in any team scenario, regardless of the specific application.
Secondly, we learned how to break down a large problem into smaller, manageable problems that can be designated to specific individuals, so that it can be attacked efficiently as a team.
Thirdly, we fostered our creativity and confidence with coding by thinking of a problem that is both useful and doable, even on a short time notice.
Finally, we learned how to combine software at multiple layers in a way that academia hasn't taught us, which solidified our overall engineering capabilities.

What's next for Course Concepts Detector using Google APIs

We can use the Google Streaming service to input longer videos and make a more user-friendly/beautiful user interface that can more optimally provide value to the end-user.
This idea can be expanded on the industrial scale to assist employees/ users in finding important information from any video/audio they need to view.
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36363/zip_files/Untitled_document.pdf,"python, google-cloud, text-to-speech, google-text-to-speech-api",Penn State,Google Cloud Platform,"",JohnAnderson1,John,Anderson,john.j.anderson5@gmail.com,Pennsylvania State University,3,CyberMobius,Brian,,brimyth@gmail.com,azb281,Abdulaziz,Boudy,azb281@psu.edu,AbhinavAgarwal,Abhinav,Agarwal,abhinavagarwal1925@gmail.com
HackPSU Overall - Tech,Course Concepts Detector using Google APIs,38,https://hackpsu-fall-2018.devpost.com/submissions/102452-course-concepts-detector-using-google-apis,"Inspiration

Have you ever missed a class or felt so lost in a tediously long lecture that you feel like you don't have time to learn the material? Our Course Concepts Detector using Google's speech-to-text API helps solve just that problem!

What it does

Our project takes in a video file of a lecture or any other video, parses the video and separates it into the major concepts that are covered. From there, it prioritizes the words based on frequency of use in the video vs. frequency of use in US-en and displays the major concepts along with their time stamps, so that they are easily found in the video.

How we built it

We wrote our code using python to parse the text that the Google API outputted. Once the text was parsed, we created sets and lists and used Parse_Timestamps to get rid of the fluff words. From there we used an average frequency function to display the most commonly used nouns/concepts. Since we used a time stamp format, we also had access to the specific time these words were displayed. With this information, the user can easily find the most important information from the video.

Challenges we ran into


60 second time limit for converting video to text
Unfamiliarity with google APIs and how to integrate it with our program
Accuracy of the speech-to-text converter


Accomplishments that we're proud of

We're very proud that we now have a functional program that we can use to split videos into the major concepts. This project allows us to see, tangibly, the power of coding and using built-in libraries such as Google's APIs. We can all personally use this software to save us time with our coursework.

What we learned

Firstly, we learned to function effectively as a team and seek help from mentors/experts to help us with our questions. This is an indispensable lesson that will help us in any team scenario, regardless of the specific application.
Secondly, we learned how to break down a large problem into smaller, manageable problems that can be designated to specific individuals, so that it can be attacked efficiently as a team.
Thirdly, we fostered our creativity and confidence with coding by thinking of a problem that is both useful and doable, even on a short time notice.
Finally, we learned how to combine software at multiple layers in a way that academia hasn't taught us, which solidified our overall engineering capabilities.

What's next for Course Concepts Detector using Google APIs

We can use the Google Streaming service to input longer videos and make a more user-friendly/beautiful user interface that can more optimally provide value to the end-user.
This idea can be expanded on the industrial scale to assist employees/ users in finding important information from any video/audio they need to view.
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36363/zip_files/Untitled_document.pdf,"python, google-cloud, text-to-speech, google-text-to-speech-api",Penn State,Google Cloud Platform,"",JohnAnderson1,John,Anderson,john.j.anderson5@gmail.com,Pennsylvania State University,3,CyberMobius,Brian,,brimyth@gmail.com,azb281,Abdulaziz,Boudy,azb281@psu.edu,AbhinavAgarwal,Abhinav,Agarwal,abhinavagarwal1925@gmail.com
Vanguard - Reducing Student Debt,HackPSU Fall 2018 - College Exchange,52,https://hackpsu-fall-2018.devpost.com/submissions/102454-hackpsu-fall-2018-college-exchange,"Inspiration

Some of us noticed how students at our college had difficultly exchanging goods and services on the crowed news feed of the class Facebook page and we wanted to alleviate this.

What it does

The website offers students to sell and search for commodities as books, car rides, clothes, services, and housing. Our intent was to use Google's Vision and Search APIs to interpret the covers of books.

How we built it

We each divided up the project to design a different portion of it.

Challenges we ran into

We ran into challenges designing the python script to interpret the images as we originally wanted it to. 
We ran into several issues with PHP not wanting to run on the Ride Share page

Accomplishments that we're proud of

We're proud that we were all able to come together and create a project for, most of us, our first HackPSU.

What we learned

Learned how to write server-side documents in PHP, relearned HTML and Javascript

What's next for HackPSU Fall 2018 - College Exchange

Possibly finishing a ticket exchange and adding a more visually appealing design.
",,https://collegeexchange.000webhostapp.com/index.php,,"php, html5, javascript, xml, python",1,"","",alexrrobbins,Alex,Robbins,alexrrobbins@gmail.com,Indiana University of Pennsylvania,2,ColeBowman,,,lqhx@iup.edu,rhrv,rhrv,,rhrv@iup.edu
Accuweather Challenge,Perfect Weather,21,https://hackpsu-fall-2018.devpost.com/submissions/102455-perfect-weather,"Inspiration - Helping people plan their events an activities in a simple and straightforward manner.

What it does - In a perfect world, our project would assist users by asking an AI what the best days for an event would be, or requesting when certain weather would take place.

How we built it

Challenges we ran into - Changing idea from different topics. Implementation issues due to time required to learn new programs.

Accomplishments that we're proud of - Learned the basics of Google & AccuWeather APIs.

What we learned - How to adapt to challenges as a team. To simplify topics to a specific idea instead of trying to hit everything at once. Keeping an open scope instead of narrowing into one niche topic.

What's next for Perfect Weather - In the future, this would be implemented directly into the AccuWeather app to plan for events based on weather, implemented into voice assistants for info on what the weather would be when planning a specific date and time, and implementing directly into calendar apps such as Google Calendars to show the weather directly when you are selecting a date and time.
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36356/zip_files/PerfectWeather.pptx,"",Pennsylvania State University,Google Cloud Platform,"",JonathanMerry,Jonathan,Merry,jmerrywork@outlook.com,Pennsylvania State University,3,zdl5022,Zack,Ley,zdl5022@psu.edu,TheDoctor33,LukeLeiter,,ldlstarwars@gmail.com,afb5417,Amer,Bualhasan,afb5417@psu.edu
HackPSU Overall - Design,Perfect Weather,21,https://hackpsu-fall-2018.devpost.com/submissions/102455-perfect-weather,"Inspiration - Helping people plan their events an activities in a simple and straightforward manner.

What it does - In a perfect world, our project would assist users by asking an AI what the best days for an event would be, or requesting when certain weather would take place.

How we built it

Challenges we ran into - Changing idea from different topics. Implementation issues due to time required to learn new programs.

Accomplishments that we're proud of - Learned the basics of Google & AccuWeather APIs.

What we learned - How to adapt to challenges as a team. To simplify topics to a specific idea instead of trying to hit everything at once. Keeping an open scope instead of narrowing into one niche topic.

What's next for Perfect Weather - In the future, this would be implemented directly into the AccuWeather app to plan for events based on weather, implemented into voice assistants for info on what the weather would be when planning a specific date and time, and implementing directly into calendar apps such as Google Calendars to show the weather directly when you are selecting a date and time.
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36356/zip_files/PerfectWeather.pptx,"",Pennsylvania State University,Google Cloud Platform,"",JonathanMerry,Jonathan,Merry,jmerrywork@outlook.com,Pennsylvania State University,3,zdl5022,Zack,Ley,zdl5022@psu.edu,TheDoctor33,LukeLeiter,,ldlstarwars@gmail.com,afb5417,Amer,Bualhasan,afb5417@psu.edu
Best use of Google Cloud Platform,Perfect Weather,21,https://hackpsu-fall-2018.devpost.com/submissions/102455-perfect-weather,"Inspiration - Helping people plan their events an activities in a simple and straightforward manner.

What it does - In a perfect world, our project would assist users by asking an AI what the best days for an event would be, or requesting when certain weather would take place.

How we built it

Challenges we ran into - Changing idea from different topics. Implementation issues due to time required to learn new programs.

Accomplishments that we're proud of - Learned the basics of Google & AccuWeather APIs.

What we learned - How to adapt to challenges as a team. To simplify topics to a specific idea instead of trying to hit everything at once. Keeping an open scope instead of narrowing into one niche topic.

What's next for Perfect Weather - In the future, this would be implemented directly into the AccuWeather app to plan for events based on weather, implemented into voice assistants for info on what the weather would be when planning a specific date and time, and implementing directly into calendar apps such as Google Calendars to show the weather directly when you are selecting a date and time.
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36356/zip_files/PerfectWeather.pptx,"",Pennsylvania State University,Google Cloud Platform,"",JonathanMerry,Jonathan,Merry,jmerrywork@outlook.com,Pennsylvania State University,3,zdl5022,Zack,Ley,zdl5022@psu.edu,TheDoctor33,LukeLeiter,,ldlstarwars@gmail.com,afb5417,Amer,Bualhasan,afb5417@psu.edu
Best Domain Name from Domain.com,Lluvia,1,https://hackpsu-fall-2018.devpost.com/submissions/102456-lluvia,"Inspiration

Everyday we go through life 

What it does

This application generates playlists for the user based on realtime weather forecast data and the impact that has on moods as well as the user's past listening history through utilization and creation of algorithms.

How we built it

We utilized Ruby on Rails to create our project and built everything around it. We pulled from AccuWeather's APIs including MinuteCast and the 24Hour Hourly Forecast. We also pulled from Spotify's Authentication, Tracks, and Playlists. We also utilized various smaller APIs for features such as IP location etc.

Challenges we ran into

We all learned Ruby which is a language that none of us had any experience with. We also faced challenges with creating a valid and acceptable process in which to go about this within 24 hours. 

Accomplishments that we're proud of

We are proud that we have something to show off at the end of this Hackathon. We are proud of the growth we underwent throughout the sleep deprivation and red bull fueled yelling matches with our computers. We are proud to have come up with an idea and know what tools and methods we need to implement in order to make something that has massive potential and can be widely used. 

What we learned

We learned essential skills in Ruby and web development. We also refined our abilities to make algorithms to decipher needed scenarios through utilizing metrics and coming up with our own through reading research papers and studies.

What's next for Lluvia

Lluvia is just getting started. We did not have a chance to implement all of our ideas to the best of our ability but we are looking to in the future. In order to do this we want to ask permission to extend API keys and possibly purchase if necessary. We have the potential to add more playlist personalization and improving the algorithm we use for this. We would also like to improve the user experience by implementing more and better visual content and interaction.
",,,,"ruby-on-rails, accuweather, spotify, google-maps, python, html/css",Penn State University,"","",austinthoet,Austin,Thoet,austinthoet@gmail.com,Pennsylvania State University,1,IsaacT1123,IsaacT1123,,isaac.thomas1060@gmail.com
Accuweather Challenge,Lluvia,1,https://hackpsu-fall-2018.devpost.com/submissions/102456-lluvia,"Inspiration

Everyday we go through life 

What it does

This application generates playlists for the user based on realtime weather forecast data and the impact that has on moods as well as the user's past listening history through utilization and creation of algorithms.

How we built it

We utilized Ruby on Rails to create our project and built everything around it. We pulled from AccuWeather's APIs including MinuteCast and the 24Hour Hourly Forecast. We also pulled from Spotify's Authentication, Tracks, and Playlists. We also utilized various smaller APIs for features such as IP location etc.

Challenges we ran into

We all learned Ruby which is a language that none of us had any experience with. We also faced challenges with creating a valid and acceptable process in which to go about this within 24 hours. 

Accomplishments that we're proud of

We are proud that we have something to show off at the end of this Hackathon. We are proud of the growth we underwent throughout the sleep deprivation and red bull fueled yelling matches with our computers. We are proud to have come up with an idea and know what tools and methods we need to implement in order to make something that has massive potential and can be widely used. 

What we learned

We learned essential skills in Ruby and web development. We also refined our abilities to make algorithms to decipher needed scenarios through utilizing metrics and coming up with our own through reading research papers and studies.

What's next for Lluvia

Lluvia is just getting started. We did not have a chance to implement all of our ideas to the best of our ability but we are looking to in the future. In order to do this we want to ask permission to extend API keys and possibly purchase if necessary. We have the potential to add more playlist personalization and improving the algorithm we use for this. We would also like to improve the user experience by implementing more and better visual content and interaction.
",,,,"ruby-on-rails, accuweather, spotify, google-maps, python, html/css",Penn State University,"","",austinthoet,Austin,Thoet,austinthoet@gmail.com,Pennsylvania State University,1,IsaacT1123,IsaacT1123,,isaac.thomas1060@gmail.com
Best use of HERE.com,MenuMap,82,https://hackpsu-fall-2018.devpost.com/submissions/102457-menumap,"Inspiration

We were inspired by the lack of convenience when it comes to campus students and the various menu options that change every day. It was our mission to streamline this process in a modern way so students could be better informed through a centralized portal what was on the menu, hence our service name: MenuMap!

What it does

Menu Map is a service that updates on a daily basis, parsing a pre-defined list of campus menu domains in order to provide critical menu information to students in a friendly and modern format. We decided to use HERE's Maps API to geographically illustrate the menu options available to students that change on a daily basis for the dining commons. Based on latitude-longitude coordinates, users are able to view their geographical proximity to dining locations (with room for expansion in the future) and their updated menus for the day. The menu data is parsed through Python's LXML toolkit, which is then written to a text file pushed to an online Git. This text file could then be read by our HTML/JS file, comprising the front-end of our website which was able to then leverage HERE's Bubble UI to display that menu information with geographical significance to the user.

How we built it

The process of our project is explained above, but in short:


HTML was parsed into text, then written into a formatted text file
The text file was read by JS, a different programming language
The text data was sorted and outputted leveraging HERE's MAP API


Challenges we ran into

We found it incredibly difficult to integrate the functionalities of both Python and JavaScript. Initially, we tried using Google Cloud's Storage API to transfer text between languages, but Google doesn't seem to support many important functions that were needed to read text from buckets. In addition, formatting data into a text file with the use of markers proved difficult to encode and decode, versus an implementation with JSON for example.

Accomplishments that we're proud of

We are proud to have competed in our first every hackathons as freshman and are happy with the progress we've made developmentally and as a team.

What we learned

We learned how to host a website on GitHub, a lot about working and creating/outputting HTML to a live web page, as well as web-development.

What's next for MenuMap

We hope to expand this service to more than just Penn State, and are interested in utilizing Algoria's Search API as an alternative to our conventional map.

git-repos: https://github.com/joshua-yan/menumap-redacted
",,http://joshua-yan.github.io,,"python, javascript, here-map, html5, here-geocoder, github, not-domain.com",The Pennsylvania State University,HERE.com,"",SamuelJohnson2022,Samuel,Johnson,samueljohnson2018@gmail.com,Pennsylvania State University,1,joshua-yan,joshua-yan,,joshuayan99@gmail.com
HackPSU Overall - Design,MenuMap,82,https://hackpsu-fall-2018.devpost.com/submissions/102457-menumap,"Inspiration

We were inspired by the lack of convenience when it comes to campus students and the various menu options that change every day. It was our mission to streamline this process in a modern way so students could be better informed through a centralized portal what was on the menu, hence our service name: MenuMap!

What it does

Menu Map is a service that updates on a daily basis, parsing a pre-defined list of campus menu domains in order to provide critical menu information to students in a friendly and modern format. We decided to use HERE's Maps API to geographically illustrate the menu options available to students that change on a daily basis for the dining commons. Based on latitude-longitude coordinates, users are able to view their geographical proximity to dining locations (with room for expansion in the future) and their updated menus for the day. The menu data is parsed through Python's LXML toolkit, which is then written to a text file pushed to an online Git. This text file could then be read by our HTML/JS file, comprising the front-end of our website which was able to then leverage HERE's Bubble UI to display that menu information with geographical significance to the user.

How we built it

The process of our project is explained above, but in short:


HTML was parsed into text, then written into a formatted text file
The text file was read by JS, a different programming language
The text data was sorted and outputted leveraging HERE's MAP API


Challenges we ran into

We found it incredibly difficult to integrate the functionalities of both Python and JavaScript. Initially, we tried using Google Cloud's Storage API to transfer text between languages, but Google doesn't seem to support many important functions that were needed to read text from buckets. In addition, formatting data into a text file with the use of markers proved difficult to encode and decode, versus an implementation with JSON for example.

Accomplishments that we're proud of

We are proud to have competed in our first every hackathons as freshman and are happy with the progress we've made developmentally and as a team.

What we learned

We learned how to host a website on GitHub, a lot about working and creating/outputting HTML to a live web page, as well as web-development.

What's next for MenuMap

We hope to expand this service to more than just Penn State, and are interested in utilizing Algoria's Search API as an alternative to our conventional map.

git-repos: https://github.com/joshua-yan/menumap-redacted
",,http://joshua-yan.github.io,,"python, javascript, here-map, html5, here-geocoder, github, not-domain.com",The Pennsylvania State University,HERE.com,"",SamuelJohnson2022,Samuel,Johnson,samueljohnson2018@gmail.com,Pennsylvania State University,1,joshua-yan,joshua-yan,,joshuayan99@gmail.com
HackPSU Overall - Tech,MenuMap,82,https://hackpsu-fall-2018.devpost.com/submissions/102457-menumap,"Inspiration

We were inspired by the lack of convenience when it comes to campus students and the various menu options that change every day. It was our mission to streamline this process in a modern way so students could be better informed through a centralized portal what was on the menu, hence our service name: MenuMap!

What it does

Menu Map is a service that updates on a daily basis, parsing a pre-defined list of campus menu domains in order to provide critical menu information to students in a friendly and modern format. We decided to use HERE's Maps API to geographically illustrate the menu options available to students that change on a daily basis for the dining commons. Based on latitude-longitude coordinates, users are able to view their geographical proximity to dining locations (with room for expansion in the future) and their updated menus for the day. The menu data is parsed through Python's LXML toolkit, which is then written to a text file pushed to an online Git. This text file could then be read by our HTML/JS file, comprising the front-end of our website which was able to then leverage HERE's Bubble UI to display that menu information with geographical significance to the user.

How we built it

The process of our project is explained above, but in short:


HTML was parsed into text, then written into a formatted text file
The text file was read by JS, a different programming language
The text data was sorted and outputted leveraging HERE's MAP API


Challenges we ran into

We found it incredibly difficult to integrate the functionalities of both Python and JavaScript. Initially, we tried using Google Cloud's Storage API to transfer text between languages, but Google doesn't seem to support many important functions that were needed to read text from buckets. In addition, formatting data into a text file with the use of markers proved difficult to encode and decode, versus an implementation with JSON for example.

Accomplishments that we're proud of

We are proud to have competed in our first every hackathons as freshman and are happy with the progress we've made developmentally and as a team.

What we learned

We learned how to host a website on GitHub, a lot about working and creating/outputting HTML to a live web page, as well as web-development.

What's next for MenuMap

We hope to expand this service to more than just Penn State, and are interested in utilizing Algoria's Search API as an alternative to our conventional map.

git-repos: https://github.com/joshua-yan/menumap-redacted
",,http://joshua-yan.github.io,,"python, javascript, here-map, html5, here-geocoder, github, not-domain.com",The Pennsylvania State University,HERE.com,"",SamuelJohnson2022,Samuel,Johnson,samueljohnson2018@gmail.com,Pennsylvania State University,1,joshua-yan,joshua-yan,,joshuayan99@gmail.com
"",FreeTime,22,https://hackpsu-fall-2018.devpost.com/submissions/102458-freetime,"Inspiration

No matter how busy you are, finding a time to meet that's perfect for everyone's schedules is a really frustrating task in college. We are currently working on a team of six on a pretty involved project, and scheduling meetings and events is _ always _ difficult. Sometimes we just want to know when the most people possible could make it to a meeting, so it isn't always a matter of looking for white space on a Google Calendar.

Trying to find a good time to meet is even harder for short-term class projects, where it doesn't make sense to put everyone's schedule into a calendar. In these situations it takes a ton of back and forth over GroupMe to iron out a good time, which often involves waiting a few hours for that last person to respond.

Aside from group projects, we also thought it would be convenient to be able to check a friend's schedule and see when they're free. Right now we send a screenshot of our schedules and then have to dig through messages to find the image just to see when our friends have class. 

What it does

FreeTime allows users to search for their friends who are signed up on the app and then select a group from their friends list to compare schedules. The comparing feature displays a calendar color coded based on how many people in the group are free at each time interval. The app also allows users to view any of their friends' schedules as well to quickly check if they're free. 

How we built it

We used React Native for the front end, Node JS in the back end with Redux in the front end to manage state. We had 2 servers, one for managing our users in a mongoose database and 1 for parsing incoming emails and making a request to the other server to update the database.

Challenges we ran into

Having never made a React Native app before, we ran into issues just getting started with that. We also hit bumps with not getting wifi, and actually had to go to another building for most of the hack, but we persevered.

Accomplishments that we're proud of

We're proud of how much we were able to accomplish with just two people. We were thinking we'd have to compromise one of the larger elements of the app for time's sake, but it looks like we're actually going to get done what we wanted to.

What we learned

Neither of us has worked on a React Native app before, so needless to say, we learned a ton from this project. Both of us expanded our skillsets, and that was our main goal!

What's next for FreeTime

We've been wanting to build this app for a really long time, because we know how useful it would be to us, so we'd like to keep developing it and get it to a place where we can use it. If all goes well, we'd love to bring it to all Penn State students.
",,,,"react-native, redux, jsx, expo.io",Penn State UP,"","",ChristinaWarren,Christina,Warren,cewarren801@gmail.com,Pennsylvania State University,1,matthewrmancini,Matt,Mancini,matthewrmancini@gmail.com
HackPSU Overall - Tech,Smart Class Alarm Clock,11,https://hackpsu-fall-2018.devpost.com/submissions/102459-smart-class-alarm-clock,"Inspiration

I miss class because sometimes I don't know when to leave.

What it does

Tells you when to go to class including walking time.

How we built it

We used Python and starter code provided by Amazon

Challenges we ran into

Syntax and generally using AWS for the first time

Accomplishments that we're proud of

Actually built my first project that worked

What we learned

How to use AWS and the powers it has

What's next for Smart Class Alarm Clock

Actually create an alarm and not just have Alexa say that she did
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36347/zip_files/Archive.zip,"amazon-alexa, python",Penn State University,"","",MLGPong,Aaron,Zhou,dexterbloons@yahoo.com,Pennsylvania State University,2,ivanhacks,,,ivv5032@psu.edu,Abheerjasuja,,,abheerjasuja@gmail.com
"",RideSafe,78,https://hackpsu-fall-2018.devpost.com/submissions/102460-ridesafe,"Inspiration

Coming from India, we've seen a lot of new and elderly drivers struggle due to underdeveloped infrastructure and wanted to alleviate the negative effects of potholes and poorly marked speedbumps.

What it does

This project alerts drivers via their phones when the system detects any anomalies in the road's surface. Certain parameters set in the code help differentiate between potholes and speedbumps after calculating the relative distance of the sensor from the road.

How we built it

The project is powered by two arduino boards, each controlling an ultrasonic sensor of their own. The outputs from both boards are taken into account to distinguish the type of anomaly in the road. The built in bluetooth chip in the arduino is used to connect to the driver's phone. The data is recorded in a database that we hope can help make a better street map once more data is aggregated.

Challenges we ran into

Establishing a connection between the bluetooth transmitter and iOS using Swift's Core Bluetooth library proved to be challenging, as it involved prior knowledge on peripheral characteristic values.

Accomplishments that we're proud of

Seamlessly integrating data output from the arduino and the cloud using Google Firebase proved to be very advantageous for us. Also, the chance to improve driver safety at a very low cost in developing countries was a huge driving force.

What we learned

Bluetooth Low Energy, Ultrasonics were some of the interesting concepts involved in making this project.
",,https://github.com/dhruvk6498/RideSafe,,"arduino, swift, xcode, firebase, mapkit, hardware, sonar",Penn State University,Google Cloud Platform,"",Dhruvk,,,dhruvkakran98@gmail.com,Pennsylvania State University,1,karthikjain999,Karthik,Jain,karthikjain999@gmail.com
"",VADER,72,https://hackpsu-fall-2018.devpost.com/submissions/102461-vader,"Inspiration

The recent floods in North Carolina, needless lives were lost due to the disaster and this could have been avoided with a better connective system. 

What it does

VADER uses the Accuweather API to pull weather data about the current location or any given location. It detects a 15-day forecast and will show up with a result with a possibility index of a disaster happening. From there, the user can create a volunteering effort if they desire or join an existing one if it exists. We used the Here.com API to generate a map with the city that the user looks up. We also used Authorize.net to make a donate function so users can also donate to a volunteering effort.

How I built it

We used Vue.js to build the web interface along with HTML and CSS. We used the Accuweather API to get weather data and display weather alerts and possible natural disasters.

Challenges I ran into

Challenges we ran into were reading all the API documentation. At some point, the API documentation for Authorize.net was very lengthy and hard to read. Another challenge is waiting for verification from Google Cloud Hosting to verify ownership of the domain. We are currently waiting on this then we can host it on Google Cloud platform using domain.com.

Accomplishments that I'm proud of

Accomplishments we're proud of is leveraging the Accuweather API to do some social good. The end product gets weather alerts puts them through a natural disaster analyzer and displays it onto a user-friendly web interface.

What I learned

I learned about the complexity that can be involved using multiple API's and combining them all into one fluid application. I also learned more about Vue.js in this process that I was not aware of earlier. 

What's next for VADER

We would like to make a mobile app next for Vader so it is easier for users to get connected on the go. Currently, we are generating a slack URL for the users to get connected and this way, through slack they can keep connected on the go. In the future, we can keep all this functionality in one app so it is more convenient for users to get in touch.
",,https://github.com/javacoldbrew/vader-hack-psu-fall-2018,,"vue, node.js, html5, css3, bootstrap, accuweather, here.com, authorize.net",Penn State Harrisburg,"","",ronak1997,,,rvp5281@psu.edu,Pennsylvania State University,3,javacoldbrew,Amish,Prajapati,swegmaster.psu@gmail.com,JohnGilbertson,John,Gilbertson,johnagilb@gmail.com,kbp5167,kbp5167,,kbp5167@psu.edu
Capital One - Best Financial Hack,Klique,44,https://hackpsu-fall-2018.devpost.com/submissions/102462-klique,"Inspiration

We wanted to combine the financial incentive to running, popularized by SweatCoin, with a local social atmosphere. For this we looked to communities from apps like Pokemon Go, and HQ Trivia.

What it does

""Runs"" are geolocation-based events that are time sensitive. These can show up randomly, or be sponsored (in our example we used Nike, also Penn State could sponsor runs for charity, etc).

The app tracks GPS data of users and tracks the total mileage of users within a ""run radii"" of the run. If the total distance covered by the community reaches the goal, all participants earn money based on their contribution and the ""bounty"" if they achieve the minimum run milestone.

Once the app is completed, an AI could calculate ideal run radii and bounty based off of population density and place them at correct locations. Payout could be done through Capital One.

How we built it

We built the GUI using Google's Flutter framework, which is currently in alpha. We also used Android Studio for our development tools, and Mapbox GL to provide maps for our applications.

In the future, we hope to incorporate more technologies like Firebase, Google Fit, Fitbit APIs, etc.

Challenges we ran into


Lack of knowledge of Flutter and lack of a good mapping solution for Flutter (since it's in alpha).
Team members being inexperienced or new to programming. 
Lack of time v. ambition of idea.


Accomplishments that we're proud of


A well thought out and implemented user interface.


What we learned


Better understanding of Flutter, introduced some team members to Dart language.


What's next for Klique

Eventually Klique will need a backend, which we want to do with Firebase Cloud Functions and Firestore. We also need to integrate with fitness APIs such as Google Fit and Fitbit, as well as HealthKit once we get running on iOS.

If Klique gets enough users in the future, we could have potential sponsorship from athletic companies for runs, as well as charity groups and social activism groups. These larger ""events"" would have higher payouts for participants and display the sponsor's branding throughout the app.
",,https://github.com/mbullington/CrowdRunning,,"java, flutter, dart",Penn State Behrend and University Park,"","",CQubed15,Cameron,Coursey,courseycameron15@gmail.com,Pennsylvania State University,4,mbullington,Michael,Bullington,mikebullingtn@gmail.com,kjpikapika,Jacob,Smith,kjpikapika@gmail.com,Adamsabo,Adam,Sabatose,asabatose@gmail.com,marcusputz058,Marcus,Putz,marcusputz058@gmail.com
"",LLPro,48,https://hackpsu-fall-2018.devpost.com/submissions/102463-llpro,"Inspiration

As an individual who has a passion for learning different languages and understanding the essence of establishing neurological pathways in learning a language, have decided to create a program that will allow for direct links in the language.

What it does

The program will ask the individual to select a setting. Then based on the setting that the user is in (i.e classroom) then the program will display a word of an object in a foreign language (Target language that the user is trying to learn), then a sound file will play with the pronunciation of the word will play. The user will then be asked to actively seek the object and take a photo of it. If the photo matches then the program will proceed to another word. 

How we built it

Using two google-cloud APIs.  The first was the google-cloud-vision API that was used to label the objects within a picture and see if it corresponds with the word (object) that was displayed prior. Then the second API that was used is the google-cloud-text-to-speech  that will take the word in the foreign language and output the sound file with the pronunciation. 

Challenges we ran into


Using and implementing both the APIs.
Using the camera in conjunction with the API and programming environment.
Implementing the GUI for the program


Accomplishments that we're proud of


Implementation of both APIs.
Implementing the camera function that will take a photo and send it through the google cloud service to identify and label the image.


What we learned


The use and execution of google's API for it's cloud service. 
GUIs are confusing to work with.


What's next for LLPro


Version 2.0 Coming up soon.

",,,https://s3.amazonaws.com/challengepost/zip_files/production/36349/zip_files/LLPro.zip,python,PSU,"","",williamkucds,William,Ku,williamkucds@gmail.com,Pennsylvania State University,3,ahmedabdou73,,,aaa6237@psu.edu,Ammuri,,,oma5128@psu.edu,ihm5020,Imran,Mohd Raji,ihm5020@psu.edu
Accuweather Challenge,Weather EMOJI,6,https://hackpsu-fall-2018.devpost.com/submissions/102464-weather-emoji,"Inspiration

we want to have people seeing the temperature with attitudes which would be expressed by emojis.

What it does

Check the weather you are currently at with an emoji telling you how this weather feels like rather than only a number.
This would be super helpful for people that are not sensitive about temperature numbers like me!

How we built it

By using Node.js, ExpressJs, I leveraged the AccuWeather API, and 

Challenges we ran into

Everything went so smoothly.

Accomplishments that we're proud of

We had fun

What we learned

Emojis are great!
People need more direct information than just a number!

What's next for Weather EMOJI

Using Machining learning to train the emoji model, to adjust every user's feeling about different temperatures, so that people can have a better expression when they render the temperature page
",,https://github.com/aphyuan/Weather_emoji,,"accuweather, node.js, express.js, ejs, javascript, git, github, api, npm",Penn State University,"","",aphyuan,Houyuan,Pan,panhouyuanjustforfun@gmail.com,Pennsylvania State University,1,yjw5141,Yiyi,Wang,yjw5141@psu.edu
HackPSU Overall - Design,Weather EMOJI,6,https://hackpsu-fall-2018.devpost.com/submissions/102464-weather-emoji,"Inspiration

we want to have people seeing the temperature with attitudes which would be expressed by emojis.

What it does

Check the weather you are currently at with an emoji telling you how this weather feels like rather than only a number.
This would be super helpful for people that are not sensitive about temperature numbers like me!

How we built it

By using Node.js, ExpressJs, I leveraged the AccuWeather API, and 

Challenges we ran into

Everything went so smoothly.

Accomplishments that we're proud of

We had fun

What we learned

Emojis are great!
People need more direct information than just a number!

What's next for Weather EMOJI

Using Machining learning to train the emoji model, to adjust every user's feeling about different temperatures, so that people can have a better expression when they render the temperature page
",,https://github.com/aphyuan/Weather_emoji,,"accuweather, node.js, express.js, ejs, javascript, git, github, api, npm",Penn State University,"","",aphyuan,Houyuan,Pan,panhouyuanjustforfun@gmail.com,Pennsylvania State University,1,yjw5141,Yiyi,Wang,yjw5141@psu.edu
HackPSU Overall - Tech,Weather EMOJI,6,https://hackpsu-fall-2018.devpost.com/submissions/102464-weather-emoji,"Inspiration

we want to have people seeing the temperature with attitudes which would be expressed by emojis.

What it does

Check the weather you are currently at with an emoji telling you how this weather feels like rather than only a number.
This would be super helpful for people that are not sensitive about temperature numbers like me!

How we built it

By using Node.js, ExpressJs, I leveraged the AccuWeather API, and 

Challenges we ran into

Everything went so smoothly.

Accomplishments that we're proud of

We had fun

What we learned

Emojis are great!
People need more direct information than just a number!

What's next for Weather EMOJI

Using Machining learning to train the emoji model, to adjust every user's feeling about different temperatures, so that people can have a better expression when they render the temperature page
",,https://github.com/aphyuan/Weather_emoji,,"accuweather, node.js, express.js, ejs, javascript, git, github, api, npm",Penn State University,"","",aphyuan,Houyuan,Pan,panhouyuanjustforfun@gmail.com,Pennsylvania State University,1,yjw5141,Yiyi,Wang,yjw5141@psu.edu
JPMC - Best Social Good Hack,Weather EMOJI,6,https://hackpsu-fall-2018.devpost.com/submissions/102464-weather-emoji,"Inspiration

we want to have people seeing the temperature with attitudes which would be expressed by emojis.

What it does

Check the weather you are currently at with an emoji telling you how this weather feels like rather than only a number.
This would be super helpful for people that are not sensitive about temperature numbers like me!

How we built it

By using Node.js, ExpressJs, I leveraged the AccuWeather API, and 

Challenges we ran into

Everything went so smoothly.

Accomplishments that we're proud of

We had fun

What we learned

Emojis are great!
People need more direct information than just a number!

What's next for Weather EMOJI

Using Machining learning to train the emoji model, to adjust every user's feeling about different temperatures, so that people can have a better expression when they render the temperature page
",,https://github.com/aphyuan/Weather_emoji,,"accuweather, node.js, express.js, ejs, javascript, git, github, api, npm",Penn State University,"","",aphyuan,Houyuan,Pan,panhouyuanjustforfun@gmail.com,Pennsylvania State University,1,yjw5141,Yiyi,Wang,yjw5141@psu.edu
HackPSU Overall - Tech,Drawing plate,60,https://hackpsu-fall-2018.devpost.com/submissions/102465-drawing-plate,"Inspiration

Because we have some reports which need to be attached with some simple picture, we create a new and simple application to complete it.

What it does

Drawing simple figures.

How we built it

Java eclipse

Challenges we ran into

The use of  two check boxes : dash and filled 

Accomplishments that we're proud of

We added some good features to this project to enable the user draw the gradient-colored lines  and so on...

What we learned

We learned how to  used GUI

What's next for Drawing Plate

And some  more features into it to make it more convenient to manipulate.
",,https://github.com/sdfqb/project,https://s3.amazonaws.com/challengepost/zip_files/production/36353/zip_files/Drawing.java,java,psu,"","",sdfqb009,difei,sun,sdfqb009@gmail.com,Pennsylvania State University,3,jfc5455,jingxuan,cao,jfc5455@psu.edu,xxw26,Xiaoxi,Wang,xxw26@psu.edu,ykc5105,yuexuan,cheng,ykc5105@psu.edu
Booz Allen Hamilton - Best Machine Learning Hack,UniInsights,47,https://hackpsu-fall-2018.devpost.com/submissions/102466-uniinsights,"Inspiration

I'm interested in knowing what personalities are valued by top universities, and I always want to give college applicants in the US more certainty because when I was applying for college, the college essay part made me frustrated.

What it does

There are main features of the app:


Analyze personalities expressed in your college essay and check if it is matched with the common personalities expressed in essays accepted to certain university.
Analyze personalities expressed in your twitter account and check if it is matched with the common personalities expressed in twitter account of students who are accepted to certain university.
Analyze what type of personalities and values a certain university looking for based on its accepted students' twitter and essay.


How we built it

We built it as an Flask application that use IBM Personality Insights for personality analysis and Twitter API for extracting tweets from certain user.

Challenges we ran into

We tried to format our results, but it doesn't work out as well as we expected to.

Accomplishments that we're proud of

We're proud of figuring out the UI design using Bootstrap.

What we learned

We learned Bootstrap, and how to intergrate UI with the algorithms themselves.

What's next for UniInsights

Adding more college options next time.
",,https://github.com/VietHTranTraining/uni-insights,https://s3.amazonaws.com/challengepost/zip_files/production/36352/zip_files/uni-insights.zip,"flask, twitter, html, python, bootstrap, css",Penn State University,"","",VietHTran,Viet Hung,Tran,trantechenterprise@gmail.com,Pennsylvania State University,1,yinluhanyang,Luhan,Yang,yinluhanyang@gmail.com
Nittany AI Alliance - AI Challenge,UniInsights,47,https://hackpsu-fall-2018.devpost.com/submissions/102466-uniinsights,"Inspiration

I'm interested in knowing what personalities are valued by top universities, and I always want to give college applicants in the US more certainty because when I was applying for college, the college essay part made me frustrated.

What it does

There are main features of the app:


Analyze personalities expressed in your college essay and check if it is matched with the common personalities expressed in essays accepted to certain university.
Analyze personalities expressed in your twitter account and check if it is matched with the common personalities expressed in twitter account of students who are accepted to certain university.
Analyze what type of personalities and values a certain university looking for based on its accepted students' twitter and essay.


How we built it

We built it as an Flask application that use IBM Personality Insights for personality analysis and Twitter API for extracting tweets from certain user.

Challenges we ran into

We tried to format our results, but it doesn't work out as well as we expected to.

Accomplishments that we're proud of

We're proud of figuring out the UI design using Bootstrap.

What we learned

We learned Bootstrap, and how to intergrate UI with the algorithms themselves.

What's next for UniInsights

Adding more college options next time.
",,https://github.com/VietHTranTraining/uni-insights,https://s3.amazonaws.com/challengepost/zip_files/production/36352/zip_files/uni-insights.zip,"flask, twitter, html, python, bootstrap, css",Penn State University,"","",VietHTran,Viet Hung,Tran,trantechenterprise@gmail.com,Pennsylvania State University,1,yinluhanyang,Luhan,Yang,yinluhanyang@gmail.com
HackPSU Overall - Tech,UniInsights,47,https://hackpsu-fall-2018.devpost.com/submissions/102466-uniinsights,"Inspiration

I'm interested in knowing what personalities are valued by top universities, and I always want to give college applicants in the US more certainty because when I was applying for college, the college essay part made me frustrated.

What it does

There are main features of the app:


Analyze personalities expressed in your college essay and check if it is matched with the common personalities expressed in essays accepted to certain university.
Analyze personalities expressed in your twitter account and check if it is matched with the common personalities expressed in twitter account of students who are accepted to certain university.
Analyze what type of personalities and values a certain university looking for based on its accepted students' twitter and essay.


How we built it

We built it as an Flask application that use IBM Personality Insights for personality analysis and Twitter API for extracting tweets from certain user.

Challenges we ran into

We tried to format our results, but it doesn't work out as well as we expected to.

Accomplishments that we're proud of

We're proud of figuring out the UI design using Bootstrap.

What we learned

We learned Bootstrap, and how to intergrate UI with the algorithms themselves.

What's next for UniInsights

Adding more college options next time.
",,https://github.com/VietHTranTraining/uni-insights,https://s3.amazonaws.com/challengepost/zip_files/production/36352/zip_files/uni-insights.zip,"flask, twitter, html, python, bootstrap, css",Penn State University,"","",VietHTran,Viet Hung,Tran,trantechenterprise@gmail.com,Pennsylvania State University,1,yinluhanyang,Luhan,Yang,yinluhanyang@gmail.com
Accuweather Challenge,ShelterMeNow,30,https://hackpsu-fall-2018.devpost.com/submissions/102467-sheltermenow,"Inspiration

During natural disasters, it's hard to find information pertaining to the situation. You need shelter, food, resources, medical help, places to avoid and directions. But getting this information isn't easy, news channels only tell you to visit their website and find the labyrinth of links and ads to find something. Our site is different.

What it does

The website uses your current location and displays the immediate forecast in your area. If it's severe, you'll immediately be notified with an alert banner to seek shelter. The FindAShelter page shows you all the shelters around you with the distance, name, address, and contact information. The site also shows you other pertinent information such as amenities available at a specific shelter including food, water, clothes, medical care and more. It also shows you an overlay of the accuweather radar on the map to show you where some roads may be inaccessible due to the disaster based on possible flood levels. The site also provides tips you can use to further prepare in the event of any other disasters.

How we built it

For the frontend, we uses Bootstrap to provide a clean user interface that scales with any devices, whether if it is a desktop, tablet, or phone. The frontend calls the accuweather api to provide immediate information and it is displayed using a combination of javascript and jquery. The backend of the site uses Google Cloud Platforms. PHP is used to retrieve information of shelters in the area and google maps api is used to populate the map view with the shelters.

Challenges we ran into

Being able to store and use the queried data and updating it. Error handling. Map overlay + radar.

Accomplishments that we're proud of

What we learned

What's next for ShelterMeNow
",,http://www.sheltermenow.com,,"html5, css3, javascript, jquery, bootstrap, php, mysql, google-maps, accuweather","Queens College, PennStateUniversity","Domain.com,Google Cloud Platform","",Amzad,Amzad,Chowdhury,amzad@amzadchowdhury.com,"Queens College of the City University of New York, Pennsylvania State University",1,picode98,picode98,,saaman1377@gmail.com
Best use of Google Cloud Platform,ShelterMeNow,30,https://hackpsu-fall-2018.devpost.com/submissions/102467-sheltermenow,"Inspiration

During natural disasters, it's hard to find information pertaining to the situation. You need shelter, food, resources, medical help, places to avoid and directions. But getting this information isn't easy, news channels only tell you to visit their website and find the labyrinth of links and ads to find something. Our site is different.

What it does

The website uses your current location and displays the immediate forecast in your area. If it's severe, you'll immediately be notified with an alert banner to seek shelter. The FindAShelter page shows you all the shelters around you with the distance, name, address, and contact information. The site also shows you other pertinent information such as amenities available at a specific shelter including food, water, clothes, medical care and more. It also shows you an overlay of the accuweather radar on the map to show you where some roads may be inaccessible due to the disaster based on possible flood levels. The site also provides tips you can use to further prepare in the event of any other disasters.

How we built it

For the frontend, we uses Bootstrap to provide a clean user interface that scales with any devices, whether if it is a desktop, tablet, or phone. The frontend calls the accuweather api to provide immediate information and it is displayed using a combination of javascript and jquery. The backend of the site uses Google Cloud Platforms. PHP is used to retrieve information of shelters in the area and google maps api is used to populate the map view with the shelters.

Challenges we ran into

Being able to store and use the queried data and updating it. Error handling. Map overlay + radar.

Accomplishments that we're proud of

What we learned

What's next for ShelterMeNow
",,http://www.sheltermenow.com,,"html5, css3, javascript, jquery, bootstrap, php, mysql, google-maps, accuweather","Queens College, PennStateUniversity","Domain.com,Google Cloud Platform","",Amzad,Amzad,Chowdhury,amzad@amzadchowdhury.com,"Queens College of the City University of New York, Pennsylvania State University",1,picode98,picode98,,saaman1377@gmail.com
HackPSU Overall - Tech,ShelterMeNow,30,https://hackpsu-fall-2018.devpost.com/submissions/102467-sheltermenow,"Inspiration

During natural disasters, it's hard to find information pertaining to the situation. You need shelter, food, resources, medical help, places to avoid and directions. But getting this information isn't easy, news channels only tell you to visit their website and find the labyrinth of links and ads to find something. Our site is different.

What it does

The website uses your current location and displays the immediate forecast in your area. If it's severe, you'll immediately be notified with an alert banner to seek shelter. The FindAShelter page shows you all the shelters around you with the distance, name, address, and contact information. The site also shows you other pertinent information such as amenities available at a specific shelter including food, water, clothes, medical care and more. It also shows you an overlay of the accuweather radar on the map to show you where some roads may be inaccessible due to the disaster based on possible flood levels. The site also provides tips you can use to further prepare in the event of any other disasters.

How we built it

For the frontend, we uses Bootstrap to provide a clean user interface that scales with any devices, whether if it is a desktop, tablet, or phone. The frontend calls the accuweather api to provide immediate information and it is displayed using a combination of javascript and jquery. The backend of the site uses Google Cloud Platforms. PHP is used to retrieve information of shelters in the area and google maps api is used to populate the map view with the shelters.

Challenges we ran into

Being able to store and use the queried data and updating it. Error handling. Map overlay + radar.

Accomplishments that we're proud of

What we learned

What's next for ShelterMeNow
",,http://www.sheltermenow.com,,"html5, css3, javascript, jquery, bootstrap, php, mysql, google-maps, accuweather","Queens College, PennStateUniversity","Domain.com,Google Cloud Platform","",Amzad,Amzad,Chowdhury,amzad@amzadchowdhury.com,"Queens College of the City University of New York, Pennsylvania State University",1,picode98,picode98,,saaman1377@gmail.com
HackPSU Overall - Design,"Beep_Boop, your personal robot pal",16,https://hackpsu-fall-2018.devpost.com/submissions/102468-beep_boop-your-personal-robot-pal,"Inspiration

I know of many people who often feel depressed, and they just want someone to talk to. I wanted to make an assistant to help provide just something to make you talk, just to get your feelings out.

What it does

It Tries to get you to talk in depth about your feelings, until you start to realize why you feel the way that you do, and can help you feel better. It also tries to match your emotions to act more sympathetic.

How we built it

We used a raspberry pi and connected it to the google assistant api, as well as the cloud speech and dialogflow api's.
The case was 3d printed and servos were mounted to simulate expression

Challenges we ran into

The program came out more sarcastic at first, making you feel worse than when you started. Also starting up the device still requires a monitor.

Accomplishments that we're proud of

The case looks adorable, and we sucseefully connected it to the cloud speech API.

What we learned

Hardware hacking takes a ton of time just for the modeling and construction. 

What's next for Beep_Boop, your personal robot pal

Adding mobility so he can move and follow you around like a pet.
",,,,"google-cloud, dialogflow, raspberry-pi",Penn State,Google Cloud Platform,"",Timerush,William,Schopf,syfyguybilly@gmail.com,Pennsylvania State University,1,tim5336,Tim,Maga,tim5336@psu.edu
Best use of Google Cloud Platform,"Beep_Boop, your personal robot pal",16,https://hackpsu-fall-2018.devpost.com/submissions/102468-beep_boop-your-personal-robot-pal,"Inspiration

I know of many people who often feel depressed, and they just want someone to talk to. I wanted to make an assistant to help provide just something to make you talk, just to get your feelings out.

What it does

It Tries to get you to talk in depth about your feelings, until you start to realize why you feel the way that you do, and can help you feel better. It also tries to match your emotions to act more sympathetic.

How we built it

We used a raspberry pi and connected it to the google assistant api, as well as the cloud speech and dialogflow api's.
The case was 3d printed and servos were mounted to simulate expression

Challenges we ran into

The program came out more sarcastic at first, making you feel worse than when you started. Also starting up the device still requires a monitor.

Accomplishments that we're proud of

The case looks adorable, and we sucseefully connected it to the cloud speech API.

What we learned

Hardware hacking takes a ton of time just for the modeling and construction. 

What's next for Beep_Boop, your personal robot pal

Adding mobility so he can move and follow you around like a pet.
",,,,"google-cloud, dialogflow, raspberry-pi",Penn State,Google Cloud Platform,"",Timerush,William,Schopf,syfyguybilly@gmail.com,Pennsylvania State University,1,tim5336,Tim,Maga,tim5336@psu.edu
HackPSU Overall - Tech,"Beep_Boop, your personal robot pal",16,https://hackpsu-fall-2018.devpost.com/submissions/102468-beep_boop-your-personal-robot-pal,"Inspiration

I know of many people who often feel depressed, and they just want someone to talk to. I wanted to make an assistant to help provide just something to make you talk, just to get your feelings out.

What it does

It Tries to get you to talk in depth about your feelings, until you start to realize why you feel the way that you do, and can help you feel better. It also tries to match your emotions to act more sympathetic.

How we built it

We used a raspberry pi and connected it to the google assistant api, as well as the cloud speech and dialogflow api's.
The case was 3d printed and servos were mounted to simulate expression

Challenges we ran into

The program came out more sarcastic at first, making you feel worse than when you started. Also starting up the device still requires a monitor.

Accomplishments that we're proud of

The case looks adorable, and we sucseefully connected it to the cloud speech API.

What we learned

Hardware hacking takes a ton of time just for the modeling and construction. 

What's next for Beep_Boop, your personal robot pal

Adding mobility so he can move and follow you around like a pet.
",,,,"google-cloud, dialogflow, raspberry-pi",Penn State,Google Cloud Platform,"",Timerush,William,Schopf,syfyguybilly@gmail.com,Pennsylvania State University,1,tim5336,Tim,Maga,tim5336@psu.edu
GM - Autonomous RC Car Challenge,Automatic steering remote control car,4,https://hackpsu-fall-2018.devpost.com/submissions/102469-automatic-steering-remote-control-car,"Inspiration

when the sponsor demo the speed of the car, it hit the wall, and it contains SR05 to test distance. 

What it does

Use SR05 to test the distance with obstacle and determine the direction of the car 

How I built it

Using arduino and the sample code provide by the sponsor

Challenges I ran into

Never write codes for hardware before. My knowledge background is not enough to solve this problem.

What I learned

Some concepts about hardware and how many things i still need to learn. 

What's next for Automatic steering remote control car

I wish i can add a camera on it and use gesture to control the car
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36359/zip_files/sketch_oct6a_copy.zip,arduino,Pennstate,"","",fxc5119,,,fxc5119@psu.edu,Pennsylvania State University,0
Booz Allen Hamilton - Best Machine Learning Hack,LionAdvisor,76,https://hackpsu-fall-2018.devpost.com/submissions/102470-lionadvisor,"Inspiration

We were looking for a specific striking problem which is very crucial for the students and the administration of Penn State. We brainstormed ideas, looking into complications we as Penn State students faced. Academic Advising stood out to us as a recurring problem faced by not just us but a majority of our peers. Waiting in a queue for over an hour, not being able to acquire advising at our convince, scheduling an appointment according to our class schedule has always been a hassle. The advisors as well receive very similar questions or questions that are futile from the students which can get very repetitive and tiring for the advisor. We also looked into the availability of academic advisors in the Commonwealth and world campuses and discovered some commonwealth campuses having just one or two advisors per campus. We found that as a recurring problem too and made our tool accessible to them as well.

What it does

Our product is an online academic advising tool which is centered around HCI and UI. This interface takes advising to the next level by being available to students at any point of the day. As of now, our MVP is capable of answering basic questions that a student might encounter and may need answers for immediately. The regression algorithm in the backend of our tool employs machine learning to identify stress patterns in the language mechanism of a student’s response.  Our ultimate goal is for the chat tool’s algorithm to populate the response directory using live human interactions between students and advisors to generate responses to any query that a student might run into. 

How we built it

Using AWS Lex and AWS Lambda we developed our basic chatbot and further employed Amazon Comprehend to understand language pattern developed in the AWS platform. In creating the basic framework for our bot, we created different intents to figure out different situations that a bot might come across when a student sends in a query. For example, we created an intent for different sectors in advising such as GPA requirement, Graduation, etc. Once we perfected the different intents that we wanted our tool to implement, we came up with different utterances, i.e., different ways the student might ask the same questions to show the variability of sentence formation. For the MVP as of today, we listed out the most suitable answers providing hyperlinks to various external resources. 
To extend this idea, we included a regression model, by creating emotion intents that track the text that the tool receives from the student to judge his or her emotional quotient. For example, we created an intent called ‘Happiness’, and then created utterances below it such as “This was very helpful.”. Words like ‘helpful’ depict happiness and a positive response. To add on to the user interface of this feature, the bot asks for a percentile rating of their experience. 

Challenges we ran into

1)  It took a great deal of brainstorming to find a focus on our overall idea towards making advising more accessible to students and at the same time to save the time and effort of Penn State administrative staff. 
2)  We laid out a bunch of cloud platforms options available to us, such as Google Cloud Platform, Amazon Web Services and various other online software. We went ahead with AWS as it was the only platform that allowed us to format and create bots.’
3)  Developing the HCI component of the chatbot and making it more human-like took us a great deal of time as this was our first time working with the platform and also since we had to figure out various emotions of a student.
4)  Being able to address different aspects of each question by writing out each of the question in different utterances (writing various questions that mean the same thing).
5)  Developing different indents such as GPA requirements, graduation, etc, took us a while to figure out.

Accomplishments that we're proud of

We self-learned our way through AWS although it took some time it was fruitful at the end. Our first prototype met expectations and we can picture the near future of LionAdvisor and the possibilities it can achieve with some external additions to our current bot. 

What we learned

This was our first opportunity participating in a full-fledged hackathon. We learned how to identify a real-world problem equipped with a perfect solution according to us. Being able to use our analytical and logical skills in a short duration without cracking under pressure is something that we have accomplished. A totally new concept of chatbots which none of us had experience within the past. We got the opportunity to get acquainted with Amazon Web Services (AWS), specifically Amazon Lexa. We intend to use the same tool for further advancements for this bot as well. 

Next steps for LionAdvisor

We would like embed more emotions within the answers for our chatbot(
 i.e improves HCI) 


We also want to develop an Amazon Lamda function in order to show escalation and sensitivity within UX
As said before, improving HCI would be one of the biggest goals
We plan on getting a live Penn state advisor to look at the machine and check if it is doing the right thing.
Another big thing, is we want to implement a side by side platform learning experience for the actual Penn state advisor, so every move is then checkmarked by a live advisor to check the accuracy or the closest it is to understand students. It would also plan and stop on 99%accuracy. 

",,https://drive.google.com/file/d/1N7R0JSuDs5BOgOIKceI8Q6p0SDJwhxWq/view?usp=sharing,,"amazon-web-services, bot, machine-learning, ai",Penn State,"","",mkd5443,Medha,Deeptimahanti,mkd5443@psu.edu,Pennsylvania State University,3,ebk5145,Eesh,Kamrah,ebk5145@psu.edu,axs6453,Anmolika,Singh,axs6453@psu.edu,saahithi2700,Saahithi,Mallarapu,saahithi2700@gmail.com
Nittany AI Alliance - AI Challenge,LionAdvisor,76,https://hackpsu-fall-2018.devpost.com/submissions/102470-lionadvisor,"Inspiration

We were looking for a specific striking problem which is very crucial for the students and the administration of Penn State. We brainstormed ideas, looking into complications we as Penn State students faced. Academic Advising stood out to us as a recurring problem faced by not just us but a majority of our peers. Waiting in a queue for over an hour, not being able to acquire advising at our convince, scheduling an appointment according to our class schedule has always been a hassle. The advisors as well receive very similar questions or questions that are futile from the students which can get very repetitive and tiring for the advisor. We also looked into the availability of academic advisors in the Commonwealth and world campuses and discovered some commonwealth campuses having just one or two advisors per campus. We found that as a recurring problem too and made our tool accessible to them as well.

What it does

Our product is an online academic advising tool which is centered around HCI and UI. This interface takes advising to the next level by being available to students at any point of the day. As of now, our MVP is capable of answering basic questions that a student might encounter and may need answers for immediately. The regression algorithm in the backend of our tool employs machine learning to identify stress patterns in the language mechanism of a student’s response.  Our ultimate goal is for the chat tool’s algorithm to populate the response directory using live human interactions between students and advisors to generate responses to any query that a student might run into. 

How we built it

Using AWS Lex and AWS Lambda we developed our basic chatbot and further employed Amazon Comprehend to understand language pattern developed in the AWS platform. In creating the basic framework for our bot, we created different intents to figure out different situations that a bot might come across when a student sends in a query. For example, we created an intent for different sectors in advising such as GPA requirement, Graduation, etc. Once we perfected the different intents that we wanted our tool to implement, we came up with different utterances, i.e., different ways the student might ask the same questions to show the variability of sentence formation. For the MVP as of today, we listed out the most suitable answers providing hyperlinks to various external resources. 
To extend this idea, we included a regression model, by creating emotion intents that track the text that the tool receives from the student to judge his or her emotional quotient. For example, we created an intent called ‘Happiness’, and then created utterances below it such as “This was very helpful.”. Words like ‘helpful’ depict happiness and a positive response. To add on to the user interface of this feature, the bot asks for a percentile rating of their experience. 

Challenges we ran into

1)  It took a great deal of brainstorming to find a focus on our overall idea towards making advising more accessible to students and at the same time to save the time and effort of Penn State administrative staff. 
2)  We laid out a bunch of cloud platforms options available to us, such as Google Cloud Platform, Amazon Web Services and various other online software. We went ahead with AWS as it was the only platform that allowed us to format and create bots.’
3)  Developing the HCI component of the chatbot and making it more human-like took us a great deal of time as this was our first time working with the platform and also since we had to figure out various emotions of a student.
4)  Being able to address different aspects of each question by writing out each of the question in different utterances (writing various questions that mean the same thing).
5)  Developing different indents such as GPA requirements, graduation, etc, took us a while to figure out.

Accomplishments that we're proud of

We self-learned our way through AWS although it took some time it was fruitful at the end. Our first prototype met expectations and we can picture the near future of LionAdvisor and the possibilities it can achieve with some external additions to our current bot. 

What we learned

This was our first opportunity participating in a full-fledged hackathon. We learned how to identify a real-world problem equipped with a perfect solution according to us. Being able to use our analytical and logical skills in a short duration without cracking under pressure is something that we have accomplished. A totally new concept of chatbots which none of us had experience within the past. We got the opportunity to get acquainted with Amazon Web Services (AWS), specifically Amazon Lexa. We intend to use the same tool for further advancements for this bot as well. 

Next steps for LionAdvisor

We would like embed more emotions within the answers for our chatbot(
 i.e improves HCI) 


We also want to develop an Amazon Lamda function in order to show escalation and sensitivity within UX
As said before, improving HCI would be one of the biggest goals
We plan on getting a live Penn state advisor to look at the machine and check if it is doing the right thing.
Another big thing, is we want to implement a side by side platform learning experience for the actual Penn state advisor, so every move is then checkmarked by a live advisor to check the accuracy or the closest it is to understand students. It would also plan and stop on 99%accuracy. 

",,https://drive.google.com/file/d/1N7R0JSuDs5BOgOIKceI8Q6p0SDJwhxWq/view?usp=sharing,,"amazon-web-services, bot, machine-learning, ai",Penn State,"","",mkd5443,Medha,Deeptimahanti,mkd5443@psu.edu,Pennsylvania State University,3,ebk5145,Eesh,Kamrah,ebk5145@psu.edu,axs6453,Anmolika,Singh,axs6453@psu.edu,saahithi2700,Saahithi,Mallarapu,saahithi2700@gmail.com
HackPSU Overall - Tech,LionAdvisor,76,https://hackpsu-fall-2018.devpost.com/submissions/102470-lionadvisor,"Inspiration

We were looking for a specific striking problem which is very crucial for the students and the administration of Penn State. We brainstormed ideas, looking into complications we as Penn State students faced. Academic Advising stood out to us as a recurring problem faced by not just us but a majority of our peers. Waiting in a queue for over an hour, not being able to acquire advising at our convince, scheduling an appointment according to our class schedule has always been a hassle. The advisors as well receive very similar questions or questions that are futile from the students which can get very repetitive and tiring for the advisor. We also looked into the availability of academic advisors in the Commonwealth and world campuses and discovered some commonwealth campuses having just one or two advisors per campus. We found that as a recurring problem too and made our tool accessible to them as well.

What it does

Our product is an online academic advising tool which is centered around HCI and UI. This interface takes advising to the next level by being available to students at any point of the day. As of now, our MVP is capable of answering basic questions that a student might encounter and may need answers for immediately. The regression algorithm in the backend of our tool employs machine learning to identify stress patterns in the language mechanism of a student’s response.  Our ultimate goal is for the chat tool’s algorithm to populate the response directory using live human interactions between students and advisors to generate responses to any query that a student might run into. 

How we built it

Using AWS Lex and AWS Lambda we developed our basic chatbot and further employed Amazon Comprehend to understand language pattern developed in the AWS platform. In creating the basic framework for our bot, we created different intents to figure out different situations that a bot might come across when a student sends in a query. For example, we created an intent for different sectors in advising such as GPA requirement, Graduation, etc. Once we perfected the different intents that we wanted our tool to implement, we came up with different utterances, i.e., different ways the student might ask the same questions to show the variability of sentence formation. For the MVP as of today, we listed out the most suitable answers providing hyperlinks to various external resources. 
To extend this idea, we included a regression model, by creating emotion intents that track the text that the tool receives from the student to judge his or her emotional quotient. For example, we created an intent called ‘Happiness’, and then created utterances below it such as “This was very helpful.”. Words like ‘helpful’ depict happiness and a positive response. To add on to the user interface of this feature, the bot asks for a percentile rating of their experience. 

Challenges we ran into

1)  It took a great deal of brainstorming to find a focus on our overall idea towards making advising more accessible to students and at the same time to save the time and effort of Penn State administrative staff. 
2)  We laid out a bunch of cloud platforms options available to us, such as Google Cloud Platform, Amazon Web Services and various other online software. We went ahead with AWS as it was the only platform that allowed us to format and create bots.’
3)  Developing the HCI component of the chatbot and making it more human-like took us a great deal of time as this was our first time working with the platform and also since we had to figure out various emotions of a student.
4)  Being able to address different aspects of each question by writing out each of the question in different utterances (writing various questions that mean the same thing).
5)  Developing different indents such as GPA requirements, graduation, etc, took us a while to figure out.

Accomplishments that we're proud of

We self-learned our way through AWS although it took some time it was fruitful at the end. Our first prototype met expectations and we can picture the near future of LionAdvisor and the possibilities it can achieve with some external additions to our current bot. 

What we learned

This was our first opportunity participating in a full-fledged hackathon. We learned how to identify a real-world problem equipped with a perfect solution according to us. Being able to use our analytical and logical skills in a short duration without cracking under pressure is something that we have accomplished. A totally new concept of chatbots which none of us had experience within the past. We got the opportunity to get acquainted with Amazon Web Services (AWS), specifically Amazon Lexa. We intend to use the same tool for further advancements for this bot as well. 

Next steps for LionAdvisor

We would like embed more emotions within the answers for our chatbot(
 i.e improves HCI) 


We also want to develop an Amazon Lamda function in order to show escalation and sensitivity within UX
As said before, improving HCI would be one of the biggest goals
We plan on getting a live Penn state advisor to look at the machine and check if it is doing the right thing.
Another big thing, is we want to implement a side by side platform learning experience for the actual Penn state advisor, so every move is then checkmarked by a live advisor to check the accuracy or the closest it is to understand students. It would also plan and stop on 99%accuracy. 

",,https://drive.google.com/file/d/1N7R0JSuDs5BOgOIKceI8Q6p0SDJwhxWq/view?usp=sharing,,"amazon-web-services, bot, machine-learning, ai",Penn State,"","",mkd5443,Medha,Deeptimahanti,mkd5443@psu.edu,Pennsylvania State University,3,ebk5145,Eesh,Kamrah,ebk5145@psu.edu,axs6453,Anmolika,Singh,axs6453@psu.edu,saahithi2700,Saahithi,Mallarapu,saahithi2700@gmail.com
Best Social Good Hack from Fidelity Weekly Challenge,LionAdvisor,76,https://hackpsu-fall-2018.devpost.com/submissions/102470-lionadvisor,"Inspiration

We were looking for a specific striking problem which is very crucial for the students and the administration of Penn State. We brainstormed ideas, looking into complications we as Penn State students faced. Academic Advising stood out to us as a recurring problem faced by not just us but a majority of our peers. Waiting in a queue for over an hour, not being able to acquire advising at our convince, scheduling an appointment according to our class schedule has always been a hassle. The advisors as well receive very similar questions or questions that are futile from the students which can get very repetitive and tiring for the advisor. We also looked into the availability of academic advisors in the Commonwealth and world campuses and discovered some commonwealth campuses having just one or two advisors per campus. We found that as a recurring problem too and made our tool accessible to them as well.

What it does

Our product is an online academic advising tool which is centered around HCI and UI. This interface takes advising to the next level by being available to students at any point of the day. As of now, our MVP is capable of answering basic questions that a student might encounter and may need answers for immediately. The regression algorithm in the backend of our tool employs machine learning to identify stress patterns in the language mechanism of a student’s response.  Our ultimate goal is for the chat tool’s algorithm to populate the response directory using live human interactions between students and advisors to generate responses to any query that a student might run into. 

How we built it

Using AWS Lex and AWS Lambda we developed our basic chatbot and further employed Amazon Comprehend to understand language pattern developed in the AWS platform. In creating the basic framework for our bot, we created different intents to figure out different situations that a bot might come across when a student sends in a query. For example, we created an intent for different sectors in advising such as GPA requirement, Graduation, etc. Once we perfected the different intents that we wanted our tool to implement, we came up with different utterances, i.e., different ways the student might ask the same questions to show the variability of sentence formation. For the MVP as of today, we listed out the most suitable answers providing hyperlinks to various external resources. 
To extend this idea, we included a regression model, by creating emotion intents that track the text that the tool receives from the student to judge his or her emotional quotient. For example, we created an intent called ‘Happiness’, and then created utterances below it such as “This was very helpful.”. Words like ‘helpful’ depict happiness and a positive response. To add on to the user interface of this feature, the bot asks for a percentile rating of their experience. 

Challenges we ran into

1)  It took a great deal of brainstorming to find a focus on our overall idea towards making advising more accessible to students and at the same time to save the time and effort of Penn State administrative staff. 
2)  We laid out a bunch of cloud platforms options available to us, such as Google Cloud Platform, Amazon Web Services and various other online software. We went ahead with AWS as it was the only platform that allowed us to format and create bots.’
3)  Developing the HCI component of the chatbot and making it more human-like took us a great deal of time as this was our first time working with the platform and also since we had to figure out various emotions of a student.
4)  Being able to address different aspects of each question by writing out each of the question in different utterances (writing various questions that mean the same thing).
5)  Developing different indents such as GPA requirements, graduation, etc, took us a while to figure out.

Accomplishments that we're proud of

We self-learned our way through AWS although it took some time it was fruitful at the end. Our first prototype met expectations and we can picture the near future of LionAdvisor and the possibilities it can achieve with some external additions to our current bot. 

What we learned

This was our first opportunity participating in a full-fledged hackathon. We learned how to identify a real-world problem equipped with a perfect solution according to us. Being able to use our analytical and logical skills in a short duration without cracking under pressure is something that we have accomplished. A totally new concept of chatbots which none of us had experience within the past. We got the opportunity to get acquainted with Amazon Web Services (AWS), specifically Amazon Lexa. We intend to use the same tool for further advancements for this bot as well. 

Next steps for LionAdvisor

We would like embed more emotions within the answers for our chatbot(
 i.e improves HCI) 


We also want to develop an Amazon Lamda function in order to show escalation and sensitivity within UX
As said before, improving HCI would be one of the biggest goals
We plan on getting a live Penn state advisor to look at the machine and check if it is doing the right thing.
Another big thing, is we want to implement a side by side platform learning experience for the actual Penn state advisor, so every move is then checkmarked by a live advisor to check the accuracy or the closest it is to understand students. It would also plan and stop on 99%accuracy. 

",,https://drive.google.com/file/d/1N7R0JSuDs5BOgOIKceI8Q6p0SDJwhxWq/view?usp=sharing,,"amazon-web-services, bot, machine-learning, ai",Penn State,"","",mkd5443,Medha,Deeptimahanti,mkd5443@psu.edu,Pennsylvania State University,3,ebk5145,Eesh,Kamrah,ebk5145@psu.edu,axs6453,Anmolika,Singh,axs6453@psu.edu,saahithi2700,Saahithi,Mallarapu,saahithi2700@gmail.com
JPMC - Best Social Good Hack,LionAdvisor,76,https://hackpsu-fall-2018.devpost.com/submissions/102470-lionadvisor,"Inspiration

We were looking for a specific striking problem which is very crucial for the students and the administration of Penn State. We brainstormed ideas, looking into complications we as Penn State students faced. Academic Advising stood out to us as a recurring problem faced by not just us but a majority of our peers. Waiting in a queue for over an hour, not being able to acquire advising at our convince, scheduling an appointment according to our class schedule has always been a hassle. The advisors as well receive very similar questions or questions that are futile from the students which can get very repetitive and tiring for the advisor. We also looked into the availability of academic advisors in the Commonwealth and world campuses and discovered some commonwealth campuses having just one or two advisors per campus. We found that as a recurring problem too and made our tool accessible to them as well.

What it does

Our product is an online academic advising tool which is centered around HCI and UI. This interface takes advising to the next level by being available to students at any point of the day. As of now, our MVP is capable of answering basic questions that a student might encounter and may need answers for immediately. The regression algorithm in the backend of our tool employs machine learning to identify stress patterns in the language mechanism of a student’s response.  Our ultimate goal is for the chat tool’s algorithm to populate the response directory using live human interactions between students and advisors to generate responses to any query that a student might run into. 

How we built it

Using AWS Lex and AWS Lambda we developed our basic chatbot and further employed Amazon Comprehend to understand language pattern developed in the AWS platform. In creating the basic framework for our bot, we created different intents to figure out different situations that a bot might come across when a student sends in a query. For example, we created an intent for different sectors in advising such as GPA requirement, Graduation, etc. Once we perfected the different intents that we wanted our tool to implement, we came up with different utterances, i.e., different ways the student might ask the same questions to show the variability of sentence formation. For the MVP as of today, we listed out the most suitable answers providing hyperlinks to various external resources. 
To extend this idea, we included a regression model, by creating emotion intents that track the text that the tool receives from the student to judge his or her emotional quotient. For example, we created an intent called ‘Happiness’, and then created utterances below it such as “This was very helpful.”. Words like ‘helpful’ depict happiness and a positive response. To add on to the user interface of this feature, the bot asks for a percentile rating of their experience. 

Challenges we ran into

1)  It took a great deal of brainstorming to find a focus on our overall idea towards making advising more accessible to students and at the same time to save the time and effort of Penn State administrative staff. 
2)  We laid out a bunch of cloud platforms options available to us, such as Google Cloud Platform, Amazon Web Services and various other online software. We went ahead with AWS as it was the only platform that allowed us to format and create bots.’
3)  Developing the HCI component of the chatbot and making it more human-like took us a great deal of time as this was our first time working with the platform and also since we had to figure out various emotions of a student.
4)  Being able to address different aspects of each question by writing out each of the question in different utterances (writing various questions that mean the same thing).
5)  Developing different indents such as GPA requirements, graduation, etc, took us a while to figure out.

Accomplishments that we're proud of

We self-learned our way through AWS although it took some time it was fruitful at the end. Our first prototype met expectations and we can picture the near future of LionAdvisor and the possibilities it can achieve with some external additions to our current bot. 

What we learned

This was our first opportunity participating in a full-fledged hackathon. We learned how to identify a real-world problem equipped with a perfect solution according to us. Being able to use our analytical and logical skills in a short duration without cracking under pressure is something that we have accomplished. A totally new concept of chatbots which none of us had experience within the past. We got the opportunity to get acquainted with Amazon Web Services (AWS), specifically Amazon Lexa. We intend to use the same tool for further advancements for this bot as well. 

Next steps for LionAdvisor

We would like embed more emotions within the answers for our chatbot(
 i.e improves HCI) 


We also want to develop an Amazon Lamda function in order to show escalation and sensitivity within UX
As said before, improving HCI would be one of the biggest goals
We plan on getting a live Penn state advisor to look at the machine and check if it is doing the right thing.
Another big thing, is we want to implement a side by side platform learning experience for the actual Penn state advisor, so every move is then checkmarked by a live advisor to check the accuracy or the closest it is to understand students. It would also plan and stop on 99%accuracy. 

",,https://drive.google.com/file/d/1N7R0JSuDs5BOgOIKceI8Q6p0SDJwhxWq/view?usp=sharing,,"amazon-web-services, bot, machine-learning, ai",Penn State,"","",mkd5443,Medha,Deeptimahanti,mkd5443@psu.edu,Pennsylvania State University,3,ebk5145,Eesh,Kamrah,ebk5145@psu.edu,axs6453,Anmolika,Singh,axs6453@psu.edu,saahithi2700,Saahithi,Mallarapu,saahithi2700@gmail.com
"",HackPSU_Self_Driving_Car,20,https://hackpsu-fall-2018.devpost.com/submissions/102471-hackpsu_self_driving_car,"Inspiration

What it does

How we built it

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for HackPSU_Self_Driving_Car

(Train & Test) plot against Epochs (iterations)

Plot to find the optimum number of Epochs (iterations) for Artificial Neural Network (for the setting of the car using Camera resolution 600x300 pixels, Batch Size = 40, Learnig Rate =0.0025,)
1) Accuracy(Train & Test) plot against Epochs(iterations)
2) Loss Function (Train & Test) plot against Epochs (iterations)
",,https://github.com/avalanche21/HackPSU_Self_Driving_Car,,python,Pennsylvania State University,"","",avalanche21,Visanu,Chumongkhon,visanu_mv@hotmail.com,Pennsylvania State University,1,mori39,mori39,,mori39@163.com
Nittany AI Alliance - AI Challenge,Personalised Recommandation Restaurant Application,68,https://hackpsu-fall-2018.devpost.com/submissions/102473-personalised-recommandation-restaurant-application,"In Penn State University, we have more than 40 thousand students. We all have one thing in common, which is wondering where to eat every day. This issue has struggled me during the past three years, so we came up with this restaurant recommendation application mainly for Penn State student. In our application, we will record the user's profile which includes, allergy, budget and waiting time. After building up the profile, we will recommend the most suitable restaurant near the users based on their profile features. In order to build up this awesome application, we used python to illustrate the connection between front end and back end, and use R to build up the recommendation algorithm. Hopefully, one day, when we publish this application, Penn state students will no longer suffer from undecided restaurant choices and get the best recommendation for them.
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36360/zip_files/Personalized__Restaurant__Recommendation__________Program.pdf,"python, r, flask",Penn State University,"","",Nae-RongChang,Nae-Rong,Chang,nxc0570@gmail.com,Pennsylvania State University,1,yuxuanxia1998,Yuxuan,Xia,yuxuanxia1998@gmail.com
JPMC - Best Social Good Hack,Personalised Recommandation Restaurant Application,68,https://hackpsu-fall-2018.devpost.com/submissions/102473-personalised-recommandation-restaurant-application,"In Penn State University, we have more than 40 thousand students. We all have one thing in common, which is wondering where to eat every day. This issue has struggled me during the past three years, so we came up with this restaurant recommendation application mainly for Penn State student. In our application, we will record the user's profile which includes, allergy, budget and waiting time. After building up the profile, we will recommend the most suitable restaurant near the users based on their profile features. In order to build up this awesome application, we used python to illustrate the connection between front end and back end, and use R to build up the recommendation algorithm. Hopefully, one day, when we publish this application, Penn state students will no longer suffer from undecided restaurant choices and get the best recommendation for them.
",,,https://s3.amazonaws.com/challengepost/zip_files/production/36360/zip_files/Personalized__Restaurant__Recommendation__________Program.pdf,"python, r, flask",Penn State University,"","",Nae-RongChang,Nae-Rong,Chang,nxc0570@gmail.com,Pennsylvania State University,1,yuxuanxia1998,Yuxuan,Xia,yuxuanxia1998@gmail.com
HackPSU Overall - Tech,Kaiwa,43,https://hackpsu-fall-2018.devpost.com/submissions/102474-kaiwa,"Inspiration

I have always wanted to use technology to do good for others. Given the state of technology, I realized we can make it easy for deaf people to communicate with others by using speech to text, and text to speech (not yet implemented in app)

What it does

It does speech to text in real time on camera view. This way, people can look at other person's face as he/she speaks. Doing so allow deaf people to have similar experience to actually having a conversation with many others

How I built it

I used swift mostly. I also wanted to integrate firebase and store information necessary on real time database, but time did not allow..

Challenges I ran into

Presenting camera view was more challenging that I thought originally. 

Accomplishments that I'm proud of

Well, it works!!

What I learned

I came up with a neat way to make network layer. Too bad, I did not have time to actually implement those...

What's next for Kaiwa

Continue on integration with firebase (3 hours)
Text to speech on same screen (2 hours)
ore research in MessageKit
Having a editable text field that suits the rest of app design (?? hours)
",,https://github.com/ttakasawa/Kaiwa2.git,https://s3.amazonaws.com/challengepost/zip_files/production/36364/zip_files/Kaiwa.zip,"swift, firebase",Penn State,"","",ttakasawa,ttakasawa,,tom_takasawa@icloud.com,Pennsylvania State University,0
Best Social Good Hack from Fidelity Weekly Challenge,Kaiwa,43,https://hackpsu-fall-2018.devpost.com/submissions/102474-kaiwa,"Inspiration

I have always wanted to use technology to do good for others. Given the state of technology, I realized we can make it easy for deaf people to communicate with others by using speech to text, and text to speech (not yet implemented in app)

What it does

It does speech to text in real time on camera view. This way, people can look at other person's face as he/she speaks. Doing so allow deaf people to have similar experience to actually having a conversation with many others

How I built it

I used swift mostly. I also wanted to integrate firebase and store information necessary on real time database, but time did not allow..

Challenges I ran into

Presenting camera view was more challenging that I thought originally. 

Accomplishments that I'm proud of

Well, it works!!

What I learned

I came up with a neat way to make network layer. Too bad, I did not have time to actually implement those...

What's next for Kaiwa

Continue on integration with firebase (3 hours)
Text to speech on same screen (2 hours)
ore research in MessageKit
Having a editable text field that suits the rest of app design (?? hours)
",,https://github.com/ttakasawa/Kaiwa2.git,https://s3.amazonaws.com/challengepost/zip_files/production/36364/zip_files/Kaiwa.zip,"swift, firebase",Penn State,"","",ttakasawa,ttakasawa,,tom_takasawa@icloud.com,Pennsylvania State University,0
JPMC - Best Social Good Hack,Kaiwa,43,https://hackpsu-fall-2018.devpost.com/submissions/102474-kaiwa,"Inspiration

I have always wanted to use technology to do good for others. Given the state of technology, I realized we can make it easy for deaf people to communicate with others by using speech to text, and text to speech (not yet implemented in app)

What it does

It does speech to text in real time on camera view. This way, people can look at other person's face as he/she speaks. Doing so allow deaf people to have similar experience to actually having a conversation with many others

How I built it

I used swift mostly. I also wanted to integrate firebase and store information necessary on real time database, but time did not allow..

Challenges I ran into

Presenting camera view was more challenging that I thought originally. 

Accomplishments that I'm proud of

Well, it works!!

What I learned

I came up with a neat way to make network layer. Too bad, I did not have time to actually implement those...

What's next for Kaiwa

Continue on integration with firebase (3 hours)
Text to speech on same screen (2 hours)
ore research in MessageKit
Having a editable text field that suits the rest of app design (?? hours)
",,https://github.com/ttakasawa/Kaiwa2.git,https://s3.amazonaws.com/challengepost/zip_files/production/36364/zip_files/Kaiwa.zip,"swift, firebase",Penn State,"","",ttakasawa,ttakasawa,,tom_takasawa@icloud.com,Pennsylvania State University,0
"",GM Silly Car,9,https://hackpsu-fall-2018.devpost.com/submissions/102475-gm-silly-car,"Inspiration

I needed a good small project to learn about arduino, so I made the GM car go forward and stop! 

What it does

How I built it

Challenges I ran into

Accomplishments that I'm proud of

What I learned

What's next for GM Silly Car
",,https://github.com/andjam19/GMSILLYCAR2018,,arduino,PSU,"","",andjam19,andjam19,,andjam19@yahoo.com,Pennsylvania State University,0
Capital One - Best Financial Hack,Foliate,53,https://hackpsu-fall-2018.devpost.com/submissions/102476-foliate,"Inspiration

It can be hard and awkward to ask how your friends and family are financially invested in different asset classes: whether equities, futures, cryptocurrencies, etc. Yet it is common to learn about different investment vehicles through suggestions of friends, online communities and family members. 

What it does

We propose a social platform for traders and investors to learn about each other’s alternative investments and compete in weekly & monthly portfolio performance tournaments. 

How we built it

Our proof of concept is built around cryptocurrency assets. We connected to Binance's API (World's largest cryptocurrency exchange). Web development is built with angular.js. There is a global and community (for friends to compete) leaderboard

Challenges we ran into

We wanted to connect to APIs of exchanges for all assets including equities (common stock), indices (S&P 500), Commodities, Bonds and forex but found the API buildout very challenging. We also wished we had time to make the platform more social and interactive. 

Accomplishments that we're proud of

Binance API Key, Homepage, leaderboard, profile, idea generation

What we learned

Exchanges do not have easy to work with APIs. 

What's next for Foliate

Allow people to connect with their friend and families' portfolio by connecting with Facebook, LinkedIn, etc. Creating better widgets and charts to visualize portfolio performances and diversification. 
",,,,"angular.js, bootstrap, html5, css3, api, .py",Penn State,"","",TeamFoliate,Josh S.S,Han,josh.h.career@gmail.com,Pennsylvania State University,1,welsakka,Waleed,Elsakka,waleedpahome@live.com
"",Portable Music Converter in Python,41,https://hackpsu-fall-2018.devpost.com/submissions/102477-portable-music-converter-in-python,"Inspiration

Wanted to create a program that compresses music for portable usage.

What it does

Currently... not much. It was a a lot of learning and a lot of learning I didn't know a lot. I did get a good jump on learning TKinter though!

How I built it

Python! I know that to see my final project through, I will want to learn some SQL as well!

Challenges I ran into

Thinking that I had more resources and thinking I knew a little more than I actually did!

Accomplishments that I'm proud of

Learning the basics of TKinter. It is definitely a little finicky, but I really like the overarching idea behind it. I will definitely be using it more going forward!

What I learned

That I didn't know nearly as much as I thought I did as well as how much the project I was going for required.
",,https://github.com/kamikaziH2Omln/MusicShenangos,,"",Pennsylvania State University,"","",nfw5030,Nathan,Wagman,nfw5030@psu.edu,Pennsylvania State University,0
